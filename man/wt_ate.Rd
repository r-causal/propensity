% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/weights.R
\name{wt_ate}
\alias{wt_ate}
\alias{wt_att}
\alias{wt_atu}
\alias{wt_atm}
\alias{wt_ato}
\alias{wt_entropy}
\title{Calculate Propensity Score Weights for Causal Inference}
\usage{
wt_ate(
  .propensity,
  .exposure,
  .sigma = NULL,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  stabilize = FALSE,
  stabilization_score = NULL,
  ...
)

wt_att(
  .propensity,
  .exposure,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  ...
)

wt_atu(
  .propensity,
  .exposure,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  ...
)

wt_atm(
  .propensity,
  .exposure,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  ...
)

wt_ato(
  .propensity,
  .exposure,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  ...
)

wt_entropy(
  .propensity,
  .exposure,
  exposure_type = c("auto", "binary", "categorical", "continuous"),
  .treated = NULL,
  .untreated = NULL,
  ...
)
}
\arguments{
\item{.propensity}{Either a numeric vector of predicted probabilities or a
\code{data.frame} where each column corresponds to a level of the exposure.}

\item{.exposure}{The exposure variable. For binary exposures, a vector of 0s
and 1s; for continuous exposures, a numeric vector.}

\item{.sigma}{For continuous exposures, a numeric vector of standard errors
used with \code{dnorm()}. For example, this can be derived from the influence
measures of a model (e.g., \code{influence(model)$sigma}).}

\item{exposure_type}{Character string specifying the type of exposure.
Options are \code{"auto"}, \code{"binary"}, \code{"categorical"}, and \code{"continuous"}.
Defaults to \code{"auto"}, which detects the type automatically.}

\item{.treated}{The value representing the treatment group. If not provided,
it is automatically detected.}

\item{.untreated}{The value representing the control group. If not provided,
it is automatically detected.}

\item{stabilize}{Logical indicating whether to stabilize the weights. For ATE
weights, stabilization multiplies the weight by either the mean of
\code{.exposure} or the supplied \code{stabilization_score}.}

\item{stabilization_score}{Optional numeric value for stabilizing the weights
(e.g., a predicted value from a regression model without predictors). Only
used when \code{stabilize} is \code{TRUE}.}

\item{...}{Reserved for future expansion. Not currently used.}
}
\value{
A \code{psw} object (a numeric vector) with additional attributes:
\itemize{
\item \strong{estimand}: A description of the estimand (e.g., "ate", "att").
\item \strong{stabilized}: A logical flag indicating if stabilization was applied.
\item \strong{trimmed}: A logical flag indicating if the weights are based on trimmed propensity scores.
\item \strong{truncated}: A logical flag indicating if the weights are based on truncated propensity scores.
}
}
\description{
This family of functions computes propensity score weights for
various causal estimands:
\itemize{
\item \strong{ATE} (Average Treatment Effect)
\item \strong{ATT} (Average Treatment Effect on the Treated)
\item \strong{ATU} (Average Treatment Effect on the Untreated, sometimes called
the \strong{ATC}, where the "C" stands for "control")
\item \strong{ATM} (Average Treatment Effect for the Evenly Matchable)
\item \strong{ATO} (Average Treatment Effect for the Overlap population)
\item \strong{Entropy} (Average Treatment Effect for the Entropy-weighted population)

The propensity score can be provided as a numeric vector of predicted
probabilities or as a \code{data.frame} where each column represents the
predicted probability for a level of the exposure. They can also be
propensity score objects created by \code{\link[=ps_trim]{ps_trim()}}, \code{\link[=ps_refit]{ps_refit()}}, or
\code{\link[=ps_trunc]{ps_trunc()}}

The returned weights are encapsulated in a \code{psw} object, which is a numeric
vector with additional attributes that record the estimand, and whether the
weights have been stabilized, trimmed, or truncated.
}
}
\details{
\subsection{Theoretical Background}{

Propensity score weighting is a method for estimating causal effects by
creating a pseudo-population where the exposure is independent of measured
confounders. The propensity score, \eqn{e(X)}, is the probability of receiving
treatment given observed covariates \eqn{X}. By weighting observations inversely
proportional to their propensity scores, we can balance the distribution of
covariates between treatment groups. Other weights allow for different target populations.
}

\subsection{Mathematical Formulas}{
\subsection{Binary Exposures}{

For binary treatments (\eqn{A = 0} or \eqn{1}), the weights are:
\itemize{
\item \strong{ATE}: \eqn{w = \frac{A}{e(X)} + \frac{1-A}{1-e(X)}}
\item \strong{ATT}: \eqn{w = A + \frac{(1-A) \cdot e(X)}{1-e(X)}}
\item \strong{ATU}: \eqn{w = \frac{A \cdot (1-e(X))}{e(X)} + (1-A)}
\item \strong{ATM}: \eqn{w = \frac{\min(e(X), 1-e(X))}{A \cdot e(X) + (1-A) \cdot (1-e(X))}}
\item \strong{ATO}: \eqn{w = A \cdot (1-e(X)) + (1-A) \cdot e(X)}
\item \strong{Entropy}: \eqn{w = \frac{h(e(X))}{A \cdot e(X) + (1-A) \cdot (1-e(X))}}, where \eqn{h(e) = -[e \cdot \log(e) + (1-e) \cdot \log(1-e)]}
}
}

\subsection{Continuous Exposures}{

For continuous treatments, weights use the density ratio:
\eqn{w = \frac{f_A(A)}{f_{A|X}(A|X)}}, where \eqn{f_A} is the marginal density of \eqn{A}
and \eqn{f_{A|X}} is the conditional density given \eqn{X}.
}

}

\subsection{Exposure Types}{

The functions support different types of exposures:
\itemize{
\item \strong{\code{binary}}: For dichotomous treatments (e.g. 0/1).
\item \strong{\code{continuous}}: For numeric exposures. Here, weights are calculated via the normal density using
\code{dnorm()}.
\item \strong{\code{categorical}}: Currently not supported (an error will be raised).
\item \strong{\code{auto}}: Automatically detects the exposure type based on \code{.exposure}.
}
}

\subsection{Stabilization}{

For ATE weights, stabilization can improve the performance of the estimator
by reducing variance. When \code{stabilize} is \code{TRUE} and no
\code{stabilization_score} is provided, the weights are multiplied by the mean
of \code{.exposure}. Alternatively, if a \code{stabilization_score} is provided, it
is used as the multiplier. Stabilized weights have the form:
\eqn{w_s = f_A(A) \times w}, where \eqn{f_A(A)} is the marginal probability or density.
}

\subsection{Weight Properties and Diagnostics}{

Extreme weights can indicate:
\itemize{
\item Positivity violations (near 0 or 1 propensity scores)
\item Poor model specification
\item Lack of overlap between treatment groups
}

See the halfmoon package for tools to diagnose and visualize weights.

You can address extreme weights in several ways. The first is to modify the target population:
use trimming, truncation, or alternative estimands (ATM, ATO, entropy).
Another technique that can help is stabilization, which reduces variance of the weights.
}

\subsection{Trimmed and Truncated Weights}{

In addition to the standard weight functions, versions exist for trimmed
and truncated propensity score weights created by \code{\link[=ps_trim]{ps_trim()}},
\code{\link[=ps_trunc]{ps_trunc()}}, and \code{\link[=ps_refit]{ps_refit()}}. These variants calculate the weights using
modified propensity scores (trimmed or truncated) and update the estimand
attribute accordingly.
}
}
\examples{
## Basic Usage with Binary Exposures

# Simulate a simple dataset
set.seed(123)
n <- 100
propensity_scores <- runif(n, 0.1, 0.9)
treatment <- rbinom(n, 1, propensity_scores)

# Calculate different weight types
weights_ate <- wt_ate(propensity_scores, treatment)
weights_att <- wt_att(propensity_scores, treatment)
weights_atu <- wt_atu(propensity_scores, treatment)
weights_atm <- wt_atm(propensity_scores, treatment)
weights_ato <- wt_ato(propensity_scores, treatment)
weights_entropy <- wt_entropy(propensity_scores, treatment)

# Compare weight distributions
summary(weights_ate)
summary(weights_ato)  # Often more stable than ATE

## Stabilized Weights

# Stabilization reduces variance
weights_ate_stab <- wt_ate(propensity_scores, treatment, stabilize = TRUE)

# Compare coefficient of variation
sd(weights_ate) / mean(weights_ate)      # Unstabilized
sd(weights_ate_stab) / mean(weights_ate_stab)  # Stabilized (lower is better)

## Handling Extreme Propensity Scores

# Create data with positivity violations
ps_extreme <- c(0.01, 0.02, 0.98, 0.99, rep(0.5, 4))
trt_extreme <- c(0, 0, 1, 1, 0, 1, 0, 1)

# Standard ATE weights can be extreme
wt_extreme <- wt_ate(ps_extreme, trt_extreme)
# Very large!
max(wt_extreme)  

# ATO weights are bounded, 
wt_extreme_atm <- wt_ato(ps_extreme, trt_extreme)
# Much more reasonable
max(wt_extreme_atm)  
# but they target a different population
estimand(wt_extreme_atm) # "ato"

}
\references{
For detailed guidance on causal inference in R, see \href{https://www.r-causal.org/}{\emph{Causal Inference in R}}
by Malcolm Barrett, Lucy D'Agostino McGowan, and Travis Gerke.
\subsection{Foundational Papers}{

Rosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity
score in observational studies for causal effects. \emph{Biometrika}, 70(1), 41-55.
}

\subsection{Estimand-Specific Methods}{

Li, L., & Greene, T. (2013). A weighting analogue to pair matching in
propensity score analysis. \emph{The International Journal of Biostatistics}, 9(2),
215-234. (ATM weights)

Li, F., Morgan, K. L., & Zaslavsky, A. M. (2018). Balancing covariates via
propensity score weighting. \emph{Journal of the American Statistical Association},
113(521), 390-400. (ATO weights)

Zhou, Y., Matsouaka, R. A., & Thomas, L. (2020). Propensity score weighting
under limited overlap and model misspecification. \emph{Statistical Methods in
Medical Research}, 29(12), 3721-3756. (Entropy weights)
}

\subsection{Continuous Exposures}{

Hirano, K., & Imbens, G. W. (2004). The propensity score with continuous
treatments. \emph{Applied Bayesian Modeling and Causal Inference from
Incomplete-Data Perspectives}, 226164, 73-84.
}

\subsection{Practical Guidance}{

Austin, P. C., & Stuart, E. A. (2015). Moving towards best practice when
using inverse probability of treatment weighting (IPTW) using the propensity
score to estimate causal treatment effects in observational studies.
\emph{Statistics in Medicine}, 34(28), 3661-3679.
}
}
\seealso{
\itemize{
\item \code{\link[=psw]{psw()}} for details on the structure of the returned weight objects.
\item \code{\link[=ps_trim]{ps_trim()}}, \code{\link[=ps_trunc]{ps_trunc()}}, and \code{\link[=ps_refit]{ps_refit()}} for handling extreme weights.
\item \code{\link[=ps_calibrate]{ps_calibrate()}} for calibrating weights.
}
}
