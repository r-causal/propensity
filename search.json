[{"path":"https://r-causal.github.io/propensity/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2026 propensity authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Getting Started with propensity","text":"’ll work simulated dataset throughout. two confounders (x1 x2), binary exposure (z), binary outcome (y): x1 x2 affect treatment outcome, need adjust .","code":"library(propensity) set.seed(42) n <- 100 x1 <- rnorm(n) x2 <- rnorm(n) z <- rbinom(n, 1, plogis(0.5 * x1 + 0.3 * x2)) y <- rbinom(n, 1, plogis(-0.5 + 0.8 * z + 0.3 * x1 + 0.2 * x2)) dat <- data.frame(x1, z, y, x2)"},{"path":[]},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"step-1-fit-a-propensity-score-model","dir":"Articles","previous_headings":"Basic workflow","what":"Step 1: Fit a propensity score model","title":"Getting Started with propensity","text":"Start model treatment assignment. use logistic regression:","code":"ps_mod <- glm(z ~ x1 + x2, data = dat, family = binomial())"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"step-2-calculate-weights-and-fit-a-weighted-outcome-model","dir":"Articles","previous_headings":"Basic workflow","what":"Step 2: Calculate weights and fit a weighted outcome model","title":"Getting Started with propensity","text":"Pass fitted model directly wt_ate() get ATE weights. pulls fitted values exposure : wt_ate() returns psw object, just numeric vector extra metadata attached: can also pass propensity scores plain numeric vector. case need supply exposure :","code":"wts <- wt_ate(ps_mod) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 outcome_mod <- glm(y ~ z, data = dat, family = binomial(), weights = wts) #> Warning in eval(family$initialize): non-integer #successes in a binomial glm! estimand(wts) #> [1] \"ate\" is_stabilized(wts) #> [1] FALSE ps <- fitted(ps_mod) wt_ate(ps, dat$z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate}[100]> #>   [1]  1.237569  1.962759  2.211732  1.312977  1.974772  1.918957  3.413991 #>   [8]  1.844849  1.223426  2.048453  1.409967  1.189795  1.283684  2.580633 #>  [15]  1.439961  1.771951  1.627989  3.438494  1.092310  1.379591  1.414973 #>  [22]  1.142879  2.132832  2.539924  1.264028  1.584122  1.614753  1.115628 #>  [29]  2.235160  1.641530  1.598952  1.767794  1.494051  2.039262  3.465881 #>  [36]  1.174226  1.511863  1.832668  1.135144  2.045876  2.067593  2.960898 #>  [43]  1.724205  2.807457  1.296458  1.487979  1.433057  3.287998  2.085343 #>  [50]  2.000254  1.845028  1.286187  1.207434  2.360698  1.840088  1.704295 #>  [57]  1.642486  2.362152 12.582758  2.974447  1.677742  1.704949  2.553764 #>  [64]  1.438721  1.711034  1.227343  1.812465  1.409825  1.518867  3.314572 #>  [71]  1.404951  1.799540  2.354036  1.941761  1.909359  1.731474  2.080547 #>  [78]  2.731912  1.606549  3.350612  1.327948  2.103802  2.178471  2.018730 #>  [85]  3.813295  1.864473  2.078958  1.959235  1.747083  1.907159  3.853789 #>  [92]  1.584359  2.693732  1.644175  1.286716  1.788770  3.037240  1.416308 #>  [99]  1.474800  1.619529"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"step-3-estimate-causal-effects","dir":"Articles","previous_headings":"Basic workflow","what":"Step 3: Estimate causal effects","title":"Getting Started with propensity","text":"ipw() takes propensity score model weighted outcome model returns causal effect estimates. standard errors use linearization account fact propensity scores estimated:","code":"result <- ipw(ps_mod, outcome_mod) result #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1 + x2, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: glm(formula = y ~ z, family = binomial(), data = dat, weights = wts)  #>  #> Estimates: #>         estimate  std.err        z ci.lower ci.upper conf.level   p.value     #> rd       0.32000  0.10411  3.07376   0.1160  0.52404       0.95  0.002114 **  #> log(rr)  0.69137  0.12490  5.53528   0.4466  0.93618       0.95 3.107e-08 *** #> log(or)  1.32884  0.12288 10.81398   1.0880  1.56969       0.95 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"choosing-an-estimand","dir":"Articles","previous_headings":"","what":"Choosing an estimand","title":"Getting Started with propensity","text":"estimand targets different population: wt_atc() alias wt_atu(). ATE common choice. ATT ATU narrow question treated untreated, respectively. ATO, ATM, entropy weights target overlap populations – produce bounded weights construction, makes good option propensity scores extreme (). switch estimands, just swap weight function:","code":"wts_ate <- wt_ate(ps_mod) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 wts_att <- wt_att(ps_mod) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 wts_ato <- wt_ato(ps_mod) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"handling-extreme-weights","dir":"Articles","previous_headings":"","what":"Handling extreme weights","title":"Getting Started with propensity","text":"Propensity scores near 0 1 produce large weights can blow variance. summary() method gives quick look weight distribution: see large maximum high variance, options.","code":"summary(wts_ate) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.092   1.440   1.780   2.028   2.111  12.583"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"overlap-estimands","dir":"Articles","previous_headings":"Handling extreme weights","what":"Overlap estimands","title":"Getting Started with propensity","text":"easiest fix use estimand bounded weights. wt_ato() wt_atm() -weight observations overlap poor: trade-’re now targeting different population.","code":"summary(wt_ato(ps_mod)) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.08451 0.30539 0.43830 0.43370 0.52629 0.92053 summary(wt_atm(ps_mod)) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.09231 0.43965 0.78036 0.70946 1.00000 1.00000"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"trimming","dir":"Articles","previous_headings":"Handling extreme weights","what":"Trimming","title":"Getting Started with propensity","text":"ps_trim() drops observations extreme propensity scores setting NA. \"ps\" method uses fixed thresholds (default, 0.1 0.9): \"adaptive\" method (Crump et al., 2009) finds data-driven threshold: can inspect result helpers: Use !is_unit_trimmed() subset data retained observations: trimming, refit propensity score model retained sample scores reflect trimmed population: pass refitted scores weight function usual: See ?ps_trim trimming methods, including percentile-based (\"pctl\"), preference score (\"pref\"), common range (\"cr\").","code":"ps_trimmed <- ps_trim(ps, method = \"ps\") ps_trimmed_adapt <- ps_trim(ps, method = \"adaptive\") # Confirm the object has been trimmed is_ps_trimmed(ps_trimmed) #> [1] TRUE  # Which observations were removed? sum(is_unit_trimmed(ps_trimmed)) #> [1] 2  # View trimming metadata (method, cutoffs, etc.) ps_trim_meta(ps_trimmed) #> $method #> [1] \"ps\" #>  #> $lower #> [1] 0.1 #>  #> $upper #> [1] 0.9 #>  #> $keep_idx #>   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  20  21  #>   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  20  21  #>  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  #>  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  #>  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  60  61  62  #>  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  60  61  62  #>  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  #>  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  #>  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100  #>  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100  #>  #> $trimmed_idx #> [1] 19 59 retained <- !is_unit_trimmed(ps_trimmed) dat_trimmed <- dat[retained, ] ps_refitted <- ps_refit(ps_trimmed, ps_mod) is_refit(ps_refitted) #> [1] TRUE wts_trimmed <- wt_ate(ps_refitted, dat$z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 summary(wts_trimmed) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's  #>   1.073   1.386   1.726   1.970   2.157   4.724       2"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"truncation","dir":"Articles","previous_headings":"Handling extreme weights","what":"Truncation","title":"Getting Started with propensity","text":"Truncation similar trimming keeps observations – just clips extreme scores specified bounds: is_unit_truncated() tells observations clipped:","code":"ps_truncated <- ps_trunc(ps, lower = 0.05, upper = 0.95) is_ps_truncated(ps_truncated) #> [1] TRUE sum(is_unit_truncated(ps_truncated)) #> [1] 0 ps_trunc_meta(ps_truncated) #> $method #> [1] \"ps\" #>  #> $lower_bound #> [1] 0.05 #>  #> $upper_bound #> [1] 0.95 #>  #> $truncated_idx #> integer(0) wts_truncated <- wt_ate(ps_truncated, dat$z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 summary(wts_truncated) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.092   1.440   1.780   2.028   2.111  12.583"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"which-approach","dir":"Articles","previous_headings":"Handling extreme weights","what":"Which approach?","title":"Getting Started with propensity","text":"aren’t mutually exclusive. general: overlap estimands like wt_ato() easiest path research question allows . Trimming (followed ps_refit()) standard choice need ATE near-violations positivity. Truncation lighter touch want keep full sample.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"binary-outcomes","dir":"Articles","previous_headings":"Interpreting results","what":"Binary outcomes","title":"Getting Started with propensity","text":"binary outcomes, ipw() returns three effect measures: risk difference, log risk ratio, log odds ratio: .data.frame() pulls estimates data frame: Use exponentiate = TRUE get risk ratios odds ratios natural scale. standard errors, z-statistics, p-values stay log scale:","code":"result #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1 + x2, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: glm(formula = y ~ z, family = binomial(), data = dat, weights = wts)  #>  #> Estimates: #>         estimate  std.err        z ci.lower ci.upper conf.level   p.value     #> rd       0.32000  0.10411  3.07376   0.1160  0.52404       0.95  0.002114 **  #> log(rr)  0.69137  0.12490  5.53528   0.4466  0.93618       0.95 3.107e-08 *** #> log(or)  1.32884  0.12288 10.81398   1.0880  1.56969       0.95 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 as.data.frame(result) #>    effect  estimate   std.err         z  ci.lower  ci.upper conf.level #> 1      rd 0.3199973 0.1041062  3.073758 0.1159529 0.5240417       0.95 #> 2 log(rr) 0.6913736 0.1249031  5.535278 0.4465679 0.9361792       0.95 #> 3 log(or) 1.3288426 0.1228819 10.813984 1.0879986 1.5696867       0.95 #>        p.value #> 1 2.113806e-03 #> 2 3.107345e-08 #> 3 0.000000e+00 as.data.frame(result, exponentiate = TRUE) #>   effect  estimate   std.err         z  ci.lower  ci.upper conf.level #> 1     rd 0.3199973 0.1041062  3.073758 0.1159529 0.5240417       0.95 #> 2     rr 1.9964559 0.1249031  5.535278 1.5629389 2.5502189       0.95 #> 3     or 3.7766698 0.1228819 10.813984 2.9683272 4.8051424       0.95 #>        p.value #> 1 2.113806e-03 #> 2 3.107345e-08 #> 3 0.000000e+00"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"continuous-outcomes","dir":"Articles","previous_headings":"Interpreting results","what":"Continuous outcomes","title":"Getting Started with propensity","text":"continuous outcomes, ipw() returns mean difference. Use lm() outcome model:","code":"y_cont <- 2 + 0.8 * z + 0.3 * x1 + 0.2 * x2 + rnorm(n) dat$y_cont <- y_cont outcome_cont <- lm(y_cont ~ z, data = dat, weights = wts) ipw(ps_mod, outcome_cont) #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1 + x2, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: lm(formula = y_cont ~ z, data = dat, weights = wts)  #>  #> Estimates: #>      estimate std.err       z ci.lower ci.upper conf.level   p.value     #> diff  0.92737 0.20498 4.52416   0.5256   1.3291       0.95 6.064e-06 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting Started with propensity","text":"examples use binary exposures. propensity also handles continuous categorical treatments.","code":""},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"continuous-exposures","dir":"Articles","previous_headings":"Next steps","what":"Continuous exposures","title":"Getting Started with propensity","text":"continuous exposures, weights use density ratios. Stabilization usually good idea :","code":"# Fit a model for the continuous exposure ps_cont <- glm(continuous_exposure ~ x1 + x2, data = dat, family = gaussian())  # Stabilized weights (strongly recommended for continuous exposures) wts_cont <- wt_ate(ps_cont, stabilize = TRUE)"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"categorical-exposures","dir":"Articles","previous_headings":"Next steps","what":"Categorical exposures","title":"Getting Started with propensity","text":"multi-level treatments, pass matrix data frame predicted probabilities one column per level:","code":"# Multinomial propensity scores (one column per treatment level) ps_matrix <- predict(multinom_model, type = \"probs\") wt_ate(ps_matrix, exposure, exposure_type = \"categorical\")  # ATT and ATU require specifying the focal level wt_att(ps_matrix, exposure, .focal_level = \"treated\")"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"calibration","dir":"Articles","previous_headings":"Next steps","what":"Calibration","title":"Getting Started with propensity","text":"ps_calibrate() adjusts propensity scores better reflect treatment probabilities. trimming truncation deal tails, calibration reshapes whole distribution. supports logistic calibration (default) isotonic regression:","code":"ps_calibrated <- ps_calibrate(ps, dat$z, method = \"logistic\", smooth = FALSE) is_ps_calibrated(ps_calibrated)  wts_calibrated <- wt_ate(ps_calibrated, dat$z)"},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"censoring-weights","dir":"Articles","previous_headings":"Next steps","what":"Censoring weights","title":"Getting Started with propensity","text":"wt_cens() calculates inverse probability censoring weights survival longitudinal analyses:","code":"# Model the probability of being uncensored cens_mod <- glm(uncensored ~ x1 + x2, data = dat, family = binomial()) wts_cens <- wt_cens(cens_mod)  # Censoring weights use the same formula as ATE weights estimand(wts_cens) # \"uncensored\""},{"path":"https://r-causal.github.io/propensity/articles/propensity.html","id":"learning-more","dir":"Articles","previous_headings":"Next steps","what":"Learning more","title":"Getting Started with propensity","text":"See function reference details: ?wt_ate – Weight calculation estimands ?ps_trim, ?ps_trunc, ?ps_calibrate – Handling extreme propensity scores ?ipw – Inverse probability weighted estimation","code":""},{"path":"https://r-causal.github.io/propensity/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Malcolm Barrett. Author, maintainer, copyright holder.","code":""},{"path":"https://r-causal.github.io/propensity/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Barrett M (2026). propensity: Toolkit Calculating Working Propensity Scores. R package version 0.0.0.9000, https://r-causal.github.io/propensity/.","code":"@Manual{,   title = {propensity: A Toolkit for Calculating and Working with Propensity Scores},   author = {Malcolm Barrett},   year = {2026},   note = {R package version 0.0.0.9000},   url = {https://r-causal.github.io/propensity/}, }"},{"path":[]},{"path":"https://r-causal.github.io/propensity/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"propensity makes easy calculate propensity score weights use estimate causal effects. supports: Six estimands binary exposures (ATE, ATT, ATU, ATO, ATM, entropy weights) Binary, categorical, continuous exposures Trimming, truncation, calibration extreme propensity scores Inverse probability weighted estimation standard errors account propensity score estimation can learn vignette(\"propensity\").","code":""},{"path":"https://r-causal.github.io/propensity/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"can install propensity CRAN : can install development version propensity GitHub :","code":"install.packages(\"propensity\") # install.packages(\"pak\") pak::pak(\"r-causal/propensity\")"},{"path":"https://r-causal.github.io/propensity/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"ipw() uses linearization account uncertainty estimated propensity scores computing standard errors.","code":"library(propensity)  # Simulate data with a confounder, binary exposure, and binary outcome n <- 200 x1 <- rnorm(n) z <- rbinom(n, 1, plogis(0.5 * x1)) y <- rbinom(n, 1, plogis(-0.5 + 0.8 * z + 0.3 * x1)) dat <- data.frame(x1, z, y)  # Step 1: Fit a propensity score model ps_mod <- glm(z ~ x1, data = dat, family = binomial())  # Step 2: Calculate ATE weights and fit a weighted outcome model wts <- wt_ate(ps_mod) outcome_mod <- glm(y ~ z, data = dat, family = binomial(), weights = wts)  # Step 3: Estimate causal effects with correct standard errors ipw(ps_mod, outcome_mod) #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: glm(formula = y ~ z, family = binomial(), data = dat, weights = wts)  #>  #> Estimates: #>         estimate std.err       z ci.lower ci.upper conf.level   p.value     #> rd       0.14230 0.07038 2.02194   0.0044  0.28025       0.95 0.0431831 *   #> log(rr)  0.28031 0.10770 2.60262   0.0692  0.49141       0.95 0.0092513 **  #> log(or)  0.57339 0.16200 3.53950   0.2559  0.89090       0.95 0.0004009 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://r-causal.github.io/propensity/index.html","id":"estimands","dir":"","previous_headings":"","what":"Estimands","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"weight function targets different population: ATO ATM weights bounded construction, making good alternative ATE weights highly variable.","code":""},{"path":"https://r-causal.github.io/propensity/index.html","id":"learn-more","dir":"","previous_headings":"","what":"Learn more","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"Causal Inference R – book causal inference methods R vignette(\"propensity\") – Getting started propensity score weighting propensity package documentation – Full reference articles","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability Weighted Estimation — ipw","title":"Inverse Probability Weighted Estimation — ipw","text":"ipw() bring---model (BYOM) inverse probability weighted estimator causal inference. supply fitted propensity score model fitted weighted outcome model; ipw() computes causal effect estimates standard errors correctly account two-step estimation process. ipw() currently supports binary exposures binary continuous outcomes. binary outcomes, returns risk difference, log risk ratio, log odds ratio. continuous outcomes, returns difference means.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Probability Weighted Estimation — ipw","text":"","code":"ipw(   ps_mod,   outcome_mod,   .data = NULL,   estimand = NULL,   ps_link = NULL,   conf_level = 0.95 )  # S3 method for class 'ipw' as.data.frame(x, row.names = NULL, optional = NULL, exponentiate = FALSE, ...)"},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability Weighted Estimation — ipw","text":"ps_mod fitted propensity score model class stats::glm(), typically logistic regression exposure left-hand side formula. outcome_mod fitted weighted outcome model class stats::glm() stats::lm(), outcome dependent variable propensity score weights supplied via weights argument. weights created propensity weight function wt_ate(). .data data frame containing exposure, outcome, covariates. NULL (default), ipw() extracts data model objects. Supply .data explicitly outcome model formula contains transformations prevent extraction exposure variable stats::model.frame(). estimand character string specifying causal estimand: \"ate\", \"att\", \"ato\", \"atm\". NULL, estimand inferred weights outcome_mod. Auto-detection requires weights created wt_ate(), wt_att(), wt_atm(), wt_ato(). ps_link character string specifying link function used propensity score model: \"logit\", \"probit\", \"cloglog\". Defaults link used ps_mod. conf_level Confidence level intervals. Default 0.95. x ipw object. row.names, optional, ... Passed base::.data.frame(). exponentiate TRUE, exponentiate log risk ratio log odds ratio produce risk ratios odds ratios natural scale. confidence interval bounds also exponentiated. Standard errors, z statistics, p-values remain log scale. Default FALSE.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability Weighted Estimation — ipw","text":"S3 object class ipw following components: estimand causal estimand: one \"ate\", \"att\", \"ato\", \"atm\". ps_mod fitted propensity score model. outcome_mod fitted outcome model. estimates data frame one row per effect measure following columns: effect (measure name), estimate (point estimate), std.err (standard error), z (z-statistic), ci.lower ci.upper (confidence interval bounds), conf.level, p.value. .data.frame() returns estimates component data frame. exponentiate = TRUE, log(rr) log() rows transformed: point estimates confidence limits exponentiated effect labels become \"rr\" \"\".","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"workflow","dir":"Reference","previous_headings":"","what":"Workflow","title":"Inverse Probability Weighted Estimation — ipw","text":"ipw() designed around three-step workflow: Fit propensity score model (e.g., logistic regression exposure confounders). Calculate propensity score weights estimand (e.g., wt_ate()) fit weighted outcome model. Pass models ipw() obtain causal effect estimates correct standard errors. responsible specifying fitting models. ipw() handles variance estimation.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"effect-measures","dir":"Reference","previous_headings":"","what":"Effect measures","title":"Inverse Probability Weighted Estimation — ipw","text":"binary outcomes (stats::glm() family = binomial()), ipw() returns three effect measures: rd: Risk difference (marginal risk exposed minus unexposed) log(rr): Log risk ratio log(): Log odds ratio continuous outcomes (stats::lm() stats::glm() family = gaussian()), difference means (diff) returned. Use .data.frame() exponentiate = TRUE obtain risk ratios odds ratios natural scale.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"variance-estimation","dir":"Reference","previous_headings":"","what":"Variance estimation","title":"Inverse Probability Weighted Estimation — ipw","text":"Standard errors computed via linearization, correctly accounts uncertainty introduced estimating propensity scores. avoids known problem underestimated standard errors arises treating estimated weights fixed. See Kostouraki et al. (2024) details.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability Weighted Estimation — ipw","text":"Kostouraki , Hajage D, Rachet B, et al. variance estimation inverse probability--treatment weighting estimator: tutorial different types propensity score weights. Statistics Medicine. 2024;43(13):2672–2694. doi:10.1002/sim.10078","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability Weighted Estimation — ipw","text":"","code":"# Simulate data with a confounder, binary exposure, and binary outcome set.seed(123) n <- 200 x1 <- rnorm(n) z <- rbinom(n, 1, plogis(0.5 * x1)) y <- rbinom(n, 1, plogis(-0.5 + 0.8 * z + 0.3 * x1)) dat <- data.frame(x1, z, y)  # Step 1: Fit a propensity score model ps_mod <- glm(z ~ x1, data = dat, family = binomial())  # Step 2: Calculate ATE weights and fit a weighted outcome model wts <- wt_ate(ps_mod) #> ℹ Using exposure variable \"z\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 outcome_mod <- glm(y ~ z, data = dat, family = binomial(), weights = wts) #> Warning: non-integer #successes in a binomial glm!  # Step 3: Estimate causal effects with correct standard errors result <- ipw(ps_mod, outcome_mod) result #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: glm(formula = y ~ z, family = binomial(), data = dat, weights = wts)  #>  #> Estimates: #>         estimate std.err       z ci.lower ci.upper conf.level   p.value     #> rd       0.14230 0.07038 2.02194   0.0044  0.28025       0.95 0.0431831 *   #> log(rr)  0.28031 0.10770 2.60262   0.0692  0.49141       0.95 0.0092513 **  #> log(or)  0.57339 0.16200 3.53950   0.2559  0.89090       0.95 0.0004009 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  # Exponentiate log-RR and log-OR to get RR and OR as.data.frame(result, exponentiate = TRUE) #>   effect  estimate   std.err        z    ci.lower  ci.upper conf.level #> 1     rd 0.1423042 0.0703802 2.021935 0.004361509 0.2802468       0.95 #> 2     rr 1.3235458 0.1077045 2.602624 1.071669109 1.6346215       0.95 #> 3     or 1.7742759 0.1619980 3.539503 1.291600480 2.4373286       0.95 #>        p.value #> 1 0.0431831009 #> 2 0.0092513440 #> 3 0.0004008815  # Continuous outcome example y_cont <- 2 + 0.8 * z + 0.3 * x1 + rnorm(n) dat$y_cont <- y_cont outcome_cont <- lm(y_cont ~ z, data = dat, weights = wts) ipw(ps_mod, outcome_cont) #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: lm(formula = y_cont ~ z, data = dat, weights = wts)  #>  #> Estimates: #>      estimate std.err       z ci.lower ci.upper conf.level   p.value     #> diff  0.90057 0.13695 6.57579   0.6322    1.169       0.95 4.839e-11 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if propensity scores are calibrated — is_ps_calibrated","title":"Check if propensity scores are calibrated — is_ps_calibrated","text":"is_ps_calibrated() tests whether x calibrated propensity score object (class ps_calib) psw object derived calibrated scores.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if propensity scores are calibrated — is_ps_calibrated","text":"","code":"is_ps_calibrated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if propensity scores are calibrated — is_ps_calibrated","text":"x object test.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if propensity scores are calibrated — is_ps_calibrated","text":"single TRUE FALSE.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if propensity scores are calibrated — is_ps_calibrated","text":"","code":"ps <- runif(100) exposure <- rbinom(100, 1, ps)  is_ps_calibrated(ps) #> [1] FALSE  calibrated <- ps_calibrate(ps, exposure, smooth = FALSE) #> ℹ Setting focal level to 1 is_ps_calibrated(calibrated) #> [1] TRUE"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether propensity scores have been trimmed — is_ps_trimmed","title":"Test whether propensity scores have been trimmed — is_ps_trimmed","text":"is_ps_trimmed() returns TRUE x ps_trim object psw object created trimmed propensity scores, FALSE otherwise. tests whether object carries trimming information, individual units trimmed; see is_unit_trimmed() .","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether propensity scores have been trimmed — is_ps_trimmed","text":"","code":"is_ps_trimmed(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether propensity scores have been trimmed — is_ps_trimmed","text":"x object test.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether propensity scores have been trimmed — is_ps_trimmed","text":"logical scalar (TRUE FALSE).","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether propensity scores have been trimmed — is_ps_trimmed","text":"","code":"ps <- c(0.05, 0.3, 0.6, 0.95) trimmed <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9)  is_ps_trimmed(trimmed) #> [1] TRUE is_ps_trimmed(ps) #> [1] FALSE"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether propensity scores have been truncated — is_ps_truncated","title":"Test whether propensity scores have been truncated — is_ps_truncated","text":"is_ps_truncated() returns TRUE x ps_trunc object psw object derived truncated propensity scores. Use is_unit_truncated() find observations modified.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether propensity scores have been truncated — is_ps_truncated","text":"","code":"is_ps_truncated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether propensity scores have been truncated — is_ps_truncated","text":"x object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether propensity scores have been truncated — is_ps_truncated","text":"single TRUE FALSE.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether propensity scores have been truncated — is_ps_truncated","text":"","code":"ps <- c(0.02, 0.3, 0.5, 0.7, 0.98) is_ps_truncated(ps) #> [1] FALSE  ps_t <- ps_trunc(ps, method = \"ps\", lower = 0.05, upper = 0.95) is_ps_truncated(ps_t) #> [1] TRUE"},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if propensity scores have been refit — is_refit","title":"Check if propensity scores have been refit — is_refit","text":"is_refit() tests whether x ps_trim object whose propensity model refit retained (non-trimmed) observations via ps_refit().","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if propensity scores have been refit — is_refit","text":"","code":"is_refit(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if propensity scores have been refit — is_refit","text":"x object test (typically ps_trim vector).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if propensity scores have been refit — is_refit","text":"single TRUE FALSE.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if propensity scores have been refit — is_refit","text":"","code":"set.seed(2) n <- 30 x <- rnorm(n) z <- rbinom(n, 1, plogis(0.4 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  trimmed <- ps_trim(ps, lower = 0.2, upper = 0.8) is_refit(trimmed) #> [1] FALSE  refit <- ps_refit(trimmed, fit) is_refit(refit) #> [1] TRUE"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify which units were trimmed — is_unit_trimmed","title":"Identify which units were trimmed — is_unit_trimmed","text":"is_unit_trimmed() returns logical vector indicating observations removed trimming. per-unit query, opposed is_ps_trimmed(), tests whether object trimmed .","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify which units were trimmed — is_unit_trimmed","text":"","code":"is_unit_trimmed(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify which units were trimmed — is_unit_trimmed","text":"x ps_trim object created ps_trim().","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify which units were trimmed — is_unit_trimmed","text":"logical vector length x, TRUE marks trimmed unit.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify which units were trimmed — is_unit_trimmed","text":"","code":"ps <- c(0.05, 0.3, 0.6, 0.95) trimmed <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9)  is_unit_trimmed(trimmed) #> [1]  TRUE FALSE FALSE  TRUE  # Use to subset data to retained observations kept <- !is_unit_trimmed(trimmed) ps[kept] #> [1] 0.3 0.6"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify which units were truncated — is_unit_truncated","title":"Identify which units were truncated — is_unit_truncated","text":"is_unit_truncated() returns logical vector indicating observations propensity scores modified truncation. Use is_ps_truncated() test whether object truncated .","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify which units were truncated — is_unit_truncated","text":"","code":"is_unit_truncated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify which units were truncated — is_unit_truncated","text":"x ps_trunc object created ps_trunc().","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify which units were truncated — is_unit_truncated","text":"logical vector length x (number rows matrix input). TRUE marks observations whose values winsorized.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify which units were truncated — is_unit_truncated","text":"","code":"ps <- c(0.02, 0.3, 0.5, 0.7, 0.98) ps_t <- ps_trunc(ps, method = \"ps\", lower = 0.05, upper = 0.95) is_unit_truncated(ps_t) #> [1]  TRUE FALSE FALSE FALSE  TRUE"},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":null,"dir":"Reference","previous_headings":"","what":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"propensity provides tools propensity score analysis causal inference. Calculate propensity score weights variety causal estimands, handle extreme propensity scores trimming, truncation, calibration, estimate causal effects inverse probability weighting. package supports binary, categorical, continuous exposures.","code":""},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"weight-functions","dir":"Reference","previous_headings":"","what":"Weight functions","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"Calculate propensity score weights different causal estimands: wt_ate(): Average treatment effect (ATE) weights wt_att(): Average treatment effect treated (ATT) weights wt_atu(): Average treatment effect untreated (ATU) weights (wt_atc() alias) wt_atm(): Average treatment effect evenly matchable (ATM) weights wt_ato(): Average treatment effect overlap population (ATO) weights wt_entropy(): Entropy balancing weights wt_cens(): Censoring weights","code":""},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"propensity-score-modifications","dir":"Reference","previous_headings":"","what":"Propensity score modifications","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"Handle extreme propensity scores calculating weights: ps_trim(): Trim observations extreme propensity scores ps_trunc(): Truncate (winsorize) extreme propensity scores ps_calibrate(): Calibrate propensity scores improve balance ps_refit(): Re-estimate propensity score model trimming","code":""},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"estimation","dir":"Reference","previous_headings":"","what":"Estimation","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"ipw(): Inverse probability weighted estimator variance estimation accounts propensity score estimation uncertainty","code":""},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"psw-class","dir":"Reference","previous_headings":"","what":"PSW class","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"psw() class represents propensity score weights metadata estimand modifications applied: psw(), as_psw(), is_psw(): Create test propensity score weights estimand(): Query causal estimand is_stabilized(): Check weights stabilized","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"Maintainer: Malcolm Barrett malcolmbarrett@gmail.com (ORCID) [copyright holder]","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate propensity scores — ps_calibrate","title":"Calibrate propensity scores — ps_calibrate","text":"ps_calibrate() adjusts estimated propensity scores better reflect true treatment probabilities. can improve accuracy inverse probability weights derived misspecified propensity score model.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate propensity scores — ps_calibrate","text":"","code":"ps_calibrate(   ps,   .exposure,   method = c(\"logistic\", \"isoreg\"),   smooth = TRUE,   .focal_level = NULL,   .reference_level = NULL,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate propensity scores — ps_calibrate","text":"ps numeric vector propensity scores 0 1. Must already calibrated. .exposure binary vector observed treatment assignments, length ps. method Calibration method. One : \"logistic\" (Default) Logistic calibration, also called Platt scaling. Fits logistic regression .exposure ps, yielding smooth, parametric correction. Works well small samples bias ps approximately monotone. \"isoreg\" Isotonic regression. Fits non-parametric, monotone step function. flexible logistic calibration makes distributional assumption, needs larger samples stable estimates. smooth Logical. method = \"logistic\", controls form calibration model. TRUE (default), fits GAM spline ps via mgcv::gam(); FALSE, fits simple logistic regression via stats::glm(). Ignored method = \"isoreg\". .focal_level value .exposure representing focal group (typically treated group). NULL (default), coding determined automatically. .reference_level value .exposure representing reference group (typically control group). NULL (default), coding determined automatically. .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate propensity scores — ps_calibrate","text":"ps_calib vector length ps. attribute ps_calib_meta stores calibration metadata (method whether smoothing applied). Use is_ps_calibrated() test whether object calibrated.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibrate propensity scores — ps_calibrate","text":"Calibration useful propensity score model correctly specified terms variable selection produces probabilities systematically high low. Unlike ps_trim() ps_trunc(), handle extreme scores removing bounding , calibration reshapes entire distribution scores. Choosing method: Use \"logistic\" (default) first choice. stable fast, smooth = TRUE option adds flexibility via spline. Use \"isoreg\" suspect non-smooth irregular relationship estimated true probabilities sufficiently large sample. calibrated scores returned ps_calib object, can passed directly weight functions wt_ate().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibrate propensity scores — ps_calibrate","text":"Platt, J. (1999). Probabilistic outputs support vector machines comparisons regularized likelihood methods. Advances Large Margin Classifiers, 61–74. Zadrozny, B., & Elkan, C. (2002). Transforming classifier scores accurate multiclass probability estimates. Proceedings Eighth ACM SIGKDD International Conference Knowledge Discovery Data Mining, 694–699. doi:10.1145/775047.775151","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate propensity scores — ps_calibrate","text":"","code":"# Simulate data set.seed(42) ps <- runif(200) exposure <- rbinom(200, 1, ps)  # Logistic calibration without smoothing (simple Platt scaling) cal <- ps_calibrate(ps, exposure, smooth = FALSE) #> ℹ Setting focal level to 1 cal #> <ps_calib[200]; method=logistic> #>  [1] 0.8768754 0.8875980 0.2784575 0.8280651 0.6675032 0.5319951 0.7570779 #>  [8] 0.1604955 0.6830053 0.7291950 #> # ... with 190 more values  # Use calibrated scores to calculate weights wt_ate(cal, exposure) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate; calibrated}[200]> #>   [1]  1.140413  1.126636  3.591212  1.207634  1.498120  1.879717  4.116546 #>   [8]  1.191179  1.464118  1.371375  1.855251  1.347954  1.128055  1.334694 #>  [15]  1.873492  1.124922  1.104636  1.176539  2.079333  2.376276  1.147607 #>  [22]  1.194797  1.099587  9.255849  1.150056  2.111273  1.625281  1.146443 #>  [29]  1.813578  1.202353  1.319373  1.227172  1.619236  1.407268 10.590004 #>  [36]  1.205271  1.105925  4.728705  1.145858  1.572381  1.595167  1.772408 #>  [43]  1.121790  1.106935  1.758141  1.115151  1.159179  1.502218  1.108219 #>  [50]  2.805228  1.480542  1.511163  1.649763  1.256712  1.122644  4.298055 #>  [57]  1.422451  1.226540  1.343593  2.112310  3.348883  1.102432  1.288466 #>  [64]  2.416129  1.189910  1.246501  3.775976  1.209850  3.548601  4.201312 #>  [71]  1.124970  1.196402  1.279265  1.945603  4.910192  1.347561  1.106196 #>  [78]  1.584041  1.899052  1.103132  1.658348  1.212932  1.541116  3.044056 #>  [85]  1.267491  1.715517  1.302617  1.155398  1.152281  1.421620  3.261444 #>  [92]  1.102497  1.269325  1.129032  1.133530  1.324601  3.084413  2.115670 #>  [99]  1.310064  1.553123  1.535242  1.280267  1.279501  1.621643  1.123516 #> [106]  1.112496  1.316044  1.325880  1.814291  1.103468  1.579973  5.960174 #> [113]  1.299399  1.835609  1.814183  2.237296  1.103041  2.877072  2.749961 #> [120]  5.782649  1.535360  1.687422  1.683636  1.634153  1.347076  2.564296 #> [127]  1.137578  1.112516  1.302365  3.946616  7.762300  1.594854  1.522340 #> [134]  1.126454  1.189213  1.663814  1.216527  1.173481  4.547330  1.541815 #> [141]  1.203794  1.148552  2.135436  1.263130  1.325454  1.220759  5.436839 #> [148]  1.122225  3.502822  5.892699  1.347525  1.460171  1.263813  1.637690 #> [155]  3.381630  1.267489  1.244673  1.117167  1.192109  1.416832  1.127966 #> [162]  2.314895  1.599584  4.917740  2.225077  1.235420  2.201430  3.245145 #> [169]  1.175468  1.242677  1.331237  1.691377  2.431857  1.949609  2.345311 #> [176]  6.186653  1.213263  1.626478  1.245416  4.622547  1.138312  1.178849 #> [183]  1.445244  1.340694  1.312530  4.276192  1.138410  5.051990  1.189997 #> [190]  1.388812  4.960086  1.257408  1.186110  1.186298  1.143134  1.130987 #> [197]  2.206125  6.802145  1.311197  1.328810  # Isotonic regression calibration cal_iso <- ps_calibrate(ps, exposure, method = \"isoreg\") #> ℹ Setting focal level to 1  if (rlang::is_installed(\"mgcv\")) {   # Logistic calibration with spline smoothing (default)   cal_smooth <- ps_calibrate(ps, exposure) } #> ℹ Setting focal level to 1"},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":null,"dir":"Reference","previous_headings":"","what":"Refit a Propensity Score Model on Retained Observations — ps_refit","title":"Refit a Propensity Score Model on Retained Observations — ps_refit","text":"Re-estimates propensity score model using observations retained trimming. recommended intermediate step ps_trim() weight calculation (e.g. wt_ate()): ps_trim() -> ps_refit() -> wt_*() Trimming changes target population removing observations extreme propensity scores. Refitting model retained subset produces propensity scores better reflect population, improving model fit downstream weight estimation. Weight functions warn trimmed propensity score refit.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refit a Propensity Score Model on Retained Observations — ps_refit","text":"","code":"ps_refit(trimmed_ps, model, .data = NULL, ...)"},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refit a Propensity Score Model on Retained Observations — ps_refit","text":"trimmed_ps ps_trim object returned ps_trim(). model original fitted model used estimate propensity scores (e.g. glm multinom object). model refit via update() retained subset. .data data frame. NULL (default), data extracted model via model.frame(). ... Additional arguments passed update().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refit a Propensity Score Model on Retained Observations — ps_refit","text":"ps_trim object re-estimated propensity scores retained observations NA trimmed observations. Use is_refit() confirm refitting applied.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Refit a Propensity Score Model on Retained Observations — ps_refit","text":"","code":"set.seed(2) n <- 200 x <- rnorm(n) z <- rbinom(n, 1, plogis(0.4 * x))  # fit a propensity score model ps_model <- glm(z ~ x, family = binomial) ps <- predict(ps_model, type = \"response\")  # trim -> refit -> weight pipeline trimmed <- ps_trim(ps, lower = 0.1, upper = 0.9) refit <- ps_refit(trimmed, ps_model) wts <- wt_ate(refit, .exposure = z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  is_refit(refit) #> [1] TRUE"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim Propensity Scores — ps_trim","title":"Trim Propensity Scores — ps_trim","text":"Trim observations extreme propensity scores replacing NA, effectively removing units downstream analyses. returned object length (dimensions) input, trimmed entries set NA. trimming, refit propensity score model retained observations ps_refit().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim Propensity Scores — ps_trim","text":"","code":"ps_trim(   ps,   method = c(\"ps\", \"adaptive\", \"pctl\", \"pref\", \"cr\", \"optimal\"),   lower = NULL,   upper = NULL,   .exposure = NULL,   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim Propensity Scores — ps_trim","text":"ps numeric vector propensity scores (0, 1) binary exposures, matrix / data frame column gives propensity score one level categorical exposure. method Trimming method. One : \"ps\" (default): Fixed threshold. Observations propensity scores outside [lower, upper] trimmed. categorical exposures, observations column falls lower (symmetric threshold delta) trimmed. \"adaptive\": Data-driven threshold minimizes asymptotic variance IPW estimator (Crump et al., 2009). lower upper arguments ignored. \"pctl\": Quantile-based. Observations outside [lower, upper] quantiles propensity score distribution trimmed. Defaults: lower = 0.05, upper = 0.95. \"pref\": Preference score trimming. Transforms propensity scores preference scale (Walker et al., 2013) trims outside [lower, upper]. Requires .exposure. Binary exposures . Defaults: lower = 0.3, upper = 0.7. \"cr\": Common range (clinical equipoise). Trims overlap region propensity score distributions across exposure groups. Requires .exposure. Binary exposures . lower upper arguments ignored. \"optimal\": Multi-category optimal trimming (Yang et al., 2016). Categorical exposures . Requires .exposure. categorical exposures, \"ps\" \"optimal\" supported. lower, upper Numeric thresholds whose interpretation depends method: \"ps\": absolute propensity score bounds (defaults: 0.1, 0.9). categorical exposures, lower used symmetric threshold. \"pctl\": quantile probabilities (defaults: 0.05, 0.95). \"pref\": preference score bounds (defaults: 0.3, 0.7). \"adaptive\", \"cr\", \"optimal\": ignored (thresholds data-driven). .exposure exposure variable. Required \"pref\", \"cr\" (binary vector), \"optimal\" (factor character). required methods. .focal_level value .exposure representing focal (treated) group. binary exposures, defaults higher value. Required wt_att() wt_atu() categorical exposures. .reference_level value .exposure representing reference (control) group. Automatically detected supplied. ... Additional arguments passed methods. .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim Propensity Scores — ps_trim","text":"ps_trim object (numeric vector class \"ps_trim\", matrix class \"ps_trim_matrix\"). Trimmed observations NA. Metadata stored \"ps_trim_meta\" attribute can accessed ps_trim_meta(). Key fields include: method: trimming method used keep_idx: integer indices retained observations trimmed_idx: integer indices trimmed (NA) observations Method-specific fields cutoff (adaptive), q_lower/q_upper (pctl), cr_lower/cr_upper (cr), delta (categorical ps), lambda (optimal)","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"how-trimming-works","dir":"Reference","previous_headings":"","what":"How trimming works","title":"Trim Propensity Scores — ps_trim","text":"Trimming identifies observations extreme (near 0 1) propensity scores sets NA. observations excluded subsequent weight calculations effect estimation. goal remove units lack sufficient overlap exposure groups, otherwise receive extreme weights destabilize estimates.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"choosing-a-method","dir":"Reference","previous_headings":"","what":"Choosing a method","title":"Trim Propensity Scores — ps_trim","text":"Use \"ps\" specific threshold mind want simple default. Use \"adaptive\" principled, data-driven cutoff targets variance reduction. Use \"pctl\" trim fixed percentage extreme values tail. Use \"pref\" want restrict region clinical equipoise based preference score. Use \"cr\" restrict common support region exposure groups observed propensity scores. Use \"optimal\" multi-category (3+) exposures; data-driven method available categorical treatments.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"typical-workflow","dir":"Reference","previous_headings":"","what":"Typical workflow","title":"Trim Propensity Scores — ps_trim","text":"Fit propensity score model Apply ps_trim() flag extreme values Call ps_refit() re-estimate propensity scores retained sample Compute weights wt_ate() another weight function","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"object-behavior","dir":"Reference","previous_headings":"","what":"Object behavior","title":"Trim Propensity Scores — ps_trim","text":"Arithmetic operations ps_trim objects return plain numeric vectors, since transformed propensity scores (e.g., 1/ps) longer propensity scores. Trimmed values propagate NA calculations; use na.rm = TRUE appropriate. combining ps_trim objects c(), trimming parameters must match. Mismatched parameters trigger warning return numeric vector. Use ps_trim_meta() inspect trimming metadata, including method, cutoffs, observations retained trimmed.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trim Propensity Scores — ps_trim","text":"Crump, R. K., Hotz, V. J., Imbens, G. W., & Mitnik, O. . (2009). Dealing limited overlap estimation average treatment effects. Biometrika, 96(1), 187–199. Walker, . M., Patrick, . R., Lauer, M. S., et al. (2013). tool assessing feasibility comparative effectiveness research. Comparative Effectiveness Research, 3, 11–20. Yang, S., Imbens, G. W., Cui, Z., Faries, D. E., & Kadziola, Z. (2016). Propensity score matching subclassification observational studies multi-level treatments. Biometrics, 72(4), 1055–1065.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim Propensity Scores — ps_trim","text":"","code":"set.seed(2) n <- 300 x <- rnorm(n) z <- rbinom(n, 1, plogis(1.3 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  # Fixed threshold trimming (default) trimmed <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9) trimmed #> <ps_trim; trimmed 44 of [300]> #>         1         2         3         4         5         6         7         8  #> 0.1780112 0.4934483 0.8725819 0.1353577 0.4025855 0.4752489 0.6683913 0.3506150  #>         9        10        11        12        13        14        15        16  #>        NA 0.3831809 0.5738044 0.7467782 0.3038553 0.1508037 0.8997256        NA  #>        17        18        19        20        21        22        23        24  #> 0.7187207 0.4419184 0.7548592 0.5787647        NA 0.1244366 0.8728587        NA  #>        25        26        27        28        29        30        31        32  #> 0.4313639        NA 0.5939254 0.2474276 0.6938170 0.5298266 0.6778670 0.5399668  #>        33        34        35        36        37        38        39        40  #> 0.7707828 0.3366773 0.2037945 0.2476600        NA 0.1768609 0.2572600 0.3484614  #>        41        42        43        44        45        46        47        48  #> 0.3065403        NA 0.1895191        NA 0.6415565        NA 0.3300895 0.3990495  #>        49        50        51        52        53        54        55        56  #> 0.3683877 0.1246121 0.1902500        NA 0.2564150 0.8160957 0.1494022        NA  #>        57        58        59        60        61        62        63        64  #> 0.3247367 0.7345271 0.7859021 0.8849770        NA        NA 0.2208817 0.4841803  #>        65        66        67        68        69        70        71        72  #> 0.6036086 0.1941979        NA 0.2790100 0.4585602 0.1783019 0.1731103 0.5439312  #>        73        74        75        76        77        78        79        80  #> 0.3822372 0.5796397 0.4114856 0.1759469 0.8218240 0.6877562 0.7649259        NA  #>        81        82        83        84        85        86        87        88  #> 0.7505008        NA 0.2641422 0.1005949        NA        NA 0.2330120 0.3365148  #>        89        90        91        92        93        94        95        96  #> 0.3055473 0.5632496 0.8745082 0.8863194 0.1269292 0.1023453        NA 0.1166039  #>        97        98        99       100       101       102       103       104  #>        NA 0.4322875 0.1893249 0.2462384 0.7703638 0.5197606 0.3273939 0.2099624  #>       105       106       107       108       109       110       111       112  #> 0.1851823        NA 0.7356255        NA 0.2954896 0.3163021 0.1530042 0.3471981  #>       113       114       115       116       117       118       119       120  #> 0.5921212 0.8328274 0.6227067 0.5867797 0.8065734 0.7877456 0.4663064 0.2023006  #>       121       122       123       124       125       126       127       128  #> 0.8087856 0.4774812 0.8903829 0.2928150 0.1499937 0.6139848 0.2290136 0.6467536  #>       129       130       131       132       133       134       135       136  #>        NA        NA 0.6627758 0.5441083 0.7165979        NA 0.8025574 0.7998822  #>       137       138       139       140       141       142       143       144  #> 0.7597742 0.6921037        NA        NA 0.2509264 0.5711077 0.1970442 0.4590332  #>       145       146       147       148       149       150       151       152  #> 0.6800801 0.2329425 0.6525433 0.6180388 0.1970997 0.1584870 0.7452343 0.3731672  #>       153       154       155       156       157       158       159       160  #> 0.6727629 0.1889404 0.8164247 0.1043218 0.6858279 0.5895482 0.5223260 0.6558189  #>       161       162       163       164       165       166       167       168  #> 0.5672709 0.2368400 0.3418011 0.5540597 0.1083159 0.1806594        NA        NA  #>       169       170       171       172       173       174       175       176  #> 0.1187105 0.7490531 0.7738375 0.7077039 0.4491471 0.5416643 0.1764396 0.2333126  #>       177       178       179       180       181       182       183       184  #> 0.3434474 0.1704628 0.7023006        NA 0.1524604 0.1153463 0.5651259 0.1351849  #>       185       186       187       188       189       190       191       192  #> 0.6161453 0.7945146 0.4382952 0.6065642 0.2328341 0.6027459 0.1139088 0.4037497  #>       193       194       195       196       197       198       199       200  #> 0.1040353 0.3422376 0.7735701 0.6661116 0.2893391 0.2011360 0.1863223 0.2107038  #>       201       202       203       204       205       206       207       208  #> 0.5327159 0.1544197        NA 0.5052145 0.1642856 0.5622725 0.3887452 0.3163883  #>       209       210       211       212       213       214       215       216  #> 0.6341619 0.5095796 0.7582940 0.2665601        NA        NA 0.4774214 0.5852567  #>       217       218       219       220       221       222       223       224  #> 0.8030404 0.1067663 0.1338595 0.8855459 0.5671613 0.6707177 0.2000938        NA  #>       225       226       227       228       229       230       231       232  #> 0.4538222 0.5912550 0.3993802 0.7230688 0.3094663        NA 0.8702859        NA  #>       233       234       235       236       237       238       239       240  #> 0.2415827 0.4195113        NA 0.1483657 0.2541910 0.5957602 0.4626159 0.2496911  #>       241       242       243       244       245       246       247       248  #> 0.4020747        NA 0.7936546 0.6179515 0.6899355 0.2556513 0.4650462 0.5270157  #>       249       250       251       252       253       254       255       256  #> 0.2803714 0.2850014 0.6020472 0.3002118 0.3705819 0.3257820 0.7087374 0.5960756  #>       257       258       259       260       261       262       263       264  #> 0.3306472 0.3363861 0.7464321 0.3725508 0.8297224 0.3965473 0.3250342        NA  #>       265       266       267       268       269       270       271       272  #> 0.2345937        NA        NA 0.5886632 0.6106387 0.4172303        NA 0.4137080  #>       273       274       275       276       277       278       279       280  #> 0.4312953 0.1206438 0.5164038 0.8752400 0.4176263 0.7591012 0.3016993 0.4527210  #>       281       282       283       284       285       286       287       288  #>        NA 0.6501483 0.8168531 0.2393292 0.8311549 0.8851143 0.7936328 0.4317872  #>       289       290       291       292       293       294       295       296  #> 0.8222307 0.3983355 0.1356224 0.6302455 0.4602807 0.3527491 0.8562989 0.3153233  #>       297       298       299       300  #> 0.5741435        NA 0.1008201 0.2253829   # How many observations were trimmed? sum(is_unit_trimmed(trimmed)) #> [1] 44  # Data-driven adaptive trimming ps_trim(ps, method = \"adaptive\") #> <ps_trim; trimmed 44 of [300]> #>         1         2         3         4         5         6         7         8  #> 0.1780112 0.4934483 0.8725819 0.1353577 0.4025855 0.4752489 0.6683913 0.3506150  #>         9        10        11        12        13        14        15        16  #>        NA 0.3831809 0.5738044 0.7467782 0.3038553 0.1508037 0.8997256        NA  #>        17        18        19        20        21        22        23        24  #> 0.7187207 0.4419184 0.7548592 0.5787647        NA 0.1244366 0.8728587        NA  #>        25        26        27        28        29        30        31        32  #> 0.4313639        NA 0.5939254 0.2474276 0.6938170 0.5298266 0.6778670 0.5399668  #>        33        34        35        36        37        38        39        40  #> 0.7707828 0.3366773 0.2037945 0.2476600        NA 0.1768609 0.2572600 0.3484614  #>        41        42        43        44        45        46        47        48  #> 0.3065403        NA 0.1895191        NA 0.6415565        NA 0.3300895 0.3990495  #>        49        50        51        52        53        54        55        56  #> 0.3683877 0.1246121 0.1902500        NA 0.2564150 0.8160957 0.1494022        NA  #>        57        58        59        60        61        62        63        64  #> 0.3247367 0.7345271 0.7859021 0.8849770        NA        NA 0.2208817 0.4841803  #>        65        66        67        68        69        70        71        72  #> 0.6036086 0.1941979        NA 0.2790100 0.4585602 0.1783019 0.1731103 0.5439312  #>        73        74        75        76        77        78        79        80  #> 0.3822372 0.5796397 0.4114856 0.1759469 0.8218240 0.6877562 0.7649259        NA  #>        81        82        83        84        85        86        87        88  #> 0.7505008        NA 0.2641422 0.1005949        NA        NA 0.2330120 0.3365148  #>        89        90        91        92        93        94        95        96  #> 0.3055473 0.5632496 0.8745082 0.8863194 0.1269292 0.1023453        NA 0.1166039  #>        97        98        99       100       101       102       103       104  #>        NA 0.4322875 0.1893249 0.2462384 0.7703638 0.5197606 0.3273939 0.2099624  #>       105       106       107       108       109       110       111       112  #> 0.1851823        NA 0.7356255        NA 0.2954896 0.3163021 0.1530042 0.3471981  #>       113       114       115       116       117       118       119       120  #> 0.5921212 0.8328274 0.6227067 0.5867797 0.8065734 0.7877456 0.4663064 0.2023006  #>       121       122       123       124       125       126       127       128  #> 0.8087856 0.4774812 0.8903829 0.2928150 0.1499937 0.6139848 0.2290136 0.6467536  #>       129       130       131       132       133       134       135       136  #>        NA        NA 0.6627758 0.5441083 0.7165979        NA 0.8025574 0.7998822  #>       137       138       139       140       141       142       143       144  #> 0.7597742 0.6921037        NA        NA 0.2509264 0.5711077 0.1970442 0.4590332  #>       145       146       147       148       149       150       151       152  #> 0.6800801 0.2329425 0.6525433 0.6180388 0.1970997 0.1584870 0.7452343 0.3731672  #>       153       154       155       156       157       158       159       160  #> 0.6727629 0.1889404 0.8164247 0.1043218 0.6858279 0.5895482 0.5223260 0.6558189  #>       161       162       163       164       165       166       167       168  #> 0.5672709 0.2368400 0.3418011 0.5540597 0.1083159 0.1806594        NA        NA  #>       169       170       171       172       173       174       175       176  #> 0.1187105 0.7490531 0.7738375 0.7077039 0.4491471 0.5416643 0.1764396 0.2333126  #>       177       178       179       180       181       182       183       184  #> 0.3434474 0.1704628 0.7023006        NA 0.1524604 0.1153463 0.5651259 0.1351849  #>       185       186       187       188       189       190       191       192  #> 0.6161453 0.7945146 0.4382952 0.6065642 0.2328341 0.6027459 0.1139088 0.4037497  #>       193       194       195       196       197       198       199       200  #> 0.1040353 0.3422376 0.7735701 0.6661116 0.2893391 0.2011360 0.1863223 0.2107038  #>       201       202       203       204       205       206       207       208  #> 0.5327159 0.1544197        NA 0.5052145 0.1642856 0.5622725 0.3887452 0.3163883  #>       209       210       211       212       213       214       215       216  #> 0.6341619 0.5095796 0.7582940 0.2665601        NA        NA 0.4774214 0.5852567  #>       217       218       219       220       221       222       223       224  #> 0.8030404 0.1067663 0.1338595 0.8855459 0.5671613 0.6707177 0.2000938        NA  #>       225       226       227       228       229       230       231       232  #> 0.4538222 0.5912550 0.3993802 0.7230688 0.3094663        NA 0.8702859        NA  #>       233       234       235       236       237       238       239       240  #> 0.2415827 0.4195113        NA 0.1483657 0.2541910 0.5957602 0.4626159 0.2496911  #>       241       242       243       244       245       246       247       248  #> 0.4020747        NA 0.7936546 0.6179515 0.6899355 0.2556513 0.4650462 0.5270157  #>       249       250       251       252       253       254       255       256  #> 0.2803714 0.2850014 0.6020472 0.3002118 0.3705819 0.3257820 0.7087374 0.5960756  #>       257       258       259       260       261       262       263       264  #> 0.3306472 0.3363861 0.7464321 0.3725508 0.8297224 0.3965473 0.3250342        NA  #>       265       266       267       268       269       270       271       272  #> 0.2345937        NA        NA 0.5886632 0.6106387 0.4172303        NA 0.4137080  #>       273       274       275       276       277       278       279       280  #> 0.4312953 0.1206438 0.5164038 0.8752400 0.4176263 0.7591012 0.3016993 0.4527210  #>       281       282       283       284       285       286       287       288  #>        NA 0.6501483 0.8168531 0.2393292 0.8311549 0.8851143 0.7936328 0.4317872  #>       289       290       291       292       293       294       295       296  #> 0.8222307 0.3983355 0.1356224 0.6302455 0.4602807 0.3527491 0.8562989 0.3153233  #>       297       298       299       300  #> 0.5741435        NA 0.1008201 0.2253829   # Quantile-based trimming at 5th and 95th percentiles ps_trim(ps, method = \"pctl\") #> <ps_trim; trimmed 30 of [300]> #>          1          2          3          4          5          6          7  #> 0.17801124 0.49344831 0.87258189 0.13535765 0.40258554 0.47524889 0.66839132  #>          8          9         10         11         12         13         14  #> 0.35061504         NA 0.38318089 0.57380442 0.74677823 0.30385529 0.15080370  #>         15         16         17         18         19         20         21  #> 0.89972561         NA 0.71872070 0.44191837 0.75485924 0.57876473         NA  #>         22         23         24         25         26         27         28  #> 0.12443658 0.87285871         NA 0.43136394         NA 0.59392536 0.24742762  #>         29         30         31         32         33         34         35  #> 0.69381700 0.52982663 0.67786695 0.53996676 0.77078278 0.33667732 0.20379449  #>         36         37         38         39         40         41         42  #> 0.24766004         NA 0.17686094 0.25726004 0.34846140 0.30654026         NA  #>         43         44         45         46         47         48         49  #> 0.18951912 0.91394741 0.64155648         NA 0.33008953 0.39904946 0.36838768  #>         50         51         52         53         54         55         56  #> 0.12461207 0.19024995         NA 0.25641497 0.81609573 0.14940217         NA  #>         57         58         59         60         61         62         63  #> 0.32473671 0.73452714 0.78590206 0.88497697         NA         NA 0.22088166  #>         64         65         66         67         68         69         70  #> 0.48418025 0.60360857 0.19419787         NA 0.27900998 0.45856017 0.17830185  #>         71         72         73         74         75         76         77  #> 0.17311028 0.54393115 0.38223719 0.57963968 0.41148556 0.17594694 0.82182398  #>         78         79         80         81         82         83         84  #> 0.68775620 0.76492590 0.09594356 0.75050082 0.06658957 0.26414219 0.10059488  #>         85         86         87         88         89         90         91  #>         NA 0.90461881 0.23301201 0.33651483 0.30554734 0.56324964 0.87450818  #>         92         93         94         95         96         97         98  #> 0.88631941 0.12692921 0.10234530 0.08426251 0.11660386         NA 0.43228752  #>         99        100        101        102        103        104        105  #> 0.18932487 0.24623842 0.77036380 0.51976065 0.32739386 0.20996243 0.18518227  #>        106        107        108        109        110        111        112  #>         NA 0.73562548         NA 0.29548965 0.31630208 0.15300421 0.34719807  #>        113        114        115        116        117        118        119  #> 0.59212123 0.83282741 0.62270671 0.58677974 0.80657336 0.78774559 0.46630644  #>        120        121        122        123        124        125        126  #> 0.20230064 0.80878565 0.47748117 0.89038286 0.29281504 0.14999367 0.61398482  #>        127        128        129        130        131        132        133  #> 0.22901364 0.64675362 0.06419209         NA 0.66277576 0.54410827 0.71659793  #>        134        135        136        137        138        139        140  #>         NA 0.80255741 0.79988215 0.75977424 0.69210372         NA 0.09079429  #>        141        142        143        144        145        146        147  #> 0.25092645 0.57110768 0.19704419 0.45903320 0.68008008 0.23294255 0.65254331  #>        148        149        150        151        152        153        154  #> 0.61803876 0.19709968 0.15848705 0.74523426 0.37316715 0.67276290 0.18894043  #>        155        156        157        158        159        160        161  #> 0.81642474 0.10432180 0.68582789 0.58954824 0.52232604 0.65581895 0.56727085  #>        162        163        164        165        166        167        168  #> 0.23684003 0.34180113 0.55405967 0.10831585 0.18065940         NA         NA  #>        169        170        171        172        173        174        175  #> 0.11871049 0.74905308 0.77383752 0.70770386 0.44914706 0.54166428 0.17643958  #>        176        177        178        179        180        181        182  #> 0.23331263 0.34344738 0.17046280 0.70230062 0.07304003 0.15246043 0.11534630  #>        183        184        185        186        187        188        189  #> 0.56512587 0.13518488 0.61614535 0.79451459 0.43829517 0.60656419 0.23283410  #>        190        191        192        193        194        195        196  #> 0.60274592 0.11390882 0.40374970 0.10403526 0.34223762 0.77357008 0.66611156  #>        197        198        199        200        201        202        203  #> 0.28933909 0.20113598 0.18632231 0.21070377 0.53271587 0.15441973         NA  #>        204        205        206        207        208        209        210  #> 0.50521454 0.16428559 0.56227253 0.38874517 0.31638831 0.63416193 0.50957963  #>        211        212        213        214        215        216        217  #> 0.75829404 0.26656013 0.90146489 0.09307013 0.47742144 0.58525674 0.80304044  #>        218        219        220        221        222        223        224  #> 0.10676633 0.13385955 0.88554593 0.56716130 0.67071770 0.20009381 0.91614132  #>        225        226        227        228        229        230        231  #> 0.45382217 0.59125501 0.39938022 0.72306882 0.30946625         NA 0.87028588  #>        232        233        234        235        236        237        238  #>         NA 0.24158271 0.41951127 0.06438704 0.14836574 0.25419100 0.59576019  #>        239        240        241        242        243        244        245  #> 0.46261588 0.24969111 0.40207472         NA 0.79365463 0.61795146 0.68993549  #>        246        247        248        249        250        251        252  #> 0.25565132 0.46504618 0.52701568 0.28037136 0.28500140 0.60204716 0.30021180  #>        253        254        255        256        257        258        259  #> 0.37058188 0.32578201 0.70873738 0.59607558 0.33064721 0.33638608 0.74643214  #>        260        261        262        263        264        265        266  #> 0.37255079 0.82972242 0.39654734 0.32503416         NA 0.23459370 0.09722939  #>        267        268        269        270        271        272        273  #> 0.91692000 0.58866324 0.61063867 0.41723032         NA 0.41370803 0.43129530  #>        274        275        276        277        278        279        280  #> 0.12064385 0.51640377 0.87523995 0.41762629 0.75910122 0.30169925 0.45272098  #>        281        282        283        284        285        286        287  #>         NA 0.65014831 0.81685306 0.23932916 0.83115493 0.88511432 0.79363282  #>        288        289        290        291        292        293        294  #> 0.43178717 0.82223069 0.39833546 0.13562237 0.63024555 0.46028071 0.35274910  #>        295        296        297        298        299        300  #> 0.85629892 0.31532329 0.57414353         NA 0.10082012 0.22538288   # Refit after trimming, then compute weights trimmed <- ps_trim(ps, method = \"adaptive\") refitted <- ps_refit(trimmed, fit) wt_ate(refitted, .exposure = z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate; trimmed}[300]> #>   [1] 1.240579 2.058164 1.179439 1.179070 2.479678 2.130709 1.546037 1.552398 #>   [9]       NA 2.593380 2.268587 1.386216 1.455212 1.200838 1.140328       NA #>  [17] 3.272545 1.782675 1.371331 2.292253       NA 1.163991 1.179032       NA #>  [25] 2.328539       NA 1.731055 3.842912 1.490847 1.926820 1.525053 1.893076 #>  [33] 3.917615 2.914998 1.280093 1.352152       NA 1.238860 1.368835 1.547658 #>  [41] 1.460487       NA 4.876301       NA 2.643752       NA 2.967353 2.499634 #>  [49] 2.687495 1.164231 1.259096       NA 3.722181 1.266295 6.029169       NA #>  [57] 3.011351 1.409295 1.316469 1.161399       NA       NA 1.307391 1.913671 #>  [65] 1.704729 1.265160       NA 1.407989 1.832054 1.241014 1.233279 1.880192 #>  [73] 2.599182 1.771319 1.698883 5.210593 4.889604 2.985370 1.353148       NA #>  [81] 1.379326       NA 1.381016 1.131873       NA       NA 1.327354 1.521848 #>  [89] 3.180870 2.219879 1.176614 1.159464 1.167411 1.134197       NA 1.153324 #>  [97]       NA 1.755289 1.257681 1.349711 3.911330 2.040050 2.989342 1.289839 #> [105] 1.251377       NA 3.455793       NA 3.277919 1.479963 5.902359 1.544890 #> [113] 1.736044 1.239690 2.526861 1.750976 1.281806 1.313320 1.855984 1.277750 #> [121] 4.594831 1.891632 7.509198 1.433882 1.199683 2.476368 1.320718 2.678015 #> [129]       NA       NA 1.558717 1.879621 1.444250       NA 4.467031 1.292873 #> [137] 1.362404 1.494456       NA       NA 1.357789 1.796221 4.709750 1.833498 #> [145] 1.520225 1.327239 2.717307 1.666857 1.269646 1.211872 1.389090 1.603744 #> [153] 1.536293 4.889627 4.762739 1.136827 1.507810 1.743207 2.049824 2.740082 #> [161] 1.807638 1.333760 1.533168 2.179201 1.142162 1.244550       NA       NA #> [169] 7.402829 1.381999 1.337371 1.462140 2.244100 1.887538 1.238231 1.327856 #> [177] 2.863148 1.229363 3.113295       NA 1.203205 1.151622 2.228379 1.178829 #> [185] 2.488677 1.301856 1.772273 1.696843 1.327058 1.707044 1.149680 2.473178 #> [193] 1.136445 1.534110 3.959981 1.551162 1.427282 1.275928 4.950895 1.291019 #> [201] 1.917087 1.206013       NA 2.013803 1.220295 2.215480 1.641148 1.480137 #> [209] 2.596564 1.997821 1.365083 1.385341       NA       NA 2.121784 1.755278 #> [217] 4.476669 1.140089 1.176986 1.160579 1.807966 1.540838 1.274301       NA #> [225] 1.817720 1.738450 1.667666 1.431467 1.466275       NA 1.182816       NA #> [233] 3.925953 2.388469       NA 1.197366 3.751310 2.377394 1.844505 1.355652 #> [241] 2.482541       NA 1.303304 1.667082 3.003822 3.732130 1.852048 1.936381 #> [249] 3.436024 1.419123 2.410589 1.448110 2.673096 1.499338 3.173717 1.725144 #> [257] 1.509464 2.917273 1.386860 1.602298 1.244567 1.660522 1.497792       NA #> [265] 1.329995       NA       NA 2.341051 1.686081 1.714101       NA 1.704739 #> [273] 2.328877 7.296804 2.027404 1.175543 1.715160 1.363621 1.451002 1.814421 #> [281]       NA 1.587922 1.265073 1.337953 1.242313 1.161201 1.303341 1.753889 #> [289] 1.256446 2.503704 1.179438 2.572282 2.194293 1.557123 1.203649 1.477989 #> [297] 1.787285       NA 1.132171 1.314740"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract trimming metadata from a ps_trim object — ps_trim_meta","title":"Extract trimming metadata from a ps_trim object — ps_trim_meta","text":"ps_trim_meta() returns metadata list attached ps_trim object ps_trim().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract trimming metadata from a ps_trim object — ps_trim_meta","text":"","code":"ps_trim_meta(x)"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract trimming metadata from a ps_trim object — ps_trim_meta","text":"x ps_trim object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract trimming metadata from a ps_trim object — ps_trim_meta","text":"named list elements: method Character string indicating trimming method used. keep_idx Integer vector retained observation indices. trimmed_idx Integer vector trimmed observation indices. lower, upper Numeric cutoffs, applicable. refit Logical, TRUE model refit via ps_refit(). Additional method-specific elements (e.g. cutoff, delta, lambda) may also present.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract trimming metadata from a ps_trim object — ps_trim_meta","text":"","code":"ps <- c(0.05, 0.3, 0.6, 0.95) trimmed <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9)  ps_trim_meta(trimmed) #> $method #> [1] \"ps\" #>  #> $lower #> [1] 0.1 #>  #> $upper #> [1] 0.9 #>  #> $keep_idx #> [1] 2 3 #>  #> $trimmed_idx #> [1] 1 4 #>"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate (Winsorize) Propensity Scores — ps_trunc","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps_trunc() bounds extreme propensity scores fixed limits, replacing --range values boundary value (form winsorizing). result vector matrix length dimensions ps, observations removed. contrasts ps_trim(), sets extreme values NA (effectively removing observations analysis).","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"","code":"ps_trunc(   ps,   method = c(\"ps\", \"pctl\", \"cr\"),   lower = NULL,   upper = NULL,   .exposure = NULL,   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps numeric vector propensity scores 0 1 (binary exposures), matrix/data.frame column contains propensity scores one level categorical exposure. method One \"ps\", \"pctl\", \"cr\": \"ps\" (default): Truncate directly propensity score values. Values outside [lower, upper] set nearest bound. categorical exposures, applies symmetric truncation using lower threshold (delta) renormalizes rows sum 1. \"pctl\": Truncate quantiles propensity score distribution. lower upper arguments specify quantile probabilities. categorical exposures, quantiles computed across columns. \"cr\": Truncate common range propensity scores across exposure groups (binary exposures ). Bounds [min(ps[focal]), max(ps[reference])]. Requires .exposure. lower, upper Bounds truncation. Interpretation depends method: method = \"ps\": Propensity score values (defaults: 0.1 0.9). categorical exposures, lower truncation threshold delta (default: 0.01); upper ignored. method = \"pctl\": Quantile probabilities (defaults: 0.05 0.95; categorical defaults: 0.01 0.99). method = \"cr\": Ignored; bounds determined data. .exposure exposure vector. Required method \"cr\" (binary exposure vector) categorical exposures (factor character vector) method. .focal_level value .exposure representing focal (treated) group. binary exposures, defaults higher value. Required wt_att() wt_atu() categorical exposures. .reference_level value .exposure representing reference (control) group. Automatically detected supplied. ... Additional arguments passed methods. .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps_trunc object (numeric vector binary exposures, matrix categorical exposures). Use ps_trunc_meta() inspect metadata including method, lower_bound, upper_bound, truncated_idx (positions modified values).","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"Unlike ps_trim(), truncation preserves observations. NA values introduced; --range scores replaced boundary value. binary exposures, propensity score \\(e_i\\) bounded: \\(e_i < l\\), set \\(e_i = l\\) (lower bound). \\(e_i > u\\), set \\(e_i = u\\) (upper bound). categorical exposures, values threshold set threshold row renormalized sum 1. Arithmetic behavior: Arithmetic operations ps_trunc objects return plain numeric vectors. propensity scores transformed (e.g., weights), result longer propensity score. Combining behavior: Combining ps_trunc objects c() requires matching truncation parameters. Mismatched parameters produce warning return plain numeric vector.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"Crump, R. K., Hotz, V. J., Imbens, G. W., & Mitnik, O. . (2009). Dealing limited overlap estimation average treatment effects. Biometrika, 96(1), 187–199. Walker, . M., Patrick, . R., Lauer, M. S., et al. (2013). tool assessing feasibility comparative effectiveness research. Comparative Effectiveness Research, 3, 11–20.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"","code":"set.seed(2) n <- 200 x <- rnorm(n) z <- rbinom(n, 1, plogis(1.2 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  # Truncate to [0.1, 0.9] ps_t <- ps_trunc(ps, method = \"ps\", lower = 0.1, upper = 0.9) ps_t #> <ps_trunc{[0.1,0.9], method=ps}[200]> #>         1         2         3         4         5         6         7         8  #> 0.2913095 0.5707511 0.8590561 0.2418820 0.4993060 0.5567591 0.7011122 0.4561604  #>         9        10        11        12        13        14        15        16  #> 0.9000000 0.4834312 0.6312438 0.7594616 0.4153613 0.2603881 0.8827176 0.1000000  #>        17        18        19        20        21        22        23        24  #> 0.7384237 0.5307543 0.7655683 0.6349278 0.9000000 0.2283122 0.8592915 0.9000000  #>        25        26        27        28        29        30        31        32  #> 0.5224033 0.1000000 0.6461643 0.3628349 0.7199125 0.5983593 0.7081103 0.6059826  #>        33        34        35        36        37        38        39        40  #> 0.7776782 0.4442186 0.3189618 0.3630602 0.1432262 0.2900408 0.3722937 0.4543264  #>        41        42        43        44        45        46        47        48  #> 0.4177638 0.1148898 0.3038315 0.8956760 0.6813225 0.9000000 0.4385124 0.4964323  #>        49        50        51        52        53        54        55        56  #> 0.4711469 0.2285337 0.3046166 0.9000000 0.3714863 0.8128663 0.2587396 0.1141443  #>        57        58        59        60        61        62        63        64  #> 0.4338453 0.7502468 0.7892860 0.8697086 0.1351329 0.9000000 0.3365403 0.5636424  #>        65        66        67        68        69        70        71        72  #> 0.6533256 0.3088378 0.1105762 0.3927369 0.5438044 0.2916295 0.2858818 0.6089556  #>        73        74        75        76        77        78        79        80  #> 0.4826524 0.6355772 0.5065031 0.2890305 0.8174117 0.7154239 0.7732114 0.1906359  #>        81        82        83        84        85        86        87        88  #> 0.7622717 0.1472971 0.3788316 0.1970403 0.1000000 0.8871259 0.3486998 0.4440783  #>        89        90        91        92        93        94        95        96  #> 0.4168763 0.6233901 0.8606965 0.8708768 0.2314475 0.1994226 0.1740398 0.2183041  #>        97        98        99       100       101       102       103       104  #> 0.9000000 0.5231365 0.3036226 0.3616811 0.7773582 0.5907629 0.4361655 0.3253709  #>       105       106       107       108       109       110       111       112  #> 0.2991480 0.9000000 0.7510710 0.9000000 0.4078242 0.4264336 0.2629645 0.4532487  #>       113       114       115       116       117       118       119       120  #> 0.6448288 0.8262184 0.6674247 0.6408723 0.8053646 0.7907095 0.5498332 0.3173982  #>       121       122       123       124       125       126       127       128  #> 0.8071017 0.5584826 0.8744315 0.4053976 0.2594361 0.6609892 0.3447196 0.6851535  #>       129       130       131       132       133       134       135       136  #> 0.1434914 0.1410494 0.6969682 0.6090883 0.7368408 0.1087328 0.8022199 0.8001309  #>       137       138       139       140       141       142       143       144  #> 0.7692948 0.7186431 0.9000000 0.1834141 0.3662171 0.6292392 0.3118604 0.5441734  #>       145       146       147       148       149       150       151       152  #> 0.7097460 0.3486308 0.6894218 0.6639810 0.3119192 0.2693231 0.7582975 0.4751339  #>       153       154       155       156       157       158       159       160  #> 0.7043397 0.3032090 0.8131267 0.2020948 0.7139969 0.6429234 0.5927018 0.6918371  #>       161       162       163       164       165       166       167       168  #> 0.6263848 0.3524856 0.4486289 0.6165339 0.2074392 0.2942181 0.9000000 0.1003085  #>       169       170       171       172       173       174       175       176  #> 0.2210197 0.7611782 0.7800143 0.7302196 0.5364399 0.6072561 0.2895753 0.3489979  #>       177       178       179       180       181       182       183       184  #> 0.4500408 0.2829251 0.7262051 0.1573127 0.2623292 0.2166743 0.6247878 0.2416706  #>       185       186       187       188       189       190       191       192  #> 0.6625838 0.7959533 0.5278943 0.6555095 0.3485232 0.6526880 0.2148033 0.5002503  #>       193       194       195       196       197       198       199       200  #> 0.2017086 0.4490035 0.7798096 0.6994296 0.4022315 0.3161761 0.3003833 0.3261363   # Truncate at the 1st and 99th percentiles ps_trunc(ps, method = \"pctl\", lower = 0.01, upper = 0.99) #> <ps_trunc{[0.0900660672917143,0.912020808232711], method=pctl}[200]> #>          1          2          3          4          5          6          7  #> 0.29130945 0.57075108 0.85905610 0.24188201 0.49930600 0.55675915 0.70111217  #>          8          9         10         11         12         13         14  #> 0.45616038 0.90360175 0.48343119 0.63124383 0.75946160 0.41536130 0.26038808  #>         15         16         17         18         19         20         21  #> 0.88271762 0.09006607 0.73842370 0.53075430 0.76556830 0.63492785 0.91202081  #>         22         23         24         25         26         27         28  #> 0.22831221 0.85929151 0.90074563 0.52240328 0.09006607 0.64616425 0.36283492  #>         29         30         31         32         33         34         35  #> 0.71991248 0.59835929 0.70811028 0.60598256 0.77767823 0.44421858 0.31896179  #>         36         37         38         39         40         41         42  #> 0.36306016 0.14322616 0.29004079 0.37229372 0.45432638 0.41776382 0.11488981  #>         43         44         45         46         47         48         49  #> 0.30383148 0.89567605 0.68132246 0.90420941 0.43851237 0.49643227 0.47114693  #>         50         51         52         53         54         55         56  #> 0.22853370 0.30461661 0.91106441 0.37148631 0.81286633 0.25873963 0.11414425  #>         57         58         59         60         61         62         63  #> 0.43384531 0.75024682 0.78928598 0.86970860 0.13513287 0.90793306 0.33654034  #>         64         65         66         67         68         69         70  #> 0.56364237 0.65332558 0.30883775 0.11057616 0.39273691 0.54380444 0.29162947  #>         71         72         73         74         75         76         77  #> 0.28588182 0.60895559 0.48265241 0.63557725 0.50650310 0.28903045 0.81741170  #>         78         79         80         81         82         83         84  #> 0.71542388 0.77321135 0.19063586 0.76227170 0.14729713 0.37883165 0.19704028  #>         85         86         87         88         89         90         91  #> 0.09015377 0.88712592 0.34869977 0.44407832 0.41687627 0.62339015 0.86069650  #>         92         93         94         95         96         97         98  #> 0.87087680 0.23144748 0.19942258 0.17403983 0.21830407 0.90120123 0.52313647  #>         99        100        101        102        103        104        105  #> 0.30362260 0.36168114 0.77735817 0.59076288 0.43616553 0.32537093 0.29914802  #>        106        107        108        109        110        111        112  #> 0.90944557 0.75107099 0.90586644 0.40782418 0.42643359 0.26296452 0.45324867  #>        113        114        115        116        117        118        119  #> 0.64482877 0.82621843 0.66742471 0.64087231 0.80536462 0.79070955 0.54983317  #>        120        121        122        123        124        125        126  #> 0.31739822 0.80710169 0.55848264 0.87443145 0.40539762 0.25943605 0.66098916  #>        127        128        129        130        131        132        133  #> 0.34471960 0.68515350 0.14349137 0.14104940 0.69696824 0.60908833 0.73684079  #>        134        135        136        137        138        139        140  #> 0.10873282 0.80221987 0.80013088 0.76929476 0.71864309 0.91202081 0.18341413  #>        141        142        143        144        145        146        147  #> 0.36621714 0.62923918 0.31186040 0.54417339 0.70974601 0.34863085 0.68942181  #>        148        149        150        151        152        153        154  #> 0.66398099 0.31191915 0.26932313 0.75829753 0.47513393 0.70433975 0.30320896  #>        155        156        157        158        159        160        161  #> 0.81312672 0.20209485 0.71399686 0.64292343 0.59270175 0.69183710 0.62638476  #>        162        163        164        165        166        167        168  #> 0.35248559 0.44862887 0.61653394 0.20743922 0.29421813 0.91200893 0.10030845  #>        169        170        171        172        173        174        175  #> 0.22101971 0.76117824 0.78001428 0.73021961 0.53643993 0.60725607 0.28957526  #>        176        177        178        179        180        181        182  #> 0.34899794 0.45004081 0.28292513 0.72620510 0.15731275 0.26232917 0.21667429  #>        183        184        185        186        187        188        189  #> 0.62478778 0.24167062 0.66258378 0.79595325 0.52789428 0.65550948 0.34852324  #>        190        191        192        193        194        195        196  #> 0.65268801 0.21480329 0.50025030 0.20170859 0.44900347 0.77980959 0.69942959  #>        197        198        199        200  #> 0.40223149 0.31617609 0.30038326 0.32613630   # Use truncated scores to calculate weights wt_ate(ps_t, .exposure = z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate; truncated}[200]> #>   [1] 1.411053 2.329651 1.164068 1.319056 2.002780 2.256110 1.426305 1.838777 #>   [9] 1.111111 2.068547 2.711819 1.316722 1.710458 1.352060 1.132865 1.111111 #>  [17] 1.354236 1.884111 1.306219 2.739185 1.111111 1.295861 1.163749 1.111111 #>  [25] 2.093817 1.111111 1.547594 1.569452 1.389058 1.671237 1.412209 2.537959 #>  [33] 4.497985 1.799268 1.468346 2.754364 1.167169 3.447791 2.686051 1.832597 #>  [41] 2.393697 1.129803 3.291298 1.116475 1.467734 1.111111 2.280437 2.014373 #>  [49] 1.890884 1.296233 1.438056 1.111111 1.591055 1.230215 3.864889 1.128852 #>  [57] 1.766302 4.003953 4.745769 1.149810 7.400124 1.111111 1.507251 1.774175 #>  [65] 1.530630 3.237946 1.124323 2.546234 1.838896 1.411691 1.400328 1.642156 #>  [73] 1.932936 1.573373 1.974322 3.459843 1.223374 1.397773 1.293307 1.235538 #>  [81] 1.311868 1.172741 2.639695 1.245392 1.111111 1.127236 2.867797 1.798815 #>  [89] 2.398793 2.655268 1.161850 1.148268 1.301147 5.014477 1.210712 1.279270 #>  [97] 1.111111 2.097036 1.436003 1.566615 1.286408 1.692727 1.773570 1.482296 #> [105] 1.426835 1.111111 1.331432 1.111111 2.452037 2.345031 1.356787 1.828985 #> [113] 1.550799 1.210334 1.498296 1.560373 5.137812 1.264687 1.818733 3.150616 #> [121] 5.184079 1.790566 1.143600 2.466714 1.350322 1.512884 1.526064 3.176151 #> [129] 1.167531 7.089715 1.434786 2.558123 3.799981 1.121998 1.246541 1.249796 #> [137] 1.299892 1.391511 1.111111 5.452143 1.577827 2.697157 1.453194 2.193817 #> [145] 1.408955 1.535228 1.450491 2.976022 1.453318 3.713012 4.137318 1.905248 #> [153] 1.419769 1.435150 5.351220 1.253282 1.400566 1.555395 1.687189 3.245037 #> [161] 2.676550 1.544367 2.229014 1.621971 4.820689 1.416868 1.111111 1.111492 #> [169] 4.524483 1.313753 4.545750 1.369451 2.157218 2.546188 1.407609 2.865346 #> [177] 2.222021 1.394555 1.377021 1.186680 1.355618 1.276608 2.665158 1.318688 #> [185] 1.509243 1.256355 1.894319 1.525531 2.869249 2.879256 1.273566 2.001002 #> [193] 1.252675 1.814893 1.282364 3.327007 1.672888 1.462365 1.429354 1.483980  # Inspect which observations were truncated is_unit_truncated(ps_t) #>   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE #>  [13] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE #>  [25] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE #>  [49] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [61] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [85]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [97]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE #> [109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [133] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE #> [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE #> [169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","title":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","text":"Returns metadata list attached ps_trunc object. list includes fields method, lower_bound, upper_bound, truncated_idx.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","text":"","code":"ps_trunc_meta(x)"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","text":"x ps_trunc object created ps_trunc().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","text":"named list truncation metadata, including: method – truncation method used (\"ps\", \"pctl\", \"cr\") lower_bound, upper_bound – applied bounds truncated_idx – integer positions values winsorized","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract truncation metadata from a ps_trunc object — ps_trunc_meta","text":"","code":"ps <- c(0.02, 0.3, 0.5, 0.7, 0.98) ps_t <- ps_trunc(ps, method = \"ps\", lower = 0.05, upper = 0.95) ps_trunc_meta(ps_t) #> $method #> [1] \"ps\" #>  #> $lower_bound #> [1] 0.05 #>  #> $upper_bound #> [1] 0.95 #>  #> $truncated_idx #> [1] 1 5 #>"},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity Score Weight Vectors — psw","title":"Propensity Score Weight Vectors — psw","text":"psw objects numeric vectors carry metadata propensity score weights, including target estimand whether underlying propensity scores trimmed, truncated, calibrated. users encounter psw objects return values wt_ate() related weight functions. constructor helper functions useful inspecting weight objects package developers extending propensity.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity Score Weight Vectors — psw","text":"","code":"new_psw(   x = double(),   estimand = NULL,   stabilized = FALSE,   trimmed = FALSE,   truncated = FALSE,   calibrated = FALSE,   ... )  psw(   x = double(),   estimand = NULL,   stabilized = FALSE,   trimmed = FALSE,   truncated = FALSE,   calibrated = FALSE )  is_psw(x)  is_stabilized(wt)  is_causal_wt(x)  as_psw(x, estimand = NULL)  estimand(wt)  estimand(wt) <- value"},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity Score Weight Vectors — psw","text":"x psw() new_psw(): numeric vector weights (default: double()). is_psw(), is_causal_wt(), as_psw(): object test coerce. estimand character string identifying target estimand (e.g., \"ate\", \"att\", \"ato\"). Defaults NULL. stabilized Logical. weights stabilized? Defaults FALSE. trimmed Logical. weights derived trimmed propensity scores? Defaults FALSE. truncated Logical. weights derived truncated propensity scores? Defaults FALSE. calibrated Logical. weights derived calibrated propensity scores? Defaults FALSE. ... Additional attributes stored object (developer use ). wt psw causal_wts object. value character string: new estimand assign.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity Score Weight Vectors — psw","text":"new_psw(), psw(), as_psw(): psw vector. is_psw(), is_causal_wt(), is_stabilized(): single logical value. estimand(): character string, NULL estimand set. estimand<-: modified psw object (called side effect).","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"constructors","dir":"Reference","previous_headings":"","what":"Constructors","title":"Propensity Score Weight Vectors — psw","text":"psw() user-facing constructor. coerces x double validates inputs creating object. new_psw() low-level constructor intended developers. assumes x already double vector performs minimal validation. as_psw() coerces existing numeric vector psw object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"queries","dir":"Reference","previous_headings":"","what":"Queries","title":"Propensity Score Weight Vectors — psw","text":"is_psw() tests whether object psw vector. is_causal_wt() tests whether object inherits broader causal_wts class (includes psw objects). estimand() estimand<- get set estimand attribute. is_stabilized() returns TRUE weights stabilized.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"arithmetic-and-combining","dir":"Reference","previous_headings":"","what":"Arithmetic and combining","title":"Propensity Score Weight Vectors — psw","text":"Arithmetic operations psw objects preserve class attributes, operations like normalization (weights / sum(weights)) retain metadata. Combining psw objects c() preserves class metadata matches; mismatched metadata produces warning falls back plain numeric vector. Subsetting [ preserves class attributes. Summary functions (sum(), mean(), etc.) return plain numeric values.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Propensity Score Weight Vectors — psw","text":"","code":"# Create psw objects directly w <- psw(c(1.2, 0.8, 1.5), estimand = \"ate\") w #> <psw{estimand = ate}[3]> #> [1] 1.2 0.8 1.5  # Query metadata is_psw(w) #> [1] TRUE estimand(w) #> [1] \"ate\" is_stabilized(w) #> [1] FALSE  # Coerce a plain numeric vector as_psw(c(1.0, 2.0), estimand = \"att\") #> <psw{estimand = att}[2]> #> [1] 1 2  # Arithmetic preserves the psw class w / sum(w) #> <psw{estimand = ate}[3]> #> [1] 0.3428571 0.2285714 0.4285714  # Combining: compatible metadata is preserved x <- psw(c(1.2, 0.8), estimand = \"ate\") y <- psw(c(1.1, 0.9), estimand = \"ate\") c(x, y) #> <psw{estimand = ate}[4]> #> [1] 1.2 0.8 1.1 0.9  # Combining: incompatible metadata warns and returns numeric x <- psw(c(1.2, 0.8), estimand = \"ate\") y <- psw(c(1.1, 0.9), estimand = \"att\") c(x, y) #> Warning: Converting psw to numeric: incompatible estimands 'ate' and 'att' #> ℹ Metadata cannot be preserved when combining incompatible objects #> ℹ Use identical objects or explicitly cast to numeric to avoid this warning #> [1] 1.2 0.8 1.1 0.9"},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate propensity score weights — wt_ate","title":"Calculate propensity score weights — wt_ate","text":"Compute inverse probability weights causal inference different estimands. function targets different population: wt_ate(): Average Treatment Effect – full population. wt_att(): Average Treatment Effect Treated – treated (focal) group. wt_atu(): Average Treatment Effect Untreated – untreated (reference) group. wt_atc() alias. wt_atm(): Average Treatment Effect Evenly Matchable – units overlap. wt_ato(): Average Treatment Effect Overlap Population – weights proportional overlap. wt_entropy(): Entropy-weighted Average Treatment Effect – entropy-balanced population. wt_cens(): Inverse probability censoring weights – uses formula wt_ate() labels estimand \"uncensored\". Use adjust censoring survival analysis, treatment weighting. .propensity accepts numeric vector predicted probabilities, data.frame per-level probabilities, fitted glm object, modified propensity score created ps_trim(), ps_trunc(), ps_refit(), ps_calibrate(). functions return psw object – numeric vector tracks estimand, stabilization status, trimming truncation applied.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate propensity score weights — wt_ate","text":"","code":"wt_ate(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_ate(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_att(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_att(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atu(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_atu(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atm(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_atm(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_ato(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_ato(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_entropy(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_entropy(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atc(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  wt_cens(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_cens(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate propensity score weights — wt_ate","text":".propensity Propensity scores one several forms: numeric vector predicted probabilities (binary/continuous). data frame matrix one column per exposure level (categorical), two columns binary (see .propensity_col). fitted glm object – fitted values extracted automatically. modified propensity score created ps_trim(), ps_trunc(), ps_refit(), ps_calibrate(). .exposure exposure (treatment) variable. binary exposures, numeric 0/1 vector, logical, two-level factor. categorical exposures, factor character vector. continuous exposures, numeric vector. Optional .propensity glm object (extracted model). .sigma Numeric vector observation-level standard deviations continuous exposures (e.g., influence(model)$sigma). Extracted automatically .propensity glm object. exposure_type Type exposure: \"auto\" (default), \"binary\", \"categorical\", \"continuous\". \"auto\" detects type .exposure. .focal_level value .exposure representing focal (treated) group. binary exposures, defaults higher value. Required wt_att() wt_atu() categorical exposures. .reference_level value .exposure representing reference (control) group. Automatically detected supplied. stabilize TRUE, multiply weights estimate marginal treatment probability (binary) density (continuous). supported wt_ate() wt_cens(). See Stabilization Details. stabilization_score Optional numeric value use stabilization multiplier instead default (marginal mean .exposure). Ignored stabilize = FALSE. ... dots future extensions must empty. .treated Use .focal_level instead. .untreated Use .reference_level instead. .propensity_col Column use .propensity data frame binary exposure. Accepts column name (quoted unquoted) numeric index. Defaults second column. Ignored categorical exposures, columns used.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate propensity score weights — wt_ate","text":"psw vector (double vector class psw) carrying attributes: estimand: character, e.g. \"ate\", \"att\", \"uncensored\". stabilized: logical, whether stabilization applied. trimmed: logical, whether propensity scores trimmed. truncated: logical, whether propensity scores truncated. calibrated: logical, whether propensity scores calibrated.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"exposure-types","dir":"Reference","previous_headings":"","what":"Exposure types","title":"Calculate propensity score weights — wt_ate","text":"weight functions support binary exposures. wt_ate() wt_cens() also support continuous exposures. except wt_cens() support categorical exposures. Binary: .exposure two-level vector (e.g., 0/1, logical, two-level factor). .propensity numeric vector P(treatment | X). Categorical: .exposure factor character vector 3+ levels. .propensity must matrix data frame one column per level, rows sum 1. Continuous: .exposure numeric vector. .propensity vector conditional means (fitted values). Weights use normal density ratio; stabilization strongly recommended. Auto (default): Detects exposure type .exposure.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"stabilization","dir":"Reference","previous_headings":"","what":"Stabilization","title":"Calculate propensity score weights — wt_ate","text":"Setting stabilize = TRUE multiplies base weight estimate P() (binary) f_A() (continuous), reducing variance. stabilization_score supplied, marginal mean .exposure used. Stabilization supported ATE censoring weights (wt_ate() wt_cens()) strongly recommended continuous exposures.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"handling-extreme-weights","dir":"Reference","previous_headings":"","what":"Handling extreme weights","title":"Calculate propensity score weights — wt_ate","text":"Extreme weights signal positivity violations, poor model fit, limited overlap. can address : Choosing overlap-focused estimand (wt_ato(), wt_atm(), wt_entropy()), -weight units regions poor overlap. Trimming (ps_trim()) truncating (ps_trunc()) propensity scores computing weights. Calibrating weights ps_calibrate(). Stabilizing ATE weights (stabilize = TRUE). See halfmoon package weight diagnostics visualization.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"binary-exposures","dir":"Reference","previous_headings":"","what":"Binary exposures","title":"Calculate propensity score weights — wt_ate","text":"binary treatments (\\(\\\\{0, 1\\}\\)), propensity score \\(e(X) = P(=1 \\mid X)\\): ATE: \\(w = \\frac{}{e(X)} + \\frac{1-}{1-e(X)}\\) ATT: \\(w = + \\frac{(1-) \\cdot e(X)}{1-e(X)}\\) ATU: \\(w = \\frac{\\cdot (1-e(X))}{e(X)} + (1-)\\) ATM: \\(w = \\frac{\\min(e(X), 1-e(X))}{\\cdot e(X) + (1-) \\cdot (1-e(X))}\\) ATO: \\(w = \\cdot (1-e(X)) + (1-) \\cdot e(X)\\) Entropy: \\(w = \\frac{h(e(X))}{\\cdot e(X) + (1-) \\cdot (1-e(X))}\\), \\(h(e) = -[e \\log(e) + (1-e) \\log(1-e)]\\)","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"continuous-exposures","dir":"Reference","previous_headings":"","what":"Continuous exposures","title":"Calculate propensity score weights — wt_ate","text":"Weights use density ratio \\(w = f_A() / f_{|X}(\\mid X)\\), \\(f_A\\) marginal density \\(f_{|X}\\) conditional density (assumed normal). wt_ate() wt_cens() support continuous exposures.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"categorical-exposures","dir":"Reference","previous_headings":"","what":"Categorical exposures","title":"Calculate propensity score weights — wt_ate","text":"\\(K\\)-level treatments, weights take tilting-function form \\(w_i = h(\\mathbf{e}_i) / e_{,Z_i}\\), \\(e_{,Z_i}\\) propensity unit \\(\\)'s observed level \\(h(\\cdot)\\) depends estimand: ATE: \\(h(\\mathbf{e}) = 1\\) ATT: \\(h(\\mathbf{e}) = e_{\\text{focal}}\\) ATU: \\(h(\\mathbf{e}) = 1 - e_{\\text{focal}}\\) ATM: \\(h(\\mathbf{e}) = \\min(e_1, \\ldots, e_K)\\) ATO: \\(h(\\mathbf{e}) = \\bigl(\\sum_k 1/e_k\\bigr)^{-1}\\) Entropy: \\(h(\\mathbf{e}) = -\\sum_k e_k \\log(e_k)\\)","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate propensity score weights — wt_ate","text":"Barrett, M., D'Agostino McGowan, L., & Gerke, T. Causal Inference R. https://www.r-causal.org/ Rosenbaum, P. R., & Rubin, D. B. (1983). central role propensity score observational studies causal effects. Biometrika, 70(1), 41–55. Li, L., & Greene, T. (2013). weighting analogue pair matching propensity score analysis. International Journal Biostatistics, 9(2), 215–234. (ATM weights) Li, F., Morgan, K. L., & Zaslavsky, . M. (2018). Balancing covariates via propensity score weighting. Journal American Statistical Association, 113(521), 390–400. (ATO weights) Zhou, Y., Matsouaka, R. ., & Thomas, L. (2020). Propensity score weighting limited overlap model misspecification. Statistical Methods Medical Research, 29(12), 3721–3756. (Entropy weights) Hirano, K., & Imbens, G. W. (2004). propensity score continuous treatments. Applied Bayesian Modeling Causal Inference Incomplete-Data Perspectives (pp. 73–84). Austin, P. C., & Stuart, E. . (2015). Moving towards best practice using inverse probability treatment weighting (IPTW). Statistics Medicine, 34(28), 3661–3679.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate propensity score weights — wt_ate","text":"","code":"# -- Binary exposure, numeric propensity scores ---------------------- set.seed(123) ps <- runif(100, 0.1, 0.9) trt <- rbinom(100, 1, ps)  wt_ate(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate}[100]> #>   [1] 1.492675 1.368655 1.745754 5.165661 1.173194 7.328950 2.094172 1.228599 #>   [9] 1.847923 1.870179 7.433103 1.861044 1.557495 2.262990 1.223002 1.219720 #>  [17] 1.422212 7.482363 1.568225 1.157940 1.232086 1.528485 1.632905 1.116800 #>  [25] 1.601115 3.001420 1.868276 1.738182 1.495501 1.278267 1.148871 5.612908 #>  [33] 2.878230 3.793252 1.135965 2.073670 3.410265 3.661309 2.820518 1.399190 #>  [41] 1.272653 1.759439 1.757406 1.653101 4.505402 1.267499 1.401399 1.896705 #>  [49] 1.455134 1.271840 1.158299 1.830697 1.352924 1.246136 1.822296 1.360961 #>  [57] 1.253173 1.423191 1.225436 1.665474 1.582048 1.213405 2.455942 1.469523 #>  [65] 1.330297 1.847790 1.336806 1.333490 1.359668 1.824369 1.421302 1.657339 #>  [73] 3.013373 1.111729 2.082235 1.381397 1.677439 1.694293 2.621656 1.232906 #>  [81] 3.391031 1.576182 2.303524 1.368819 1.222930 1.811313 1.126170 1.227836 #>  [89] 5.240410 4.165936 1.257160 1.606473 2.667996 1.598960 2.806635 1.333605 #>  [97] 1.377723 1.211939 1.899058 2.037508 wt_att(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = att}[100]> #>   [1] 0.4926755 1.0000000 0.7457538 4.1656608 1.0000000 1.0000000 1.0941724 #>   [8] 1.0000000 1.0000000 0.8701789 6.4331026 0.8610445 1.0000000 1.2629898 #>  [15] 0.2230018 1.0000000 0.4222125 1.0000000 0.5682254 1.0000000 1.0000000 #>  [22] 1.0000000 1.0000000 1.0000000 1.0000000 2.0014200 1.0000000 1.0000000 #>  [29] 0.4955011 0.2782671 1.0000000 4.6129081 1.8782298 2.7932516 0.1359647 #>  [36] 1.0000000 2.4102647 1.0000000 1.0000000 0.3991897 0.2726533 0.7594392 #>  [43] 0.7574058 0.6531012 1.0000000 0.2674992 0.4013989 0.8967053 0.4551341 #>  [50] 1.0000000 0.1582988 0.8306973 1.0000000 0.2461361 1.0000000 0.3609610 #>  [57] 0.2531726 1.0000000 1.0000000 0.6654737 1.0000000 0.2134045 1.0000000 #>  [64] 0.4695226 1.0000000 0.8477904 1.0000000 1.0000000 1.0000000 0.8243692 #>  [71] 1.0000000 1.0000000 2.0133726 0.1117285 1.0000000 0.3813969 0.6774393 #>  [78] 1.0000000 1.0000000 0.2329063 1.0000000 1.0000000 1.0000000 1.0000000 #>  [85] 0.2229300 0.8113126 1.0000000 1.0000000 4.2404103 1.0000000 0.2571604 #>  [92] 1.0000000 1.0000000 1.0000000 1.0000000 0.3336052 1.0000000 0.2119390 #>  [99] 0.8990583 1.0375079 wt_atu(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = atu}[100]> #>   [1] 1.0000000 0.3686554 1.0000000 1.0000000 0.1731942 6.3289497 1.0000000 #>   [8] 0.2285990 0.8479233 1.0000000 1.0000000 1.0000000 0.5574953 1.0000000 #>  [15] 1.0000000 0.2197205 1.0000000 6.4823626 1.0000000 0.1579396 0.2320863 #>  [22] 0.5284847 0.6329051 0.1167996 0.6011153 1.0000000 0.8682760 0.7381824 #>  [29] 1.0000000 1.0000000 0.1488715 1.0000000 1.0000000 1.0000000 1.0000000 #>  [36] 1.0736701 1.0000000 2.6613092 1.8205180 1.0000000 1.0000000 1.0000000 #>  [43] 1.0000000 1.0000000 3.5054016 1.0000000 1.0000000 1.0000000 1.0000000 #>  [50] 0.2718404 1.0000000 1.0000000 0.3529239 1.0000000 0.8222956 1.0000000 #>  [57] 1.0000000 0.4231912 0.2254357 1.0000000 0.5820478 1.0000000 1.4559422 #>  [64] 1.0000000 0.3302967 1.0000000 0.3368064 0.3334905 0.3596676 1.0000000 #>  [71] 0.4213022 0.6573389 1.0000000 1.0000000 1.0822347 1.0000000 1.0000000 #>  [78] 0.6942927 1.6216558 1.0000000 2.3910308 0.5761821 1.3035242 0.3688192 #>  [85] 1.0000000 1.0000000 0.1261698 0.2278362 1.0000000 3.1659355 1.0000000 #>  [92] 0.6064733 1.6679958 0.5989600 1.8066347 1.0000000 0.3777228 1.0000000 #>  [99] 1.0000000 1.0000000 wt_atm(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = atm}[100]> #>   [1] 0.4926755 0.3686554 0.7457538 1.0000000 0.1731942 1.0000000 1.0000000 #>   [8] 0.2285990 0.8479233 0.8701789 1.0000000 0.8610445 0.5574953 1.0000000 #>  [15] 0.2230018 0.2197205 0.4222125 1.0000000 0.5682254 0.1579396 0.2320863 #>  [22] 0.5284847 0.6329051 0.1167996 0.6011153 1.0000000 0.8682760 0.7381824 #>  [29] 0.4955011 0.2782671 0.1488715 1.0000000 1.0000000 1.0000000 0.1359647 #>  [36] 1.0000000 1.0000000 1.0000000 1.0000000 0.3991897 0.2726533 0.7594392 #>  [43] 0.7574058 0.6531012 1.0000000 0.2674992 0.4013989 0.8967053 0.4551341 #>  [50] 0.2718404 0.1582988 0.8306973 0.3529239 0.2461361 0.8222956 0.3609610 #>  [57] 0.2531726 0.4231912 0.2254357 0.6654737 0.5820478 0.2134045 1.0000000 #>  [64] 0.4695226 0.3302967 0.8477904 0.3368064 0.3334905 0.3596676 0.8243692 #>  [71] 0.4213022 0.6573389 1.0000000 0.1117285 1.0000000 0.3813969 0.6774393 #>  [78] 0.6942927 1.0000000 0.2329063 1.0000000 0.5761821 1.0000000 0.3688192 #>  [85] 0.2229300 0.8113126 0.1261698 0.2278362 1.0000000 1.0000000 0.2571604 #>  [92] 0.6064733 1.0000000 0.5989600 1.0000000 0.3336052 0.3777228 0.2119390 #>  [99] 0.8990583 1.0000000 wt_ato(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ato}[100]> #>   [1] 0.3300620 0.2693559 0.4271815 0.8064139 0.1476262 0.8635548 0.5224844 #>   [8] 0.1860648 0.4588520 0.4652918 0.8654667 0.4626673 0.3579435 0.5581067 #>  [15] 0.1823397 0.1801400 0.2968702 0.8663524 0.3623366 0.1363971 0.1883685 #>  [22] 0.3457573 0.3875945 0.1045842 0.3754354 0.6668244 0.4647472 0.4246864 #>  [29] 0.3313278 0.2176909 0.1295806 0.8218392 0.6525642 0.7363739 0.1196909 #>  [36] 0.5177632 0.7067676 0.7268737 0.6454552 0.2853006 0.2142400 0.4316371 #>  [43] 0.4309795 0.3950764 0.7780442 0.2110449 0.2864273 0.4727700 0.3127781 #>  [50] 0.2137378 0.1366649 0.4537601 0.2608601 0.1975194 0.4512416 0.2652251 #>  [57] 0.2020253 0.2973537 0.1839637 0.3995702 0.3679078 0.1758725 0.5928243 #>  [64] 0.3195069 0.2482880 0.4588131 0.2519485 0.2500884 0.2645261 0.4518654 #>  [71] 0.2964199 0.3966231 0.6681459 0.1004998 0.5197467 0.2760951 0.4038532 #>  [78] 0.4097832 0.6185617 0.1889083 0.7051044 0.3655555 0.5658826 0.2694433 #>  [85] 0.1822917 0.4479142 0.1120344 0.1855591 0.8091752 0.7599579 0.2045566 #>  [92] 0.3775185 0.6251868 0.3745935 0.6437014 0.2501529 0.2741646 0.1748760 #>  [99] 0.4734232 0.5092044 wt_entropy(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = entropy}[100]> #>   [1] 0.9466884 0.7974021 1.1914845 2.5383087 0.4910630 2.9202760 1.4494516 #>   [8] 0.5903003 1.2746181 1.2917997 2.9354392 1.2847853 1.0158386 1.5532690 #>  [15] 0.5808315 0.5752272 0.8649741 2.9425314 1.0267968 0.4612870 0.5961433 #>  [22] 0.9855373 1.0902253 0.3741728 1.0595945 1.9101181 1.2903427 1.1850225 #>  [29] 0.9498151 0.6697735 0.4429918 2.6301699 1.8588898 2.1880067 0.4161138 #>  [36] 1.4360497 2.0632803 2.1467853 1.8339424 0.8365617 0.6611694 1.2030532 #>  [43] 1.2013433 1.1091726 2.3850345 0.6531902 0.8393281 1.3118818 0.9040828 #>  [50] 0.6599161 0.4620024 1.2611029 0.7765170 0.6192602 1.2544407 0.7872501 #>  [57] 0.6305931 0.8661618 0.5849629 1.1205924 1.0407229 0.5643262 1.6597604 #>  [64] 0.9206519 0.7455600 1.2745145 0.7545814 0.7499980 0.7855318 1.2560894 #>  [71] 0.8638679 1.1130997 1.9149498 0.3626234 1.4416708 0.8139569 1.1315051 #>  [78] 1.1466626 1.7427820 0.5975110 2.0565825 1.0348389 1.5766261 0.7976169 #>  [85] 0.5807093 1.2456605 0.3950015 0.5890166 2.5542633 2.2959657 0.6369461 #>  [92] 1.0648287 1.7647932 1.0574806 1.8278454 0.7501570 0.8092153 0.5617751 #>  [99] 1.3136430 1.4119476  # Stabilized ATE weights (reduces variance) wt_ate(ps, trt, stabilize = TRUE) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate; stabilized}[100]> #>   [1] 0.7612645 0.6706411 0.8903344 2.6344870 0.5748651 3.5911853 1.0680279 #>   [8] 0.6020135 0.9054824 0.9537912 3.7908823 0.9491327 0.7631727 1.1541248 #>  [15] 0.6237309 0.5976630 0.7253284 3.6663577 0.7997950 0.5673904 0.6037223 #>  [22] 0.7489575 0.8001235 0.5472318 0.7845465 1.5307242 0.9154552 0.8517094 #>  [29] 0.7627055 0.6519162 0.5629470 2.8625831 1.4678972 1.9345583 0.5793420 #>  [36] 1.0160984 1.7392350 1.7940415 1.3820538 0.7135867 0.6490532 0.8973140 #>  [43] 0.8962770 0.8430816 2.2076468 0.6464246 0.7147134 0.9673197 0.7421184 #>  [50] 0.6232018 0.5907324 0.9336556 0.6629327 0.6355294 0.8929248 0.6940901 #>  [57] 0.6391180 0.6973637 0.6004635 0.8493916 0.7752034 0.6188363 1.2034117 #>  [64] 0.7494566 0.6518454 0.9423731 0.6550351 0.6534103 0.6662371 0.9304283 #>  [71] 0.6964381 0.8120960 1.5368200 0.5669815 1.0202950 0.7045124 0.8554940 #>  [78] 0.8302034 1.2846113 0.6287822 1.6616051 0.7723292 1.1287269 0.6707214 #>  [85] 0.6236943 0.9237694 0.5518232 0.6016397 2.6726093 2.0413084 0.6411518 #>  [92] 0.7871719 1.3073180 0.7834904 1.3752510 0.6801387 0.6750841 0.6180889 #>  [99] 0.9685198 1.0391291  # Inspect the result w <- wt_ate(ps, trt) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 estimand(w) #> [1] \"ate\" summary(w) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.112   1.317   1.591   2.044   2.047   7.482   # -- Overlap-focused estimands handle extreme PS better -------------- ps_extreme <- c(0.01, 0.02, 0.98, 0.99, rep(0.5, 4)) trt_extreme <- c(0, 0, 1, 1, 0, 1, 0, 1)  max(wt_ate(ps_extreme, trt_extreme)) #> ℹ Treating `.exposure` as binary #> [1] 2 max(wt_ato(ps_extreme, trt_extreme)) #> ℹ Treating `.exposure` as binary #> [1] 0.5  # -- From a fitted GLM ----------------------------------------------- x1 <- rnorm(100) x2 <- rnorm(100) trt2 <- rbinom(100, 1, plogis(0.5 * x1 + 0.3 * x2)) ps_model <- glm(trt2 ~ x1 + x2, family = binomial)  # Exposure is extracted from the model automatically wt_ate(ps_model) #> ℹ Using exposure variable \"trt2\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate}[100]> #>   [1] 1.772299 2.816364 1.919886 2.059945 1.590514 2.019637 1.592626 3.675866 #>   [9] 1.731064 1.526937 2.194737 1.585679 1.604308 2.035997 1.836701 3.038426 #>  [17] 1.926720 2.527851 2.956648 1.456686 1.951071 2.308830 2.122857 1.859348 #>  [25] 1.333779 1.789153 2.089527 2.008161 1.809376 1.845397 1.236823 2.436497 #>  [33] 1.817852 2.352419 1.300776 1.637110 3.144659 2.924006 4.687625 1.406029 #>  [41] 2.396310 2.163061 2.510037 1.356974 1.430312 2.334509 3.102993 2.202745 #>  [49] 1.310198 1.607962 2.624988 2.535210 1.793952 1.647484 2.569296 2.061068 #>  [57] 3.046296 1.936586 1.517183 1.624578 2.826262 2.825176 1.554039 1.098856 #>  [65] 1.637046 1.507218 2.581387 1.554926 2.385541 1.698365 1.811373 1.670399 #>  [73] 1.760472 1.365580 1.911171 1.539045 2.208360 1.724933 1.617692 1.874702 #>  [81] 1.406166 3.813823 1.982021 2.553269 1.982884 1.957207 1.440986 1.560568 #>  [89] 1.603633 1.885138 1.584638 2.218637 1.630055 1.585865 1.872610 1.274698 #>  [97] 1.393716 1.394134 1.800220 1.778728  # -- Data frame input ------------------------------------------------ ps_df <- data.frame(   control = c(0.9, 0.7, 0.3, 0.1),   treated = c(0.1, 0.3, 0.7, 0.9) ) exposure <- c(0, 0, 1, 1) wt_ate(ps_df, exposure) #> ℹ Treating `.exposure` as binary #> ℹ Treating `.exposure` as binary #> <psw{estimand = ate}[4]> #> [1] 1.111111 1.428571 1.428571 1.111111 wt_ate(ps_df, exposure, .propensity_col = \"treated\") #> ℹ Treating `.exposure` as binary #> ℹ Treating `.exposure` as binary #> <psw{estimand = ate}[4]> #> [1] 1.111111 1.428571 1.428571 1.111111  # -- Censoring weights ----------------------------------------------- cens_ps <- runif(50, 0.6, 0.95) cens_ind <- rbinom(50, 1, cens_ps) wt_cens(cens_ps, cens_ind) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = uncensored}[50]> #>  [1] 1.116412 1.447081 1.644465 1.108844 1.394494 1.217840 1.263824 3.727943 #>  [9] 1.503634 1.333104 1.218367 1.278290 1.203561 1.169213 1.298047 1.361360 #> [17] 1.660049 1.663092 1.054599 2.760604 3.945306 1.174730 1.162941 1.104729 #> [25] 1.230385 1.156509 1.115406 1.227788 1.139434 2.551015 1.340626 1.103498 #> [33] 1.209817 1.082758 2.943590 1.407391 1.134443 1.056929 1.402849 2.502609 #> [41] 1.055677 1.533923 1.620017 1.235981 3.477837 1.274250 1.138436 1.602240 #> [49] 1.185878 1.072937 estimand(wt_cens(cens_ps, cens_ind))  # \"uncensored\" #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> [1] \"uncensored\""}]
