[{"path":"https://r-causal.github.io/propensity/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 propensity authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://r-causal.github.io/propensity/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Malcolm Barrett. Author, maintainer, copyright holder.","code":""},{"path":"https://r-causal.github.io/propensity/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Barrett M (2026). propensity: Toolkit Calculating Working Propensity Scores. R package version 0.0.0.9000, https://r-causal.github.io/propensity/.","code":"@Manual{,   title = {propensity: A Toolkit for Calculating and Working with Propensity Scores},   author = {Malcolm Barrett},   year = {2026},   note = {R package version 0.0.0.9000},   url = {https://r-causal.github.io/propensity/}, }"},{"path":"https://r-causal.github.io/propensity/index.html","id":"propensity-","dir":"","previous_headings":"","what":"A Toolkit for Calculating and Working with Propensity Scores","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"propensity provides comprehensive toolkit propensity score analysis causal inference. package supports multiple estimands, handles extreme weights, provides statistically valid inference inverse probability weighting.","code":""},{"path":"https://r-causal.github.io/propensity/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"can install propensity CRAN : can install development version propensity GitHub :","code":"install.packages(\"propensity\") # install.packages(\"devtools\") devtools::install_github(\"r-causal/propensity\")"},{"path":"https://r-causal.github.io/propensity/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"’s complete workflow causal effect estimation: ipw() function accounts uncertainty propensity score estimation, providing valid confidence intervals p-values.","code":"library(propensity)  # Simulate data with confounding n <- 200 x1 <- rnorm(n) x2 <- rnorm(n) treatment <- rbinom(n, 1, plogis(0.5 * x1 - 0.3 * x2)) outcome <- rbinom(n, 1, plogis(1 + 0.8 * treatment + 0.5 * x1 - 0.3 * x2))  # Fit propensity score model ps_model <- glm(treatment ~ x1 + x2, family = binomial())  # Calculate ATE weights wts <- wt_ate(ps_model) #> ℹ Using exposure variable \"treatment\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  # Fit weighted outcome model outcome_model <- glm(outcome ~ treatment, family = binomial(), weights = wts) #> Warning in eval(family$initialize): non-integer #successes in a binomial glm!  # Get causal effect estimates with correct standard errors ipw(ps_model, outcome_model) #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = treatment ~ x1 + x2, family = binomial())  #>  #> Outcome Model: #>   Call: glm(formula = outcome ~ treatment, family = binomial(), weights = wts)  #>  #> Estimates: #>         estimate  std.err        z ci.lower ci.upper conf.level p.value   #> rd      0.074863 0.051824 1.444570  -0.0267  0.17643       0.95 0.14858   #> log(rr) 0.091501 0.057897 1.580417  -0.0220  0.20498       0.95 0.11401   #> log(or) 0.510526 0.220945 2.310648   0.0775  0.94357       0.95 0.02085 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://r-causal.github.io/propensity/index.html","id":"multiple-estimands","dir":"","previous_headings":"","what":"Multiple Estimands","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"propensity supports six different causal estimands: Choose estimand based research question: - ATE: Effect entire population - ATT: Effect among received treatment - ATU/ATC: Effect among didn’t receive treatment - ATO: Effect population overlap (stable weights) - ATM: Effect matched population - Entropy: Balances efficiency overlap","code":"ps <- predict(ps_model, type = \"response\")  wt_ate(ps, treatment) # Average Treatment Effect #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate}[200]> #>   [1] 1.470779 2.068930 1.546098 1.232231 1.820995 2.024578 1.344924 1.495716 #>   [9] 2.217640 2.193364 1.715910 1.801797 3.732186 3.503668 1.438201 1.868097 #>  [17] 1.922443 2.079571 1.834538 1.332966 1.788833 1.633368 1.301630 1.821102 #>  [25] 1.679110 2.399182 1.380026 1.473493 1.646620 1.626722 1.424301 2.003376 #>  [33] 1.829952 2.225673 1.407329 1.988122 1.605516 1.623829 2.053488 2.510054 #>  [41] 1.423668 1.524282 1.829257 1.691047 1.471506 2.674584 1.327642 3.093271 #>  [49] 2.330734 2.314127 1.350606 3.005055 2.984867 1.478913 1.563689 2.809816 #>  [57] 1.749273 2.337510 3.332681 2.991772 1.998441 1.194681 2.024361 1.547311 #>  [65] 1.953848 4.967949 1.689181 5.093562 1.527294 2.021179 2.305803 3.698911 #>  [73] 2.485525 1.989953 2.271353 1.706920 1.366111 1.479168 1.772592 2.223966 #>  [81] 2.658169 1.821960 1.758813 1.696490 1.384585 2.399317 1.443507 2.021727 #>  [89] 1.469493 1.561712 2.461594 2.180753 1.155001 1.388714 1.393119 1.573849 #>  [97] 1.926909 1.468325 2.593163 3.977904 2.848188 1.725918 2.269394 1.532868 #> [105] 2.392849 1.597024 1.889476 1.570240 2.680789 1.761019 1.503138 1.645602 #> [113] 1.763572 1.555643 1.694603 2.026177 1.624535 2.699905 3.101536 2.510389 #> [121] 2.052995 1.734747 1.234539 1.280988 1.342521 1.605403 3.080384 1.793828 #> [129] 1.469570 1.578528 1.596617 2.192363 1.773740 2.232075 1.489021 1.628306 #> [137] 2.082229 1.185081 1.492569 1.837623 2.033960 1.496145 2.000751 2.623126 #> [145] 2.408770 1.798632 1.255588 1.251283 1.542644 1.578020 3.776381 2.103042 #> [153] 1.256482 2.269634 3.556495 1.559996 3.477468 1.977787 1.748482 1.361639 #> [161] 1.460139 1.393987 2.104371 1.910747 1.561723 1.791428 1.197745 1.937296 #> [169] 2.030522 2.190334 4.712759 3.362976 1.844335 3.292583 1.281848 2.475882 #> [177] 2.414548 1.127966 1.995835 2.294861 2.579686 4.774356 1.401574 2.426269 #> [185] 2.224822 1.553441 1.763196 2.352843 1.298357 1.918415 1.395278 1.801854 #> [193] 1.931121 1.862172 1.361941 1.992374 2.257764 1.521538 2.218199 1.578212 wt_att(ps, treatment) # Average Treatment Effect on the Treated #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = att}[200]> #>   [1] 0.4707789 1.0000000 1.0000000 0.2322311 1.0000000 1.0245778 0.3449241 #>   [8] 0.4957157 1.0000000 1.1933637 0.7159101 0.8017975 1.0000000 2.5036682 #>  [15] 1.0000000 0.8680975 0.9224426 1.0000000 0.8345383 1.0000000 0.7888328 #>  [22] 0.6333681 0.3016302 0.8211016 0.6791099 1.0000000 0.3800259 0.4734925 #>  [29] 1.0000000 0.6267215 1.0000000 1.0000000 1.0000000 1.0000000 0.4073285 #>  [36] 1.0000000 1.0000000 0.6238288 1.0000000 1.0000000 1.0000000 0.5242825 #>  [43] 1.0000000 0.6910469 0.4715061 1.0000000 0.3276415 1.0000000 1.0000000 #>  [50] 1.0000000 0.3506062 1.0000000 1.0000000 0.4789134 1.0000000 1.8098161 #>  [57] 1.0000000 1.3375095 2.3326810 1.0000000 1.0000000 1.0000000 1.0243608 #>  [64] 1.0000000 0.9538478 3.9679493 0.6891813 4.0935618 1.0000000 1.0000000 #>  [71] 1.3058033 1.0000000 1.0000000 1.0000000 1.2713535 1.0000000 0.3661107 #>  [78] 0.4791676 1.0000000 1.0000000 1.6581689 0.8219595 0.7588134 0.6964897 #>  [85] 1.0000000 1.3993170 1.0000000 1.0217275 1.0000000 0.5617123 1.0000000 #>  [92] 1.1807528 1.0000000 1.0000000 0.3931187 0.5738490 1.0000000 1.0000000 #>  [99] 1.5931634 2.9779037 1.8481879 1.0000000 1.2693943 0.5328683 1.0000000 #> [106] 1.0000000 0.8894758 0.5702399 1.6807891 0.7610191 0.5031375 0.6456016 #> [113] 0.7635718 1.0000000 1.0000000 1.0000000 0.6245350 1.0000000 2.1015358 #> [120] 1.5103891 1.0000000 0.7347466 1.0000000 1.0000000 1.0000000 1.0000000 #> [127] 1.0000000 0.7938279 0.4695699 1.0000000 1.0000000 1.0000000 0.7737400 #> [134] 1.2320755 0.4890211 1.0000000 1.0822290 0.1850811 1.0000000 1.0000000 #> [141] 1.0000000 1.0000000 1.0007510 1.0000000 1.4087699 0.7986321 1.0000000 #> [148] 1.0000000 1.0000000 1.0000000 2.7763806 1.0000000 1.0000000 1.0000000 #> [155] 2.5564948 1.0000000 1.0000000 0.9777871 0.7484818 0.3616386 0.4601392 #> [162] 0.3939866 1.0000000 1.0000000 1.0000000 0.7914278 1.0000000 0.9372959 #> [169] 1.0000000 1.0000000 3.7127593 2.3629759 0.8443348 1.0000000 1.0000000 #> [176] 1.0000000 1.0000000 1.0000000 1.0000000 1.2948611 1.0000000 3.7743558 #> [183] 1.0000000 1.0000000 1.2248219 1.0000000 1.0000000 1.0000000 1.0000000 #> [190] 0.9184152 0.3952778 1.0000000 1.0000000 0.8621715 1.0000000 1.0000000 #> [197] 1.2577643 0.5215382 1.2181988 0.5782116 wt_atu(ps, treatment) # Average Treatment Effect on the Untreated #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = atu}[200]> #>   [1] 1.0000000 1.0689304 0.5460976 1.0000000 0.8209947 1.0000000 1.0000000 #>   [8] 1.0000000 1.2176401 1.0000000 1.0000000 1.0000000 2.7321864 1.0000000 #>  [15] 0.4382010 1.0000000 1.0000000 1.0795713 1.0000000 0.3329662 1.0000000 #>  [22] 1.0000000 1.0000000 1.0000000 1.0000000 1.3991825 1.0000000 1.0000000 #>  [29] 0.6466199 1.0000000 0.4243007 1.0033757 0.8299522 1.2256735 1.0000000 #>  [36] 0.9881219 0.6055160 1.0000000 1.0534882 1.5100543 0.4236685 1.0000000 #>  [43] 0.8292569 1.0000000 1.0000000 1.6745844 1.0000000 2.0932708 1.3307338 #>  [50] 1.3141266 1.0000000 2.0050554 1.9848665 1.0000000 0.5636887 1.0000000 #>  [57] 0.7492731 1.0000000 1.0000000 1.9917719 0.9984414 0.1946807 1.0000000 #>  [64] 0.5473114 1.0000000 1.0000000 1.0000000 1.0000000 0.5272941 1.0211792 #>  [71] 1.0000000 2.6989113 1.4855253 0.9899526 1.0000000 0.7069204 1.0000000 #>  [78] 1.0000000 0.7725923 1.2239660 1.0000000 1.0000000 1.0000000 1.0000000 #>  [85] 0.3845848 1.0000000 0.4435067 1.0000000 0.4694926 1.0000000 1.4615940 #>  [92] 1.0000000 0.1550010 0.3887143 1.0000000 1.0000000 0.9269090 0.4683251 #>  [99] 1.0000000 1.0000000 1.0000000 0.7259181 1.0000000 1.0000000 1.3928486 #> [106] 0.5970239 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 #> [113] 1.0000000 0.5556430 0.6946028 1.0261769 1.0000000 1.6999054 1.0000000 #> [120] 1.0000000 1.0529954 1.0000000 0.2345394 0.2809878 0.3425212 0.6054034 #> [127] 2.0803840 1.0000000 1.0000000 0.5785281 0.5966166 1.1923627 1.0000000 #> [134] 1.0000000 1.0000000 0.6283059 1.0000000 1.0000000 0.4925693 0.8376227 #> [141] 1.0339600 0.4961454 1.0000000 1.6231258 1.0000000 1.0000000 0.2555875 #> [148] 0.2512830 0.5426442 0.5780203 1.0000000 1.1030419 0.2564823 1.2696343 #> [155] 1.0000000 0.5599957 2.4774683 1.0000000 1.0000000 1.0000000 1.0000000 #> [162] 1.0000000 1.1043710 0.9107475 0.5617230 1.0000000 0.1977453 1.0000000 #> [169] 1.0305221 1.1903341 1.0000000 1.0000000 1.0000000 2.2925834 0.2818475 #> [176] 1.4758820 1.4145480 0.1279665 0.9958348 1.0000000 1.5796862 1.0000000 #> [183] 0.4015740 1.4262688 1.0000000 0.5534408 0.7631955 1.3528431 0.2983569 #> [190] 1.0000000 1.0000000 0.8018540 0.9311206 1.0000000 0.3619412 0.9923737 #> [197] 1.0000000 1.0000000 1.0000000 1.0000000 wt_ato(ps, treatment) # Average Treatment Effect in Overlap population #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ato}[200]> #>   [1] 0.3200881 0.5166585 0.3532103 0.1884639 0.4508496 0.5060699 0.2564636 #>   [8] 0.3314237 0.5490702 0.5440793 0.4172189 0.4449987 0.7320605 0.7145848 #>  [15] 0.3046869 0.4646960 0.4798284 0.5191316 0.4549037 0.2497934 0.4409763 #>  [22] 0.3877681 0.2317326 0.4508818 0.4044464 0.5831914 0.2753759 0.3213403 #>  [29] 0.3926953 0.3852666 0.2979010 0.5008425 0.4535376 0.5506978 0.2894339 #>  [36] 0.4970127 0.3771473 0.3841715 0.5130238 0.6016022 0.2975893 0.3439536 #>  [43] 0.4533299 0.4086503 0.3204242 0.6261101 0.2467846 0.6767176 0.5709506 #>  [50] 0.5678715 0.2595917 0.6672274 0.6649766 0.3238279 0.3604865 0.6441048 #>  [57] 0.4283340 0.5721943 0.6999413 0.6657499 0.4996100 0.1629563 0.5060169 #>  [64] 0.3537177 0.4881894 0.7987097 0.4079972 0.8036737 0.3452472 0.5052393 #>  [71] 0.5663117 0.7296502 0.5976706 0.4974755 0.5597339 0.4141496 0.2679949 #>  [78] 0.3239441 0.4358545 0.5503528 0.6238012 0.4511404 0.4314348 0.4105476 #>  [85] 0.2777618 0.5832147 0.3072426 0.5053735 0.3194930 0.3596772 0.5937592 #>  [92] 0.5414427 0.1341999 0.2799095 0.2821861 0.3646150 0.4810341 0.3189519 #>  [99] 0.6143706 0.7486113 0.6488996 0.4205982 0.5593538 0.3476282 0.5820881 #> [106] 0.3738353 0.4707527 0.3631546 0.6269755 0.4321470 0.3347249 0.3923195 #> [113] 0.4329689 0.3571790 0.4098912 0.5064597 0.3844392 0.6296167 0.6775791 #> [120] 0.6016554 0.5129068 0.4235469 0.1899813 0.2193524 0.2551328 0.3771036 #> [127] 0.6753652 0.4425329 0.3195288 0.3664984 0.3736756 0.5438711 0.4362195 #> [134] 0.5519865 0.3284179 0.3858648 0.5197454 0.1561759 0.3300143 0.4558187 #> [141] 0.5083482 0.3316158 0.5001877 0.6187754 0.5848503 0.4440219 0.2035601 #> [148] 0.2008203 0.3517624 0.3662946 0.7351962 0.5244983 0.2041273 0.5594004 #> [155] 0.7188243 0.3589726 0.7124345 0.4943844 0.4280753 0.2655908 0.3151338 #> [162] 0.2826330 0.5247986 0.4766446 0.3596816 0.4417860 0.1650980 0.4838166 #> [169] 0.5075158 0.5434487 0.7878101 0.7026443 0.4577991 0.6962871 0.2198760 #> [176] 0.5961035 0.5858438 0.1134488 0.4989565 0.5642438 0.6123560 0.7905477 #> [183] 0.2865164 0.5878445 0.5505258 0.3562677 0.4328479 0.5749823 0.2297958 #> [190] 0.4787364 0.2832969 0.4450161 0.4821660 0.4629925 0.2657539 0.4980861 #> [197] 0.5570840 0.3427703 0.5491838 0.3663714 wt_atm(ps, treatment) # Average Treatment Effect in Matched population #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = atm}[200]> #>   [1] 0.4707789 1.0000000 0.5460976 0.2322311 0.8209947 1.0000000 0.3449241 #>   [8] 0.4957157 1.0000000 1.0000000 0.7159101 0.8017975 1.0000000 1.0000000 #>  [15] 0.4382010 0.8680975 0.9224426 1.0000000 0.8345383 0.3329662 0.7888328 #>  [22] 0.6333681 0.3016302 0.8211016 0.6791099 1.0000000 0.3800259 0.4734925 #>  [29] 0.6466199 0.6267215 0.4243007 1.0000000 0.8299522 1.0000000 0.4073285 #>  [36] 0.9881219 0.6055160 0.6238288 1.0000000 1.0000000 0.4236685 0.5242825 #>  [43] 0.8292569 0.6910469 0.4715061 1.0000000 0.3276415 1.0000000 1.0000000 #>  [50] 1.0000000 0.3506062 1.0000000 1.0000000 0.4789134 0.5636887 1.0000000 #>  [57] 0.7492731 1.0000000 1.0000000 1.0000000 0.9984414 0.1946807 1.0000000 #>  [64] 0.5473114 0.9538478 1.0000000 0.6891813 1.0000000 0.5272941 1.0000000 #>  [71] 1.0000000 1.0000000 1.0000000 0.9899526 1.0000000 0.7069204 0.3661107 #>  [78] 0.4791676 0.7725923 1.0000000 1.0000000 0.8219595 0.7588134 0.6964897 #>  [85] 0.3845848 1.0000000 0.4435067 1.0000000 0.4694926 0.5617123 1.0000000 #>  [92] 1.0000000 0.1550010 0.3887143 0.3931187 0.5738490 0.9269090 0.4683251 #>  [99] 1.0000000 1.0000000 1.0000000 0.7259181 1.0000000 0.5328683 1.0000000 #> [106] 0.5970239 0.8894758 0.5702399 1.0000000 0.7610191 0.5031375 0.6456016 #> [113] 0.7635718 0.5556430 0.6946028 1.0000000 0.6245350 1.0000000 1.0000000 #> [120] 1.0000000 1.0000000 0.7347466 0.2345394 0.2809878 0.3425212 0.6054034 #> [127] 1.0000000 0.7938279 0.4695699 0.5785281 0.5966166 1.0000000 0.7737400 #> [134] 1.0000000 0.4890211 0.6283059 1.0000000 0.1850811 0.4925693 0.8376227 #> [141] 1.0000000 0.4961454 1.0000000 1.0000000 1.0000000 0.7986321 0.2555875 #> [148] 0.2512830 0.5426442 0.5780203 1.0000000 1.0000000 0.2564823 1.0000000 #> [155] 1.0000000 0.5599957 1.0000000 0.9777871 0.7484818 0.3616386 0.4601392 #> [162] 0.3939866 1.0000000 0.9107475 0.5617230 0.7914278 0.1977453 0.9372959 #> [169] 1.0000000 1.0000000 1.0000000 1.0000000 0.8443348 1.0000000 0.2818475 #> [176] 1.0000000 1.0000000 0.1279665 0.9958348 1.0000000 1.0000000 1.0000000 #> [183] 0.4015740 1.0000000 1.0000000 0.5534408 0.7631955 1.0000000 0.2983569 #> [190] 0.9184152 0.3952778 0.8018540 0.9311206 0.8621715 0.3619412 0.9923737 #> [197] 1.0000000 0.5215382 1.0000000 0.5782116 wt_entropy(ps, treatment) # Entropy-weighted ATE #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = entropy}[200]> #>   [1] 0.9220840 1.4329248 1.0040533 0.5963850 1.2534049 1.4031812 0.7656995 #>   [8] 0.9500521 1.5264541 1.5117895 1.1657523 1.2379873 2.1691415 2.0951770 #>  [15] 0.8841821 1.2902059 1.3309708 1.4399263 1.2641332 0.7492711 1.2274314 #>  [22] 1.0906640 0.7046524 1.2534901 1.1330186 1.6296231 0.8121906 0.9251700 #>  [29] 1.1031341 1.0843459 0.8675064 1.3886314 1.2605140 1.5312585 0.8467108 #>  [36] 1.3780256 1.0638957 1.0815827 1.4226729 1.6876517 0.8667405 0.9810635 #>  [43] 1.2599641 1.1437625 0.9229121 1.7678830 0.7418530 1.9466539 1.5919964 #>  [50] 1.5826441 0.7733968 1.9115902 1.9033872 0.9313031 1.0221795 1.8292459 #>  [57] 1.1944730 1.5957865 2.0359817 1.9062006 1.3852134 0.5310830 1.4030334 #>  [64] 1.0053157 1.3537590 2.4948344 1.1420915 2.5226740 0.9842719 1.4008637 #>  [71] 1.5779228 2.1587086 1.6751071 1.3793047 1.5581345 1.1578610 0.7940577 #>  [78] 0.9315898 1.2140399 1.5302393 1.7601665 1.2541732 1.2025273 1.1486206 #>  [85] 0.8180500 1.6296956 0.8904655 1.4012379 0.9206176 1.0201609 1.6627110 #>  [92] 1.5040831 0.4554091 0.8233241 0.8289142 1.0324881 1.3342450 0.9192844 #>  [99] 1.7289991 2.2429634 1.8459823 1.1744602 1.5569969 0.9901809 1.6262016 #> [106] 1.0555775 1.3064505 1.0288395 1.7707839 1.2043797 0.9582116 1.1021817 #> [113] 1.2065190 1.0139335 1.1469392 1.4042697 1.0822580 1.7796680 1.9498761 #> [120] 1.6878219 1.4223439 1.1820755 0.6002279 0.6739112 0.7624234 1.0637858 #> [127] 1.9416087 1.2315124 0.9207058 1.0371968 1.0551767 1.5111800 1.2149925 #> [134] 1.5350702 0.9426286 1.0858559 1.4416671 0.5134648 0.9465707 1.2665596 #> [141] 1.4095501 0.9505266 1.3868148 1.7434879 1.6347794 1.2354209 0.6344463 #> [148] 0.6275654 1.0004522 1.0366869 2.1828304 1.4551922 0.6358694 1.5571363 #> [155] 2.1127724 1.0184038 2.0863331 1.3707728 1.1938019 0.7881489 0.9098812 #> [162] 0.8300116 1.4560495 1.3223439 1.0201717 1.2295537 0.5366230 1.3418163 #> [169] 1.4072212 1.5099437 2.4357601 2.0467310 1.2718185 2.0215720 0.6752144 #> [176] 1.6701309 1.6378739 0.3989231 1.3834029 1.5716810 1.7224115 2.4503434 #> [183] 0.8395471 1.6441210 1.5307503 1.0116635 1.2062039 1.6043095 0.6998526 #> [190] 1.3280088 0.8316416 1.2380331 1.3373221 1.2856536 0.7885499 1.3809936 #> [197] 1.5502166 0.9781299 1.5267890 1.0368790"},{"path":"https://r-causal.github.io/propensity/index.html","id":"flexible-input-formats","dir":"","previous_headings":"","what":"Flexible Input Formats","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"propensity accepts propensity scores multiple formats:","code":"# Numeric vector wt_ate(ps, treatment)  # Data frame (uses second column by default for treatment probability) ps_df <- data.frame(control = 1 - ps, treated = ps) wt_ate(ps_df, treatment)  # GLM object directly (extracts fitted values automatically) wt_ate(ps_model)"},{"path":"https://r-causal.github.io/propensity/index.html","id":"handling-extreme-weights","dir":"","previous_headings":"","what":"Handling Extreme Weights","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"Extreme propensity scores (near 0 1) can lead unstable weights. propensity offers several solutions: trimming, can refit propensity score model retained subset:","code":"# Check for extreme weights summary(wt_ate(ps, treatment)) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.128   1.527   1.811   1.999   2.238   5.094  # Solution 1: Use overlap-weighted estimand (bounded weights) summary(wt_ato(ps, treatment)) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.1134  0.3449  0.4479  0.4519  0.5533  0.8037  # Solution 2: Trim extreme propensity scores ps_trimmed <- ps_trim(ps, method = \"adaptive\") summary(wt_ate(ps_trimmed, treatment)) #> Warning in wt_ate(ps_trimmed, treatment): It appears you trimmed your propensity score but did not refit the model. #> ℹ Use `ps_refit()` for more accurate re-estimation. #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's  #>   1.155   1.530   1.821   2.003   2.245   5.094       1  # Solution 3: Truncate propensity scores ps_truncated <- ps_trunc(ps, lower = 0.05, upper = 0.95) summary(wt_ate(ps_truncated, treatment)) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.128   1.527   1.811   1.999   2.238   5.094  # Solution 4: Calibrate propensity scores ps_calibrated <- ps_calibrate(ps, treatment) #> ℹ Setting focal level to 1 summary(wt_ate(ps_calibrated, treatment)) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.185   1.510   1.797   1.999   2.268   4.771 ps_refitted <- ps_refit(ps_trimmed, ps_model) wts_refitted <- wt_ate(ps_refitted, treatment)"},{"path":[]},{"path":"https://r-causal.github.io/propensity/index.html","id":"weight-stabilization","dir":"","previous_headings":"Advanced Features","what":"Weight Stabilization","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"Stabilized weights can reduce variance ATE estimation:","code":"wt_ate(ps, treatment, stabilize = TRUE) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 #> <psw{estimand = ate; stabilized}[200]> #>   [1] 0.7206816 1.0551545 0.7885098 0.6037932 0.9287073 0.9920431 0.6590128 #>   [8] 0.7329007 1.1309964 1.0747482 0.8407960 0.8828808 1.9034151 1.7167974 #>  [15] 0.7334825 0.9153678 0.9419969 1.0605813 0.8989238 0.6798128 0.8765281 #>  [22] 0.8003504 0.6377988 0.8923398 0.8227638 1.2235831 0.6762127 0.7220113 #>  [29] 0.8397762 0.7970935 0.7263933 1.0217216 0.9332756 1.1350935 0.6895910 #>  [36] 1.0139422 0.8188132 0.7956761 1.0472790 1.2801277 0.7260709 0.7468984 #>  [43] 0.9329210 0.8286130 0.7210380 1.3640381 0.6505443 1.5775681 1.1886742 #>  [50] 1.1802046 0.6617970 1.5325783 1.5222819 0.7246675 0.7974812 1.3768099 #>  [57] 0.8921293 1.1453797 1.6330137 1.5258036 1.0192051 0.6092872 0.9919368 #>  [64] 0.7891288 0.9573854 2.4342952 0.8276989 2.4958453 0.7789200 1.0308014 #>  [71] 1.1298436 1.8864448 1.2676179 1.0148758 1.1129632 0.8705294 0.6693942 #>  [78] 0.7247921 0.9040221 1.1342227 1.3025028 0.8927602 0.8618185 0.8312800 #>  [85] 0.7061382 1.1756653 0.7361884 0.9906465 0.7494412 0.7652391 1.2554129 #>  [92] 1.0685689 0.5890505 0.7082443 0.6826282 0.7711860 0.9827236 0.7488458 #>  [99] 1.2706501 1.9491728 1.3956120 0.8802182 1.1120032 0.7511055 1.2203528 #> [106] 0.8144822 0.9258432 0.7694175 1.3135866 0.8628994 0.7365374 0.8063448 #> [113] 0.8641502 0.7933779 0.8642474 1.0333502 0.7960221 1.3769518 1.5197525 #> [120] 1.2300907 1.0470276 0.8500259 0.6296151 0.6533038 0.6846858 0.8187557 #> [127] 1.5709959 0.8789757 0.7200893 0.8050493 0.8142745 1.1181050 0.8691326 #> [134] 1.0937170 0.7296204 0.8304360 1.0202922 0.5806898 0.7612103 0.9371876 #> [141] 1.0373196 0.7630342 0.9803680 1.3377941 1.1802973 0.8813297 0.6403496 #> [148] 0.6381543 0.7867485 0.8047904 1.8504265 1.0725514 0.6408060 1.1575135 #> [155] 1.7426825 0.7955978 1.7735088 0.9691157 0.8567561 0.6672029 0.7154682 #> [162] 0.6830534 1.0732292 0.9744812 0.7964787 0.8777996 0.6108501 0.9492750 #> [169] 1.0355662 1.1170704 2.3092521 1.6478582 0.9037241 1.6792175 0.6537422 #> [176] 1.2626998 1.2314195 0.5752629 1.0178758 1.1244819 1.3156400 2.3394343 #> [183] 0.7148027 1.2373971 1.0901627 0.7922548 0.8992297 1.1999500 0.6621620 #> [190] 0.9400235 0.6836861 0.9189455 0.9848715 0.9124641 0.6945900 1.0161106 #> [197] 1.1063045 0.7455537 1.0869174 0.7733237"},{"path":"https://r-causal.github.io/propensity/index.html","id":"continuous-exposures","dir":"","previous_headings":"Advanced Features","what":"Continuous Exposures","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"continuous treatments, propensity scores represent conditional densities:","code":"# Fit linear model for continuous treatment continuous_treatment <- rnorm(n, mean = 0.5 * x1 - 0.3 * x2) ps_continuous <- lm(continuous_treatment ~ x1 + x2)  # Density-based weights wts_continuous <- wt_ate(   ps_continuous,   continuous_treatment,   exposure_type = \"continuous\",   # stabilization is highly recommended for continuous exposures   stabilize = TRUE )"},{"path":"https://r-causal.github.io/propensity/index.html","id":"categorical-exposures","dir":"","previous_headings":"Advanced Features","what":"Categorical Exposures","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"multi-level treatments, provide data frame matrix propensity scores:","code":"# Multinomial propensity scores (3 treatment levels) ps_matrix <- matrix(c(0.3, 0.5, 0.2), ncol = 3, nrow = n, byrow = TRUE) categorical_treatment <- factor(sample(1:3, n, replace = TRUE))  wt_ate(ps_matrix, categorical_treatment, exposure_type = \"categorical\")  # For ATT, specify focal level wt_att(ps_matrix, categorical_treatment, .focal_level = \"2\")"},{"path":"https://r-causal.github.io/propensity/index.html","id":"censoring-weights","dir":"","previous_headings":"Advanced Features","what":"Censoring Weights","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"Combine treatment censoring weights survival longitudinal analyses:","code":"# Propensity of being uncensored censoring_ps <- predict(   glm(uncensored ~ x1 + x2, family = binomial()),   type = \"response\" )  # Censoring weights wts_cens <- wt_cens(censoring_ps, uncensored)  # Combine with treatment weights wts_combined <- wt_ate(ps, treatment) * wts_cens"},{"path":"https://r-causal.github.io/propensity/index.html","id":"learn-more","dir":"","previous_headings":"","what":"Learn More","title":"A Toolkit for Calculating and Working with Propensity Scores","text":"Causal Inference R - Comprehensive guide causal inference methods R","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability Weights for Causal Inference — ipw","title":"Inverse Probability Weights for Causal Inference — ipw","text":"ipw() bring---model (BYOM) inverse probability weighted estimator. ipw() accepts propensity score model weighted outcome model already fit. purpose ipw() capture uncertainty inherent two-step process calculate correct standard errors estimate. Currently, ipw() supports binary exposures either binary continuous outcomes. binary outcomes, ipw() calculates marginal risk difference, log risk ratio, log odds ratio. continuous outcomes, ipw() calculates marginal difference means.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Probability Weights for Causal Inference — ipw","text":"","code":"ipw(   ps_mod,   outcome_mod,   .data = NULL,   estimand = NULL,   ps_link = NULL,   conf_level = 0.95 )  # S3 method for class 'ipw' as.data.frame(x, row.names = NULL, optional = NULL, exponentiate = FALSE, ...)"},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability Weights for Causal Inference — ipw","text":"ps_mod fitted propensity score model class stats::glm(), typically logistic regression exposure dependent variable. outcome_mod fitted, weighted outcome model class stats::glm() stats::lm(), outcome dependent variable. .data data frame containing exposure, outcome, covariates. NULL, ipw() try extract data ps_mod outcome_mod. estimand character string specifying causal estimand: ate, att, ato, atm. NULL, function attempts infer existing weights outcome_mod, assuming calculated wt_ate(), wt_att(), wt_atm(), wt_ato(). ps_link character string specifying link function propensity score model: logit, probit, cloglog. Defaults whatever link used ps_mod. conf_level Numeric. Confidence level intervals (default 0.95). x ipw object row.names, optional, ... Passed .data.frame(). exponentiate Logical. log-RR log-exponentiated?","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability Weights for Causal Inference — ipw","text":"S3 object class ipw containing: estimand: One \"ate\", \"att\", \"ato\", \"atm\". ps_mod: fitted propensity score model. outcome_mod: fitted outcome model. estimates: data frame point estimates, standard errors, z-statistics, confidence intervals, p-values.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability Weights for Causal Inference — ipw","text":"function constructs inverse probability weights based chosen estimand, uses weights (extracts outcome_mod) compute effect measures: rd: Risk difference log(rr): Log risk ratio log(): Log odds ratio linear outcome model (using stats::lm() stats::glm() family = gaussian()), difference means (diff) returned. Variance Estimation variance estimated via linearization, provide variance estimates IPW correctly account uncertainty estimation propensity scores. details various types propensity score weights corresponding variance estimators, see: Kostouraki , Hajage D, Rachet B, et al. variance estimation inverse probability--treatment weighting estimator: tutorial different types propensity score weights. Statistics Medicine. 2024; 43(13): 2672-2694. doi: 10.1002/sim.10078","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ipw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability Weights for Causal Inference — ipw","text":"","code":"set.seed(123) n <- 100 # confounder x1 <- rnorm(n) # exposure z  <- rbinom(n, 1, plogis(0.2 * x1)) # binary outcome y  <- rbinom(n, 1, plogis(1 + 2*z + 0.5*x1))  dat <- data.frame(x1, z, y)  # fit a propensity score model (exposure ~ x1) ps_mod <- glm(z ~ x1, data = dat, family = binomial())  # calculate weights for ATE ps <- predict(ps_mod, type = \"response\") wts <- wt_ate(ps, z) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  # fit an outcome model (binary y ~ z) using IPW outcome_mod <- glm(y ~ z, data = dat, family = binomial(), weights = wts) #> Warning: non-integer #successes in a binomial glm!  # run IPW ipw_res <- ipw(ps_mod, outcome_mod)  ipw_res #> Inverse Probability Weight Estimator #> Estimand: ATE  #>  #> Propensity Score Model: #>   Call: glm(formula = z ~ x1, family = binomial(), data = dat)  #>  #> Outcome Model: #>   Call: glm(formula = y ~ z, family = binomial(), data = dat, weights = wts)  #>  #> Estimates: #>         estimate  std.err        z ci.lower ci.upper conf.level   p.value     #> rd       0.16311 0.076670 2.127466   0.0128  0.31338       0.95   0.03338 *   #> log(rr)  0.19720 0.080683 2.444134   0.0391  0.35533       0.95   0.01452 *   #> log(or)  1.24122 0.170217 7.291963   0.9076  1.57484       0.95 3.055e-13 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  # Convert to a data frame with exponentiated RR/OR ipw_res_df <- as.data.frame(ipw_res, exponentiate = TRUE) ipw_res_df #>   effect  estimate    std.err        z   ci.lower  ci.upper conf.level #> 1     rd 0.1631125 0.07666988 2.127466 0.01284233 0.3133827       0.95 #> 2     rr 1.2179865 0.08068260 2.444134 1.03983716 1.4266572       0.95 #> 3     or 3.4598274 0.17021737 7.291963 2.47836430 4.8299620       0.95 #>        p.value #> 1 3.338141e-02 #> 2 1.452002e-02 #> 3 3.055334e-13"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is calibrated — is_ps_calibrated","title":"Check if object is calibrated — is_ps_calibrated","text":"is_ps_calibrated() S3 generic returns TRUE argument represents calibrated propensity scores.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is calibrated — is_ps_calibrated","text":"","code":"is_ps_calibrated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is calibrated — is_ps_calibrated","text":"x R object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_calibrated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is calibrated — is_ps_calibrated","text":"logical scalar (TRUE FALSE).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is trimmed — is_ps_trimmed","title":"Check if object is trimmed — is_ps_trimmed","text":"is_ps_trimmed() S3 generic returns TRUE argument represents ps_trim object psw object created trimmed propensity scores. is_ps_trimmed() question whether propensity scores trimmed, opposed is_unit_trimmed(), question units trimmed.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is trimmed — is_ps_trimmed","text":"","code":"is_ps_trimmed(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is trimmed — is_ps_trimmed","text":"x object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_trimmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is trimmed — is_ps_trimmed","text":"logical scalar (TRUE FALSE).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is truncated — is_ps_truncated","title":"Check if object is truncated — is_ps_truncated","text":"is_ps_truncated() S3 generic returns TRUE argument represents ps_trunc object psw object created truncated propensity scores. is_ps_truncated() question whether propensity scores truncated, opposed is_unit_truncated(), question units truncated.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is truncated — is_ps_truncated","text":"","code":"is_ps_truncated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is truncated — is_ps_truncated","text":"x object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_ps_truncated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is truncated — is_ps_truncated","text":"logical scalar (TRUE FALSE).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an object has been refit — is_refit","title":"Check if an object has been refit — is_refit","text":"is_refit() S3 generic returns TRUE argument represents ps_trim object (weighting object) propensity model refit retained subset.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an object has been refit — is_refit","text":"","code":"is_refit(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an object has been refit — is_refit","text":"x R object (e.g. ps_trim psw).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_refit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an object has been refit — is_refit","text":"logical scalar (TRUE FALSE).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if units have been trimmed — is_unit_trimmed","title":"Check if units have been trimmed — is_unit_trimmed","text":"is_unit_trimmed() vector TRUE FALSE values, representing unit trimmed. is_unit_trimmed() question units trimmed, opposed is_ps_trimmed(), question whether propensity scores trimmed.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if units have been trimmed — is_unit_trimmed","text":"","code":"is_unit_trimmed(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if units have been trimmed — is_unit_trimmed","text":"x object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_trimmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if units have been trimmed — is_unit_trimmed","text":"logical scalar (TRUE FALSE).","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if units have been truncated — is_unit_truncated","title":"Check if units have been truncated — is_unit_truncated","text":"is_ps_truncated() S3 generic returns vector TRUE FALSE, representing element truncated. is_unit_truncated() question units truncated, opposed is_ps_truncated(), question whether propensity scores truncated.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if units have been truncated — is_unit_truncated","text":"","code":"is_unit_truncated(x)"},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if units have been truncated — is_unit_truncated","text":"x object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/is_unit_truncated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if units have been truncated — is_unit_truncated","text":"logical vector.","code":""},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":null,"dir":"Reference","previous_headings":"","what":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"comprehensive toolkit propensity score analysis causal inference. Supports calculating propensity score weights multiple causal estimands across binary, continuous, categorical exposures. Provides methods handling extreme propensity scores trimming, truncation, calibration. Includes inverse probability weighted estimators correctly accounts propensity score estimation uncertainty.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/propensity-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"propensity: A Toolkit for Calculating and Working with Propensity Scores — propensity-package","text":"Maintainer: Malcolm Barrett malcolmbarrett@gmail.com (ORCID) [copyright holder]","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate propensity scores — ps_calibrate","title":"Calibrate propensity scores — ps_calibrate","text":"function calibrates propensity scores improve accuracy using either Platt scaling (logistic regression) isotonic regression. preserves attributes causal weight objects applicable.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate propensity scores — ps_calibrate","text":"","code":"ps_calibrate(   ps,   .exposure,   method = c(\"logistic\", \"isoreg\"),   smooth = TRUE,   .focal_level = NULL,   .reference_level = NULL,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate propensity scores — ps_calibrate","text":"ps Numeric vector propensity scores 0 1 .exposure binary vector treatment assignments method Calibration method: \"logistic\" (Default) Logistic calibration (also known Platt scaling). Assumes sigmoid relationship observed true probabilities. Best : propensity scores follow logistic pattern systematically biased. Provides smooth, parametric calibration. Faster stable small samples. \"isoreg\" Isotonic regression calibration. Uses non-parametric monotonic transformation. Best : relationship observed true probabilities non-linear want preserve rank order without assuming specific functional form. flexible requires larger samples stable estimates. smooth Logical. method = \"logistic\", whether use smoothed logistic spline model (smooth = TRUE, default) simple logistic regression (smooth = FALSE). TRUE, uses mgcv::gam() spline smoothing. FALSE, uses stats::glm(). Ignored method = \"isoreg\". .focal_level value representing focal group (typically treatment). provided, ps_calibrate() attempt automatically determine coding. .reference_level value representing reference group (typically control). provided, ps_calibrate() attempt automatically determine coding. .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate propensity scores — ps_calibrate","text":"calibrated propensity score object (ps_calib)","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_calibrate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate propensity scores — ps_calibrate","text":"","code":"# Generate example data ps <- runif(100) exposure <- rbinom(100, 1, ps)  # Logistic calibration with smoothing (default) calibrated_smooth <- ps_calibrate(ps, exposure) #> ℹ Setting focal level to 1  # Logistic calibration without smoothing (simple logistic regression) calibrated_simple <- ps_calibrate(ps, exposure, smooth = FALSE) #> ℹ Setting focal level to 1  # Isotonic regression calibrated_iso <- ps_calibrate(ps, exposure, method = \"isoreg\") #> ℹ Setting focal level to 1"},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":null,"dir":"Reference","previous_headings":"","what":"Refit the Propensity Score Model on Retained Observations — ps_refit","title":"Refit the Propensity Score Model on Retained Observations — ps_refit","text":"Takes ps_trim object original model used calculate propensity score, : Retrieves data model (.df argument provided) Subsets rows non‐trimmed indices Refits model Predicts new propensity scores rows (trimmed rows -> NA) Returns new ps_trim object refit = TRUE.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refit the Propensity Score Model on Retained Observations — ps_refit","text":"","code":"ps_refit(trimmed_ps, model, .data = NULL, ...)"},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refit the Propensity Score Model on Retained Observations — ps_refit","text":"trimmed_ps ps_trim object (length data, NAs trimmed). model fitted model used get original PS (e.g. glm). .data Optional. data frame. NULL, try retrieve model. ... Additional arguments passed update().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refit the Propensity Score Model on Retained Observations — ps_refit","text":"new ps_trim object updated propensity scores ps_trim_meta(x)$refit set TRUE.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_refit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Refit the Propensity Score Model on Retained Observations — ps_refit","text":"","code":"set.seed(2) n <- 30 x <- rnorm(n) z <- rbinom(n, 1, plogis(0.4 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  # trim and refit refit <- ps_trim(ps, lower = .2, upper = .8) |>   ps_refit(fit)  is_refit(refit) #> [1] TRUE"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim Propensity Scores — ps_trim","title":"Trim Propensity Scores — ps_trim","text":"ps_trim() applies trimming methods propensity-score vector matrix, returning new vector/matrix length/dimensions, trimmed entries replaced NA. can inspect metadata ps_trim_meta(x). running ps_trim(), refit model ps_refit().","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim Propensity Scores — ps_trim","text":"","code":"ps_trim(   ps,   method = c(\"ps\", \"adaptive\", \"pctl\", \"pref\", \"cr\", \"optimal\"),   lower = NULL,   upper = NULL,   .exposure = NULL,   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim Propensity Scores — ps_trim","text":"ps propensity score, either numeric vector 0 1 binary exposures, matrix/data.frame column represents propensity scores level categorical exposure. method One c(\"ps\", \"adaptive\", \"pctl\", \"pref\", \"cr\", \"optimal\"). categorical exposures, \"ps\" \"optimal\" supported. lower, upper Numeric cutoffs quantiles. NULL, defaults vary method. categorical exposures method \"ps\", lower represents symmetric trimming threshold (delta). .exposure methods like \"pref\" \"cr\", vector binary exposure. categorical exposures method \"optimal\", must factor character vector. .focal_level binary exposures, value representing focal group (typically treatment group). categorical exposures ATT ATU estimands, specifies focal category. Must one levels exposure variable. Required wt_att() wt_atu() categorical exposures. .reference_level binary exposures, value representing reference group (typically control group). provided, automatically detected. ... Additional arguments passed methods .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim Propensity Scores — ps_trim","text":"ps_trim object (numeric vector matrix). attribute ps_trim_meta stores metadata.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trim Propensity Scores — ps_trim","text":"returned object ps_trim vector/matrix length/dimensions ps, trimmed entries replaced NA. attribute ps_trim_meta contains: method: trimming method used keep_idx: Indices retained trimmed_idx: Indices replaced NA Possibly fields final cutoffs, etc. categorical exposures: Symmetric trimming (method = \"ps\"): Removes observations propensity score falls threshold delta (specified via lower). Optimal trimming (method = \"optimal\"): Uses Yang et al. (2016) approach multi-category treatments. Arithmetic behavior: Arithmetic operations ps_trim objects return numeric vectors, ps_trim objects. intentional - transform propensity scores (e.g., 1/ps weights), result longer propensity score. NA handling: Trimmed values set NA. Operations handle NA values propagate (e.g., sum() returns NA unless na.rm = TRUE). Metadata tracking: trimmed_idx keep_idx updated subsetting reordering: Subsetting [ updates indices new positions sort() reorders data updates indices accordingly unique() may change lengths preserves class na.omit() removes trimmed values updates indices Combining behavior: combining ps_trim objects c(), metadata must match (trimming parameters). Mismatched metadata triggers warning returns numeric vector.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim Propensity Scores — ps_trim","text":"","code":"set.seed(2) n <- 300 x <- rnorm(n) z <- rbinom(n, 1, plogis(1.3 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  ps_trim(ps, method = \"adaptive\") #> <ps_trim; trimmed 44 of [300]> #>         1         2         3         4         5         6         7         8  #> 0.1780112 0.4934483 0.8725819 0.1353577 0.4025855 0.4752489 0.6683913 0.3506150  #>         9        10        11        12        13        14        15        16  #>        NA 0.3831809 0.5738044 0.7467782 0.3038553 0.1508037 0.8997256        NA  #>        17        18        19        20        21        22        23        24  #> 0.7187207 0.4419184 0.7548592 0.5787647        NA 0.1244366 0.8728587        NA  #>        25        26        27        28        29        30        31        32  #> 0.4313639        NA 0.5939254 0.2474276 0.6938170 0.5298266 0.6778670 0.5399668  #>        33        34        35        36        37        38        39        40  #> 0.7707828 0.3366773 0.2037945 0.2476600        NA 0.1768609 0.2572600 0.3484614  #>        41        42        43        44        45        46        47        48  #> 0.3065403        NA 0.1895191        NA 0.6415565        NA 0.3300895 0.3990495  #>        49        50        51        52        53        54        55        56  #> 0.3683877 0.1246121 0.1902500        NA 0.2564150 0.8160957 0.1494022        NA  #>        57        58        59        60        61        62        63        64  #> 0.3247367 0.7345271 0.7859021 0.8849770        NA        NA 0.2208817 0.4841803  #>        65        66        67        68        69        70        71        72  #> 0.6036086 0.1941979        NA 0.2790100 0.4585602 0.1783019 0.1731103 0.5439312  #>        73        74        75        76        77        78        79        80  #> 0.3822372 0.5796397 0.4114856 0.1759469 0.8218240 0.6877562 0.7649259        NA  #>        81        82        83        84        85        86        87        88  #> 0.7505008        NA 0.2641422 0.1005949        NA        NA 0.2330120 0.3365148  #>        89        90        91        92        93        94        95        96  #> 0.3055473 0.5632496 0.8745082 0.8863194 0.1269292 0.1023453        NA 0.1166039  #>        97        98        99       100       101       102       103       104  #>        NA 0.4322875 0.1893249 0.2462384 0.7703638 0.5197606 0.3273939 0.2099624  #>       105       106       107       108       109       110       111       112  #> 0.1851823        NA 0.7356255        NA 0.2954896 0.3163021 0.1530042 0.3471981  #>       113       114       115       116       117       118       119       120  #> 0.5921212 0.8328274 0.6227067 0.5867797 0.8065734 0.7877456 0.4663064 0.2023006  #>       121       122       123       124       125       126       127       128  #> 0.8087856 0.4774812 0.8903829 0.2928150 0.1499937 0.6139848 0.2290136 0.6467536  #>       129       130       131       132       133       134       135       136  #>        NA        NA 0.6627758 0.5441083 0.7165979        NA 0.8025574 0.7998822  #>       137       138       139       140       141       142       143       144  #> 0.7597742 0.6921037        NA        NA 0.2509264 0.5711077 0.1970442 0.4590332  #>       145       146       147       148       149       150       151       152  #> 0.6800801 0.2329425 0.6525433 0.6180388 0.1970997 0.1584870 0.7452343 0.3731672  #>       153       154       155       156       157       158       159       160  #> 0.6727629 0.1889404 0.8164247 0.1043218 0.6858279 0.5895482 0.5223260 0.6558189  #>       161       162       163       164       165       166       167       168  #> 0.5672709 0.2368400 0.3418011 0.5540597 0.1083159 0.1806594        NA        NA  #>       169       170       171       172       173       174       175       176  #> 0.1187105 0.7490531 0.7738375 0.7077039 0.4491471 0.5416643 0.1764396 0.2333126  #>       177       178       179       180       181       182       183       184  #> 0.3434474 0.1704628 0.7023006        NA 0.1524604 0.1153463 0.5651259 0.1351849  #>       185       186       187       188       189       190       191       192  #> 0.6161453 0.7945146 0.4382952 0.6065642 0.2328341 0.6027459 0.1139088 0.4037497  #>       193       194       195       196       197       198       199       200  #> 0.1040353 0.3422376 0.7735701 0.6661116 0.2893391 0.2011360 0.1863223 0.2107038  #>       201       202       203       204       205       206       207       208  #> 0.5327159 0.1544197        NA 0.5052145 0.1642856 0.5622725 0.3887452 0.3163883  #>       209       210       211       212       213       214       215       216  #> 0.6341619 0.5095796 0.7582940 0.2665601        NA        NA 0.4774214 0.5852567  #>       217       218       219       220       221       222       223       224  #> 0.8030404 0.1067663 0.1338595 0.8855459 0.5671613 0.6707177 0.2000938        NA  #>       225       226       227       228       229       230       231       232  #> 0.4538222 0.5912550 0.3993802 0.7230688 0.3094663        NA 0.8702859        NA  #>       233       234       235       236       237       238       239       240  #> 0.2415827 0.4195113        NA 0.1483657 0.2541910 0.5957602 0.4626159 0.2496911  #>       241       242       243       244       245       246       247       248  #> 0.4020747        NA 0.7936546 0.6179515 0.6899355 0.2556513 0.4650462 0.5270157  #>       249       250       251       252       253       254       255       256  #> 0.2803714 0.2850014 0.6020472 0.3002118 0.3705819 0.3257820 0.7087374 0.5960756  #>       257       258       259       260       261       262       263       264  #> 0.3306472 0.3363861 0.7464321 0.3725508 0.8297224 0.3965473 0.3250342        NA  #>       265       266       267       268       269       270       271       272  #> 0.2345937        NA        NA 0.5886632 0.6106387 0.4172303        NA 0.4137080  #>       273       274       275       276       277       278       279       280  #> 0.4312953 0.1206438 0.5164038 0.8752400 0.4176263 0.7591012 0.3016993 0.4527210  #>       281       282       283       284       285       286       287       288  #>        NA 0.6501483 0.8168531 0.2393292 0.8311549 0.8851143 0.7936328 0.4317872  #>       289       290       291       292       293       294       295       296  #> 0.8222307 0.3983355 0.1356224 0.6302455 0.4602807 0.3527491 0.8562989 0.3153233  #>       297       298       299       300  #> 0.5741435        NA 0.1008201 0.2253829   # Coercion behavior with ps_trim objects ps_trim1 <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9) ps_trim2 <- ps_trim(ps, method = \"ps\", lower = 0.1, upper = 0.9)  # Compatible objects combine silently c(ps_trim1[1:50], ps_trim2[51:100])  # Returns ps_trim object #> <ps_trim; trimmed 20 of [100]> #>         1         2         3         4         5         6         7         8  #> 0.1780112 0.4934483 0.8725819 0.1353577 0.4025855 0.4752489 0.6683913 0.3506150  #>         9        10        11        12        13        14        15        16  #>        NA 0.3831809 0.5738044 0.7467782 0.3038553 0.1508037 0.8997256        NA  #>        17        18        19        20        21        22        23        24  #> 0.7187207 0.4419184 0.7548592 0.5787647        NA 0.1244366 0.8728587        NA  #>        25        26        27        28        29        30        31        32  #> 0.4313639        NA 0.5939254 0.2474276 0.6938170 0.5298266 0.6778670 0.5399668  #>        33        34        35        36        37        38        39        40  #> 0.7707828 0.3366773 0.2037945 0.2476600        NA 0.1768609 0.2572600 0.3484614  #>        41        42        43        44        45        46        47        48  #> 0.3065403        NA 0.1895191        NA 0.6415565        NA 0.3300895 0.3990495  #>        49        50        51        52        53        54        55        56  #> 0.3683877 0.1246121 0.1902500        NA 0.2564150 0.8160957 0.1494022        NA  #>        57        58        59        60        61        62        63        64  #> 0.3247367 0.7345271 0.7859021 0.8849770        NA        NA 0.2208817 0.4841803  #>        65        66        67        68        69        70        71        72  #> 0.6036086 0.1941979        NA 0.2790100 0.4585602 0.1783019 0.1731103 0.5439312  #>        73        74        75        76        77        78        79        80  #> 0.3822372 0.5796397 0.4114856 0.1759469 0.8218240 0.6877562 0.7649259        NA  #>        81        82        83        84        85        86        87        88  #> 0.7505008        NA 0.2641422 0.1005949        NA        NA 0.2330120 0.3365148  #>        89        90        91        92        93        94        95        96  #> 0.3055473 0.5632496 0.8745082 0.8863194 0.1269292 0.1023453        NA 0.1166039  #>        97        98        99       100  #>        NA 0.4322875 0.1893249 0.2462384   # Different trim parameters trigger warning ps_trim3 <- ps_trim(ps, method = \"ps\", lower = 0.2, upper = 0.8) c(ps_trim1[1:50], ps_trim3[51:100])  # Warning: returns numeric #> Warning: Converting ps_trim to numeric: different trimming parameters #> ℹ Metadata cannot be preserved when combining incompatible objects #> ℹ Use identical objects or explicitly cast to numeric to avoid this warning #>         1         2         3         4         5         6         7         8  #> 0.1780112 0.4934483 0.8725819 0.1353577 0.4025855 0.4752489 0.6683913 0.3506150  #>         9        10        11        12        13        14        15        16  #>        NA 0.3831809 0.5738044 0.7467782 0.3038553 0.1508037 0.8997256        NA  #>        17        18        19        20        21        22        23        24  #> 0.7187207 0.4419184 0.7548592 0.5787647        NA 0.1244366 0.8728587        NA  #>        25        26        27        28        29        30        31        32  #> 0.4313639        NA 0.5939254 0.2474276 0.6938170 0.5298266 0.6778670 0.5399668  #>        33        34        35        36        37        38        39        40  #> 0.7707828 0.3366773 0.2037945 0.2476600        NA 0.1768609 0.2572600 0.3484614  #>        41        42        43        44        45        46        47        48  #> 0.3065403        NA 0.1895191        NA 0.6415565        NA 0.3300895 0.3990495  #>        49        50        51        52        53        54        55        56  #> 0.3683877 0.1246121        NA        NA 0.2564150        NA        NA        NA  #>        57        58        59        60        61        62        63        64  #> 0.3247367 0.7345271 0.7859021        NA        NA        NA 0.2208817 0.4841803  #>        65        66        67        68        69        70        71        72  #> 0.6036086        NA        NA 0.2790100 0.4585602        NA        NA 0.5439312  #>        73        74        75        76        77        78        79        80  #> 0.3822372 0.5796397 0.4114856        NA        NA 0.6877562 0.7649259        NA  #>        81        82        83        84        85        86        87        88  #> 0.7505008        NA 0.2641422        NA        NA        NA 0.2330120 0.3365148  #>        89        90        91        92        93        94        95        96  #> 0.3055473 0.5632496        NA        NA        NA        NA        NA        NA  #>        97        98        99       100  #>        NA 0.4322875        NA 0.2462384   # Cross-class combinations warn and return numeric psw_obj <- psw(ps[1:50], estimand = \"ate\") c(ps_trim1[1:50], psw_obj)  # Warning: returns numeric #> Warning: Converting ps_trim and psw to numeric #> ℹ Class-specific attributes and metadata have been dropped #> ℹ Use explicit casting to numeric to avoid this warning #>          1          2          3          4          5          6          7  #> 0.17801124 0.49344831 0.87258189 0.13535765 0.40258554 0.47524889 0.66839132  #>          8          9         10         11         12         13         14  #> 0.35061504         NA 0.38318089 0.57380442 0.74677823 0.30385529 0.15080370  #>         15         16         17         18         19         20         21  #> 0.89972561         NA 0.71872070 0.44191837 0.75485924 0.57876473         NA  #>         22         23         24         25         26         27         28  #> 0.12443658 0.87285871         NA 0.43136394         NA 0.59392536 0.24742762  #>         29         30         31         32         33         34         35  #> 0.69381700 0.52982663 0.67786695 0.53996676 0.77078278 0.33667732 0.20379449  #>         36         37         38         39         40         41         42  #> 0.24766004         NA 0.17686094 0.25726004 0.34846140 0.30654026         NA  #>         43         44         45         46         47         48         49  #> 0.18951912         NA 0.64155648         NA 0.33008953 0.39904946 0.36838768  #>         50                                                                    #> 0.12461207 0.17801124 0.49344831 0.87258189 0.13535765 0.40258554 0.47524889  #>                                                                               #> 0.66839132 0.35061504 0.92239228 0.38318089 0.57380442 0.74677823 0.30385529  #>                                                                               #> 0.15080370 0.89972561 0.02943822 0.71872070 0.44191837 0.75485924 0.57876473  #>                                                                               #> 0.93233516 0.12443658 0.87285871 0.91937240 0.43136394 0.02433818 0.59392536  #>                                                                               #> 0.24742762 0.69381700 0.52982663 0.67786695 0.53996676 0.77078278 0.33667732  #>                                                                               #> 0.20379449 0.24766004 0.06402613 0.17686094 0.25726004 0.34846140 0.30654026  #>                                                                               #> 0.04714018 0.18951912 0.91394741 0.64155648 0.92303132 0.33008953 0.39904946  #>                        #> 0.36838768 0.12461207"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract ps_trim metadata — ps_trim_meta","title":"Extract ps_trim metadata — ps_trim_meta","text":"Returns internal metadata list ps_trim object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract ps_trim metadata — ps_trim_meta","text":"","code":"ps_trim_meta(x)"},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract ps_trim metadata — ps_trim_meta","text":"x ps_trim object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trim_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract ps_trim metadata — ps_trim_meta","text":"named list metadata.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate (Winsorize) Propensity Scores — ps_trunc","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps_trunc() sets ‐‐range propensity scores fixed bounding values (form winsorizing). alternative ps_trim(), removes (sets NA) instead bounding refit ps_refit()","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"","code":"ps_trunc(   ps,   method = c(\"ps\", \"pctl\", \"cr\"),   lower = NULL,   upper = NULL,   .exposure = NULL,   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps propensity score, either numeric vector 0 1 binary exposures, matrix/data.frame column represents propensity scores level categorical exposure. method One \"ps\", \"pctl\", \"cr\". \"ps\": directly cut [lower, upper] ps. categorical, uses symmetric truncation lower threshold. \"pctl\": use quantiles ps bounding values. categorical, calculates quantiles across propensity score values. \"cr\": common range ps given .exposure, bounding [min(ps[treated]), max(ps[untreated])] (binary ) lower, upper Numeric quantile bounds. NULL, defaults vary method. categorical exposures method \"ps\", lower represents truncation threshold (delta). .exposure method \"cr\", binary exposure vector. categorical exposures, must factor character vector. .focal_level binary exposures, value representing focal group (typically treatment group). categorical exposures ATT ATU estimands, specifies focal category. Must one levels exposure variable. Required wt_att() wt_atu() categorical exposures. .reference_level binary exposures, value representing reference group (typically control group). provided, automatically detected. ... Additional arguments passed methods .treated Use .focal_level instead. .untreated Use .reference_level instead.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"ps_trunc object (numeric vector matrix). attribute ps_trunc_meta storing fields like method, lower_bound, upper_bound.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"binary exposures \\(ps[]\\): \\(ps[] < lower\\_bound\\), set \\(ps[] = lower\\_bound\\). \\(ps[] > upper\\_bound\\), set \\(ps[] = upper\\_bound\\). categorical exposures: value threshold set threshold Rows renormalized sum 1 approach often called winsorizing. Arithmetic behavior: Like ps_trim, arithmetic operations ps_trunc objects return numeric vectors. reasoning - transformed propensity scores (e.g., weights) longer propensity scores. NA values: Unlike ps_trim, truncation create NA values. --range values set boundaries, values remain finite valid calculations. Metadata tracking: truncated_idx tracks positions values modified (winsorized boundaries): Subsetting [ updates indices new positions sort() reorders data updates indices accordingly Operations preserve finite values (NA handling needed) Boundary detection: Values exactly boundaries (truncation) may indicate truncation, necessarily truncated - boundary originally. Combining behavior: combining ps_trunc objects c(), truncation parameters must match. Mismatched parameters trigger warning return numeric vector.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate (Winsorize) Propensity Scores — ps_trunc","text":"","code":"set.seed(2) n <- 30 x <- rnorm(n) z <- rbinom(n, 1, plogis(0.4 * x)) fit <- glm(z ~ x, family = binomial) ps <- predict(fit, type = \"response\")  # truncate just the 99th percentile ps_trunc(ps, method = \"pctl\", lower = 0, upper = .99) #> <ps_trunc{[0.341443426776033,0.805793268892769], method=pctl}[30]> #>         1         2         3         4         5         6         7         8  #> 0.5149714 0.6361298 0.7694837 0.4880712 0.6073989 0.6305169 0.6899234 0.5897388  #>         9        10        11        12        13        14        15        16  #> 0.8003122 0.6009455 0.6605909 0.7162599 0.5725720 0.4985231 0.7849940 0.3561684  #>        17        18        19        20        21        22        23        24  #> 0.7064972 0.6200818 0.7191624 0.6620999 0.8057933 0.4800637 0.7696302 0.7981060  #>        25        26        27        28        29        30  #> 0.6167236 0.3414434 0.6667225 0.5494305 0.6981704 0.6472363   # Coercion behavior with ps_trunc objects ps_trunc1 <- ps_trunc(ps, method = \"ps\", lower = 0.1, upper = 0.9) ps_trunc2 <- ps_trunc(ps, method = \"ps\", lower = 0.1, upper = 0.9)  # Compatible objects combine silently c(ps_trunc1[1:15], ps_trunc2[16:30])  # Returns ps_trunc object #> <ps_trunc{[0.1,0.9], method=ps}[30]> #>         1         2         3         4         5         6         7         8  #> 0.5149714 0.6361298 0.7694837 0.4880712 0.6073989 0.6305169 0.6899234 0.5897388  #>         9        10        11        12        13        14        15        16  #> 0.8003122 0.6009455 0.6605909 0.7162599 0.5725720 0.4985231 0.7849940 0.3561684  #>        17        18        19        20        21        22        23        24  #> 0.7064972 0.6200818 0.7191624 0.6620999 0.8080320 0.4800637 0.7696302 0.7981060  #>        25        26        27        28        29        30  #> 0.6167236 0.3414434 0.6667225 0.5494305 0.6981704 0.6472363   # Different truncation parameters trigger warning ps_trunc3 <- ps_trunc(ps, method = \"ps\", lower = 0.2, upper = 0.8) c(ps_trunc1[1:15], ps_trunc3[16:30])  # Warning: returns numeric #> Warning: Converting ps_trunc to numeric: different truncation parameters #> ℹ Metadata cannot be preserved when combining incompatible objects #> ℹ Use identical objects or explicitly cast to numeric to avoid this warning #>         1         2         3         4         5         6         7         8  #> 0.5149714 0.6361298 0.7694837 0.4880712 0.6073989 0.6305169 0.6899234 0.5897388  #>         9        10        11        12        13        14        15        16  #> 0.8003122 0.6009455 0.6605909 0.7162599 0.5725720 0.4985231 0.7849940 0.3561684  #>        17        18        19        20        21        22        23        24  #> 0.7064972 0.6200818 0.7191624 0.6620999 0.8000000 0.4800637 0.7696302 0.7981060  #>        25        26        27        28        29        30  #> 0.6167236 0.3414434 0.6667225 0.5494305 0.6981704 0.6472363   # Mixing with other propensity classes warns ps_trim_obj <- ps_trim(ps[1:15], method = \"ps\", lower = 0.1) c(ps_trunc1[1:15], ps_trim_obj)  # Warning: returns numeric #> Warning: Converting ps_trunc and ps_trim to numeric #> ℹ Class-specific attributes and metadata have been dropped #> ℹ Use explicit casting to numeric to avoid this warning #>         1         2         3         4         5         6         7         8  #> 0.5149714 0.6361298 0.7694837 0.4880712 0.6073989 0.6305169 0.6899234 0.5897388  #>         9        10        11        12        13        14        15         1  #> 0.8003122 0.6009455 0.6605909 0.7162599 0.5725720 0.4985231 0.7849940 0.5149714  #>         2         3         4         5         6         7         8         9  #> 0.6361298 0.7694837 0.4880712 0.6073989 0.6305169 0.6899234 0.5897388 0.8003122  #>        10        11        12        13        14        15  #> 0.6009455 0.6605909 0.7162599 0.5725720 0.4985231 0.7849940"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract ps_trunc metadata — ps_trunc_meta","title":"Extract ps_trunc metadata — ps_trunc_meta","text":"Returns internal metadata list ps_trunc object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract ps_trunc metadata — ps_trunc_meta","text":"","code":"ps_trunc_meta(x)"},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract ps_trunc metadata — ps_trunc_meta","text":"x ps_trunc object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/ps_trunc_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract ps_trunc metadata — ps_trunc_meta","text":"named list metadata.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and Manipulate psw Objects — psw","title":"Create and Manipulate psw Objects — psw","text":"Functions create manipulate psw objects, specialized vectors propensity score weights optional estimand attributes. users use wt_ate() friends, functions can help extend functionality psw objects.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and Manipulate psw Objects — psw","text":"","code":"new_psw(   x = double(),   estimand = NULL,   stabilized = FALSE,   trimmed = FALSE,   truncated = FALSE,   calibrated = FALSE,   ... )  psw(   x = double(),   estimand = NULL,   stabilized = FALSE,   trimmed = FALSE,   truncated = FALSE,   calibrated = FALSE )  is_psw(x)  is_stabilized(wt)  is_causal_wt(x)  as_psw(x, estimand = NULL)  estimand(wt)  estimand(wt) <- value"},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and Manipulate psw Objects — psw","text":"x numeric vector (default: double()). estimand character string representing estimand (e.g., \"ate\", \"att\", \"ato\"). Default NULL. stabilized logical TRUE trimmed Logical, whether weights came trimmed PS. truncated Logical, whether weights came truncated PS. calibrated Logical, whether weights came calibrated PS. ... Additional attributes track weights. wt object check convert. value value add attribute.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and Manipulate psw Objects — psw","text":"new_psw(): psw object. psw(): psw object. is_psw(): TRUE object psw, otherwise FALSE. as_psw(): psw object. estimand(): estimand attribute psw object. is_stabilized(): stabilized attribute psw object.","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create and Manipulate psw Objects — psw","text":"psw class vctrs-based S3 class represents propensity score weights. extends numeric vectors additional metadata tracking estimand type, stabilization status, source transformations. Arithmetic behavior: Unlike ps_trim ps_trunc objects, arithmetic operations psw objects preserve class attributes. allows weight manipulations like normalization (weights / sum(weights)) maintaining metadata. Combining behavior: combining psw objects c(), class preserved metadata matches. Mismatched metadata triggers warning returns numeric vector. Base R compatibility: base R operations work seamlessly: Subsetting [ preserves class attributes Summary functions (sum(), mean(), etc.) return numeric values Comparison operators return logical vectors Works data frames tidyverse functions","code":""},{"path":"https://r-causal.github.io/propensity/reference/psw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and Manipulate psw Objects — psw","text":"","code":"psw_weights <- new_psw(c(0.1, 0.2, 0.3), estimand = \"ate\") is_psw(psw_weights) #> [1] TRUE estimand(psw_weights) #> [1] \"ate\"  psw_helper <- psw(c(0.5, 0.7), estimand = \"att\") as_psw(c(0.1, 0.2), estimand = \"ato\") #> <psw{estimand = ato}[2]> #> [1] 0.1 0.2  # Coercion behavior - compatible objects combine silently x <- psw(c(0.5, 0.7), estimand = \"ate\") y <- psw(c(0.3, 0.8), estimand = \"ate\") c(x, y)  # Returns psw object #> <psw{estimand = ate}[4]> #> [1] 0.5 0.7 0.3 0.8  # Incompatible metadata triggers warning and returns numeric x <- psw(c(0.5, 0.7), estimand = \"ate\") y <- psw(c(0.3, 0.8), estimand = \"att\") c(x, y)  # Warning: returns numeric #> Warning: Converting psw to numeric: incompatible estimands 'ate' and 'att' #> ℹ Metadata cannot be preserved when combining incompatible objects #> ℹ Use identical objects or explicitly cast to numeric to avoid this warning #> [1] 0.5 0.7 0.3 0.8  # Works with tidyr::pivot_longer for plotting if (requireNamespace(\"tidyr\", quietly = TRUE)) {   df <- data.frame(     id = 1:4,     ate_wts = psw(c(0.5, 0.7, 0.3, 0.8), estimand = \"ate\"),     att_wts = psw(c(0.4, 0.6, 0.2, 0.9), estimand = \"att\")   )   # This will warn but succeed, returning numeric in the pivoted column   tidyr::pivot_longer(df, cols = c(ate_wts, att_wts)) } #> Warning: Converting psw to numeric: incompatible estimands 'ate' and 'att' #> ℹ Metadata cannot be preserved when combining incompatible objects #> ℹ Use identical objects or explicitly cast to numeric to avoid this warning #> # A tibble: 8 × 3 #>      id name    value #>   <int> <chr>   <dbl> #> 1     1 ate_wts   0.5 #> 2     1 att_wts   0.4 #> 3     2 ate_wts   0.7 #> 4     2 att_wts   0.6 #> 5     3 ate_wts   0.3 #> 6     3 att_wts   0.2 #> 7     4 ate_wts   0.8 #> 8     4 att_wts   0.9"},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Propensity Score Weights for Causal Inference — wt_ate","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"family functions computes propensity score weights various causal estimands: ATE (Average Treatment Effect) ATT (Average Treatment Effect Treated) ATU (Average Treatment Effect Untreated, sometimes called ATC, \"C\" stands \"control\"). wt_atc() provided alias wt_atu() ATM (Average Treatment Effect Evenly Matchable) ATO (Average Treatment Effect Overlap population) Entropy (Average Treatment Effect Entropy-weighted population) Censoring weights can calculated using wt_cens(), uses formula ATE weights estimand \"uncensored\". useful handling censoring survival analysis propensity score can provided numeric vector predicted probabilities, data.frame column represents predicted probability level exposure, fitted GLM object. can also propensity score objects created ps_trim(), ps_refit(), ps_trunc() returned weights encapsulated psw object, numeric vector additional attributes record estimand, whether weights stabilized, trimmed, truncated.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"","code":"wt_ate(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_ate(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_att(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_att(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atu(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_atu(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atm(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_atm(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_ato(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_ato(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_entropy(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_entropy(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )  wt_atc(   .propensity,   .exposure,   exposure_type = c(\"auto\", \"binary\", \"categorical\"),   .focal_level = NULL,   .reference_level = NULL,   ...,   .treated = NULL,   .untreated = NULL )  wt_cens(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .treated = NULL,   .untreated = NULL )  # S3 method for class 'data.frame' wt_cens(   .propensity,   .exposure,   .sigma = NULL,   exposure_type = c(\"auto\", \"binary\", \"categorical\", \"continuous\"),   .focal_level = NULL,   .reference_level = NULL,   stabilize = FALSE,   stabilization_score = NULL,   ...,   .propensity_col = NULL,   .treated = NULL,   .untreated = NULL )"},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":".propensity Either numeric vector predicted probabilities, data.frame column corresponds level exposure, fitted GLM object. data frames, second column used default binary exposures unless specified otherwise .propensity_col. GLM objects, fitted values extracted automatically. .exposure exposure variable. binary exposures, vector 0s 1s; continuous exposures, numeric vector. .propensity GLM object, argument optional extracted model provided. .sigma continuous exposures, numeric vector standard errors used dnorm(). example, can derived influence measures model (e.g., influence(model)$sigma). exposure_type Character string specifying type exposure. Options \"auto\", \"binary\", \"categorical\", \"continuous\". Defaults \"auto\", detects type automatically. .focal_level binary exposures, value representing focal group (typically treatment group). categorical exposures ATT ATU estimands, specifies focal category. Must one levels exposure variable. Required wt_att() wt_atu() categorical exposures. .reference_level binary exposures, value representing reference group (typically control group). provided, automatically detected. stabilize Logical indicating whether stabilize weights. ATE weights, stabilization multiplies weight either mean .exposure supplied stabilization_score. Note: stabilization supported ATE continuous exposures. stabilization_score Optional numeric value stabilizing weights (e.g., predicted value regression model without predictors). used stabilize TRUE. ... Reserved future expansion. currently used. .treated Use .focal_level instead. .untreated Use .reference_level instead. .propensity_col binary exposure, .propensity data frame, specifies column use propensity scores. Can column name (quoted unquoted) numeric index. Defaults second column available, otherwise first. categorical exposures, entire data frame used matrix propensity scores.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"psw object (numeric vector) additional attributes: estimand: description estimand (e.g., \"ate\", \"att\"). stabilized: logical flag indicating stabilization applied. trimmed: logical flag indicating weights based trimmed propensity scores. truncated: logical flag indicating weights based truncated propensity scores.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"theoretical-background","dir":"Reference","previous_headings":"","what":"Theoretical Background","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Propensity score weighting method estimating causal effects creating pseudo-population exposure independent measured confounders. propensity score, \\(e(X)\\), probability receiving treatment given observed covariates \\(X\\). weighting observations inversely proportional propensity scores, can balance distribution covariates treatment groups. weights allow different target populations.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"binary-exposures","dir":"Reference","previous_headings":"","what":"Binary Exposures","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"binary treatments (\\(= 0\\) \\(1\\)), weights : ATE: \\(w = \\frac{}{e(X)} + \\frac{1-}{1-e(X)}\\) ATT: \\(w = + \\frac{(1-) \\cdot e(X)}{1-e(X)}\\) ATU: \\(w = \\frac{\\cdot (1-e(X))}{e(X)} + (1-)\\) ATM: \\(w = \\frac{\\min(e(X), 1-e(X))}{\\cdot e(X) + (1-) \\cdot (1-e(X))}\\) ATO: \\(w = \\cdot (1-e(X)) + (1-) \\cdot e(X)\\) Entropy: \\(w = \\frac{h(e(X))}{\\cdot e(X) + (1-) \\cdot (1-e(X))}\\), \\(h(e) = -[e \\cdot \\log(e) + (1-e) \\cdot \\log(1-e)]\\)","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"continuous-exposures","dir":"Reference","previous_headings":"","what":"Continuous Exposures","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"continuous treatments, weights use density ratio: \\(w = \\frac{f_A()}{f_{|X}(|X)}\\), \\(f_A\\) marginal density \\(\\) \\(f_{|X}\\) conditional density given \\(X\\).","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"categorical-exposures","dir":"Reference","previous_headings":"","what":"Categorical Exposures","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"categorical treatments \\(K\\) levels, weights use tilting function approach: \\(w_i = \\frac{h(e_i)}{e_{,Z_i}}\\), \\(e_{,Z_i}\\) propensity score unit \\(\\)'s observed treatment level, \\(h(e_i)\\) tilting function depends estimand: ATE: \\(h(e) = 1\\) ATT: \\(h(e) = e_{focal}\\) (propensity score focal category) ATU: \\(h(e) = 1 - e_{focal}\\) (complement focal category propensity) ATM: \\(h(e) = \\min(e_1, ..., e_K)\\) ATO: \\(h(e) = 1 / \\sum_k(1/e_k)\\) (reciprocal harmonic mean denominator) Entropy: \\(h(e) = -\\sum_k[e_k \\cdot \\log(e_k)]\\) (entropy propensity scores)","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"exposure-types","dir":"Reference","previous_headings":"","what":"Exposure Types","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"functions support different types exposures: binary: dichotomous treatments (e.g. 0/1). continuous: numeric exposures. , weights calculated via normal density using dnorm(). categorical: exposures 2 categories. Requires .propensity matrix data frame columns representing propensity scores category. auto: Automatically detects exposure type based .exposure.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"stabilization","dir":"Reference","previous_headings":"","what":"Stabilization","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"ATE weights, stabilization can improve performance estimator reducing variance. stabilize TRUE stabilization_score provided, weights multiplied mean .exposure. Alternatively, stabilization_score provided, used multiplier. Stabilized weights form: \\(w_s = f_A() \\times w\\), \\(f_A()\\) marginal probability density.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"weight-properties-and-diagnostics","dir":"Reference","previous_headings":"","what":"Weight Properties and Diagnostics","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Extreme weights can indicate: Positivity violations (near 0 1 propensity scores) Poor model specification Lack overlap treatment groups See halfmoon package tools diagnose visualize weights. can address extreme weights several ways. first modify target population: use trimming, truncation, alternative estimands (ATM, ATO, entropy). Another technique can help stabilization, reduces variance weights.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"trimmed-and-truncated-weights","dir":"Reference","previous_headings":"","what":"Trimmed and Truncated Weights","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"addition standard weight functions, versions exist trimmed truncated propensity score weights created ps_trim(), ps_trunc(), ps_refit(). variants calculate weights using modified propensity scores (trimmed truncated) update estimand attribute accordingly.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"detailed guidance causal inference R, see Causal Inference R Malcolm Barrett, Lucy D'Agostino McGowan, Travis Gerke.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"foundational-papers","dir":"Reference","previous_headings":"","what":"Foundational Papers","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Rosenbaum, P. R., & Rubin, D. B. (1983). central role propensity score observational studies causal effects. Biometrika, 70(1), 41-55.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"estimand-specific-methods","dir":"Reference","previous_headings":"","what":"Estimand-Specific Methods","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Li, L., & Greene, T. (2013). weighting analogue pair matching propensity score analysis. International Journal Biostatistics, 9(2), 215-234. (ATM weights) Li, F., Morgan, K. L., & Zaslavsky, . M. (2018). Balancing covariates via propensity score weighting. Journal American Statistical Association, 113(521), 390-400. (ATO weights) Zhou, Y., Matsouaka, R. ., & Thomas, L. (2020). Propensity score weighting limited overlap model misspecification. Statistical Methods Medical Research, 29(12), 3721-3756. (Entropy weights)","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"continuous-exposures-1","dir":"Reference","previous_headings":"","what":"Continuous Exposures","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Hirano, K., & Imbens, G. W. (2004). propensity score continuous treatments. Applied Bayesian Modeling Causal Inference Incomplete-Data Perspectives, 226164, 73-84.","code":""},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"practical-guidance","dir":"Reference","previous_headings":"","what":"Practical Guidance","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"Austin, P. C., & Stuart, E. . (2015). Moving towards best practice using inverse probability treatment weighting (IPTW) using propensity score estimate causal treatment effects observational studies. Statistics Medicine, 34(28), 3661-3679.","code":""},{"path":[]},{"path":"https://r-causal.github.io/propensity/reference/wt_ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Propensity Score Weights for Causal Inference — wt_ate","text":"","code":"## Basic Usage with Binary Exposures  # Simulate a simple dataset set.seed(123) n <- 100 propensity_scores <- runif(n, 0.1, 0.9) treatment <- rbinom(n, 1, propensity_scores)  # Calculate different weight types weights_ate <- wt_ate(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 weights_att <- wt_att(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 weights_atu <- wt_atu(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  # With explicit focal and reference levels weights_att_explicit <- wt_att(propensity_scores, treatment,                                .focal_level = 1, .reference_level = 0) #> ℹ Treating `.exposure` as binary weights_atm <- wt_atm(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 weights_ato <- wt_ato(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1 weights_entropy <- wt_entropy(propensity_scores, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  # Compare weight distributions summary(weights_ate) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.112   1.317   1.591   2.044   2.047   7.482  summary(weights_ato)  # Often more stable than ATE #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.1005  0.2406  0.3713  0.3976  0.5113  0.8664   ## Stabilized Weights  # Stabilization reduces variance weights_ate_stab <- wt_ate(propensity_scores, treatment, stabilize = TRUE) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  ## Handling Extreme Propensity Scores  # Create data with positivity violations ps_extreme <- c(0.01, 0.02, 0.98, 0.99, rep(0.5, 4)) trt_extreme <- c(0, 0, 1, 1, 0, 1, 0, 1)  # Standard ATE weights can be extreme wt_extreme <- wt_ate(ps_extreme, trt_extreme) #> ℹ Treating `.exposure` as binary # Very large! max(wt_extreme) #> [1] 2  # ATO weights are bounded wt_extreme_ato <- wt_ato(ps_extreme, trt_extreme) #> ℹ Treating `.exposure` as binary # Much more reasonable max(wt_extreme_ato) #> [1] 0.5 # but they target a different population estimand(wt_extreme_ato) # \"ato\" #> [1] \"ato\"  ## Working with Data Frames  # Example with custom data frame ps_df <- data.frame(   control = c(0.9, 0.7, 0.3, 0.1),   treated = c(0.1, 0.3, 0.7, 0.9) ) exposure <- c(0, 0, 1, 1)  # Uses second column by default (treated probabilities) wt_ate(ps_df, exposure) #> ℹ Treating `.exposure` as binary #> ℹ Treating `.exposure` as binary #> <psw{estimand = ate}[4]> #> [1] 1.111111 1.428571 1.428571 1.111111  # Explicitly specify column by name wt_ate(ps_df, exposure, .propensity_col = \"treated\") #> ℹ Treating `.exposure` as binary #> ℹ Treating `.exposure` as binary #> <psw{estimand = ate}[4]> #> [1] 1.111111 1.428571 1.428571 1.111111  # Or by position wt_ate(ps_df, exposure, .propensity_col = 2) #> ℹ Treating `.exposure` as binary #> ℹ Treating `.exposure` as binary #> <psw{estimand = ate}[4]> #> [1] 1.111111 1.428571 1.428571 1.111111  ## Working with GLM Objects  # Fit a propensity score model set.seed(123) n <- 100 x1 <- rnorm(n) x2 <- rnorm(n) treatment <- rbinom(n, 1, plogis(0.5 * x1 + 0.3 * x2))  ps_model <- glm(treatment ~ x1 + x2, family = binomial)  # Use GLM directly for weight calculation weights_from_glm <- wt_ate(ps_model, treatment) #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1  # Or omit the exposure argument (it will be extracted from the GLM) weights_from_glm_auto <- wt_ate(ps_model) #> ℹ Using exposure variable \"treatment\" from GLM model #> ℹ Treating `.exposure` as binary #> ℹ Setting focal level to 1"},{"path":"https://r-causal.github.io/propensity/news/index.html","id":"propensity-development-version","dir":"Changelog","previous_headings":"","what":"propensity (development version)","title":"propensity (development version)","text":"Initial CRAN submission.","code":""}]
